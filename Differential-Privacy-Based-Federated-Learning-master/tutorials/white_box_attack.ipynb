{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whitebox attack using privacy meter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this tutorial we will see:\n",
    "\n",
    "- How to use the privacy meter to audit model implemented on Pytorch\n",
    "- How to extract the white-box signal (i.e., gradient norm)\n",
    "- How to run membership inference attack based on white-box attack based on the population attack"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "<td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/privacytrustlab/ml_privacy_meter/blob/master/tutorials/white_box_attack.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/privacytrustlab/ml_privacy_meter/blob/master/tutorials/white_box_attack.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wayne/.local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "\n",
    "from torch import nn\n",
    "from ast import List\n",
    "from torchvision import transforms\n",
    "from decimal import *\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from scipy.special import comb\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from opacus.grad_sample import GradSampleModule\n",
    "\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "torch.cuda.manual_seed_all(123)\n",
    "torch.cuda.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 15:27:05.932366: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-23 15:27:06.441664: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-23 15:27:06.441715: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-23 15:27:06.441721: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from privacy_meter.audit import Audit, MetricEnum\n",
    "from privacy_meter.metric import PopulationMetric\n",
    "from privacy_meter.information_source_signal import ModelGradientNorm, ModelGradient, ModelLoss\n",
    "from privacy_meter.hypothesis_test import linear_itp_threshold_func\n",
    "from privacy_meter.audit_report import ROCCurveReport, SignalHistogramReport\n",
    "from privacy_meter.constants import InferenceGame\n",
    "from privacy_meter.dataset import Dataset\n",
    "from privacy_meter.information_source import InformationSource\n",
    "from privacy_meter.model import PytorchModelTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# epsilon = 1\n",
    "# vals_laplace = [np.random.laplace(loc=0, scale=1/epsilon) for x in range(100000)]\n",
    "# delta = 10e-5\n",
    "# sigma = np.sqrt(2 * np.log(1.25 / delta)) * 1 / epsilon\n",
    "# vals_gauss = [np.random.normal(loc=0, scale=sigma) for x in range(100000)]\n",
    "# torch.normal(0, sigma, (1,10))\n",
    "\n",
    "def per_sample_clip(net, clip, norm):\n",
    "    grad_samples = [x.grad_sample for x in net.parameters()]\n",
    "    per_param_norms = [\n",
    "        g.reshape(len(g), -1).norm(norm, dim=-1) for g in grad_samples\n",
    "    ]\n",
    "    per_sample_norms = torch.stack(per_param_norms, dim=1).norm(norm, dim=1)\n",
    "    per_sample_clip_factor = (\n",
    "        torch.div(clip, (per_sample_norms + 1e-6))\n",
    "    ).clamp(max=1.0)\n",
    "    for grad in grad_samples:\n",
    "        factor = per_sample_clip_factor.reshape(per_sample_clip_factor.shape + (1,) * (grad.dim() - 1))\n",
    "        grad.detach().mul_(factor.to(grad.device))\n",
    "    # average per sample gradient after clipping and set back gradient\n",
    "    for param in net.parameters():\n",
    "        param.grad = param.grad_sample.detach().mean(dim=0)\n",
    "\n",
    "def clip_gradients(net, clip):\n",
    "    per_sample_clip(net, clip, norm=2)\n",
    "\n",
    "def Gaussian_Simple(epsilon, delta):\n",
    "    return np.sqrt(2 * np.log(1.25 / delta)) / epsilon\n",
    "\n",
    "def cal_noise_scale(glob_e, epsilon, delta):\n",
    "    epsilon_single_query = epsilon / glob_e\n",
    "    delta_single_query = delta / glob_e\n",
    "    return Gaussian_Simple(epsilon=epsilon_single_query, delta=delta_single_query)\n",
    "\n",
    "def cal_sensitivity(lr, clip, dataset_size):\n",
    "    return 2 * lr * clip / dataset_size\n",
    "\n",
    "def add_noise(net, glob_e, lr, epsilon, delta, clip, dataset_len, device):\n",
    "    sensitivity = cal_sensitivity(lr, clip, dataset_len)\n",
    "    noise_scale = cal_noise_scale(glob_e, epsilon, delta)\n",
    "    state_dict = net.state_dict()\n",
    "    for k, v in state_dict.items():\n",
    "        state_dict[k] += torch.from_numpy(np.random.normal(loc=0, scale=sensitivity * noise_scale,\n",
    "                                                            size=v.shape)).to(device)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdp2dp(rdp, bad_event, alpha):\n",
    "    \"\"\"\n",
    "    convert RDP to DP, Ref:\n",
    "    - Canonne, ClÃ©ment L., Gautam Kamath, and Thomas Steinke. The discrete gaussian for differential privacy. In NeurIPS, 2020. (See Proposition 12)\n",
    "    - Asoodeh, S., Liao, J., Calmon, F.P., Kosut, O. and Sankar, L., A better bound gives a hundred rounds: Enhanced privacy guarantees via f-divergences. In ISIT, 2020. (See Lemma 1)\n",
    "    \"\"\"\n",
    "    return rdp + 1.0/(alpha-1) * (np.log(1.0/bad_event) + (alpha-1)*np.log(1-1.0/alpha) - np.log(alpha))\n",
    "\n",
    "\n",
    "def compute_rdp(alpha, q, sigma):\n",
    "    \"\"\"\n",
    "    RDP for subsampled Gaussian mechanism, Ref:\n",
    "    - Mironov, Ilya, Kunal Talwar, and Li Zhang. R\\'enyi differential privacy of the sampled gaussian mechanism. arXiv preprint 2019.\n",
    "    \"\"\"\n",
    "    sum_ = Decimal(0.0)\n",
    "    for k in range(0, alpha+1):\n",
    "        sum_ += Decimal(comb(alpha, k)) * Decimal(1-q)**Decimal(alpha-k) * Decimal(q**k) * Decimal(np.e)**(Decimal(k**2-k)/Decimal(2*sigma**2))\n",
    "    rdp = sum_.ln() / Decimal(alpha-1)\n",
    "    return float(rdp)\n",
    "\n",
    "def search_dp(q, sigma, bad_event, iters=1):\n",
    "    \"\"\"\n",
    "    Given the sampling rate, variance of Gaussian noise, and privacy parameter delta, \n",
    "    this function returns the corresponding DP budget.\n",
    "    \"\"\"\n",
    "    min_dp = 1e5\n",
    "    for alpha in list(range(2, 101)):\n",
    "        rdp = iters * compute_rdp(alpha, q, sigma)\n",
    "        dp = rdp2dp(rdp, bad_event, alpha)\n",
    "        min_dp = min(min_dp, dp)\n",
    "    return min_dp\n",
    "\n",
    "def calibrating_sampled_gaussian(q, eps, bad_event, iters=1, err=1e-3):\n",
    "    \"\"\"\n",
    "    Calibrate noise to privacy budgets\n",
    "    \"\"\"\n",
    "    sigma_max = 100\n",
    "    sigma_min = 0.1\n",
    "    \n",
    "    def binary_search(left, right):\n",
    "        mid = (left + right) / 2\n",
    "        \n",
    "        lbd = search_dp(q, mid, bad_event, iters)\n",
    "        ubd = search_dp(q, left, bad_event, iters)\n",
    "        \n",
    "        if ubd > eps and lbd > eps:    # min noise & mid noise are too small\n",
    "            left = mid\n",
    "        elif ubd > eps and lbd < eps:  # mid noise is too large\n",
    "            right = mid\n",
    "        else:\n",
    "            print(\"an error occurs in func: binary search!\")\n",
    "            return -1\n",
    "        return left, right\n",
    "        \n",
    "    # check\n",
    "    if search_dp(q, sigma_max, bad_event, iters) > eps:\n",
    "        print(\"noise > 100\")\n",
    "        return -1\n",
    "    \n",
    "    while sigma_max-sigma_min > err:\n",
    "        sigma_min, sigma_max = binary_search(sigma_min, sigma_max)\n",
    "    return sigma_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noise scale = 4.34361230389877\n"
     ]
    }
   ],
   "source": [
    "# for training the target model\n",
    "num_train_points = 1500\n",
    "num_test_points = 1500\n",
    "num_population_points = 2000\n",
    "batch_size = 32\n",
    "learning_rate = 0.01\n",
    "local_epochs = 15\n",
    "clients = 10\n",
    "glob_epochs = 10\n",
    "drop_frac = 0.1\n",
    "\n",
    "q = 0.9 # sampling rate\n",
    "eps = 1.0 # privacy budget\n",
    "delta = 10e-5 # probability of something bad happening\n",
    "clip = 1.0\n",
    "# sigma = calibrating_sampled_gaussian(q, eps, delta, iters=local_epochs * glob_epochs, err=1e-3)\n",
    "# laplace noise: [np.random.laplace(loc=0, scale=1/epsilon) for x in range(100000)]\n",
    "sigma = np.sqrt(2 * np.log(1.25 / delta)) * 1 / eps\n",
    "# gaussian noise: vals_gauss = [np.random.normal(loc=0, scale=sigma) for x in range(100000)]\n",
    "print(\"noise scale =\", sigma)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' # you can change it to 'cuda' if you have GPU\n",
    "mechanism = \"DP2\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "    \"\"\"Simple CNN for CIFAR10 dataset.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Forward pass of the model.\"\"\"\n",
    "        inputs = self.pool(F.relu(self.conv1(inputs)))\n",
    "        inputs = self.pool(F.relu(self.conv2(inputs)))\n",
    "        # flatten all dimensions except batch\n",
    "        inputs = inputs.reshape(-1, 16 * 5 * 5)\n",
    "        inputs = F.relu(self.fc1(inputs))\n",
    "        inputs = F.relu(self.fc2(inputs))\n",
    "        outputs = self.fc3(inputs)\n",
    "        return outputs\n",
    "    \n",
    "class CNNMnist(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, x.shape[1]*x.shape[2]*x.shape[3])\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        output = self.fc2(x)\n",
    "        return output\n",
    "    \n",
    "class CNNCifar(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        # self.pool = nn.MaxPool2d(2, 2)\n",
    "        # self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.conv1 = nn.Conv2d(3, 64, 5)\n",
    "        self.pool = nn.MaxPool2d(3, 2)\n",
    "        self.conv2 = nn.Conv2d(64, 64, 5)\n",
    "        # self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        # self.fc2 = nn.Linear(120, 84)\n",
    "        # self.fc3 = nn.Linear(84, args.num_classes)\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 384)\n",
    "        self.fc2 = nn.Linear(384, 192)\n",
    "        self.fc3 = nn.Linear(192, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        #x = x.view(-1, 16 * 5 * 5)\n",
    "        x = x.view(-1, 64 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      self.conv1 = nn.Conv2d(3, 16, 3, 1, padding=1) # input is color image, hence 3 i/p channels. 16 filters, kernal size is tuned to 3 to avoid overfitting, stride is 1 , padding is 1 extract all edge features.\n",
    "      self.conv2 = nn.Conv2d(16, 32, 3, 1, padding=1) # We double the feature maps for every conv layer as in pratice it is really good.\n",
    "      self.conv3 = nn.Conv2d(32, 64, 3, 1, padding=1)\n",
    "      self.fc1 = nn.Linear(4*4*64, 500) # I/p image size is 32*32, after 3 MaxPooling layers it reduces to 4*4 and 64 because our last conv layer has 64 outputs. Output nodes is 500\n",
    "      self.dropout1 = nn.Dropout(0.5)\n",
    "      self.fc2 = nn.Linear(500, 10) # output nodes are 10 because our dataset have 10 different categories\n",
    "    def forward(self, x):\n",
    "      x = F.relu(self.conv1(x)) #Apply relu to each output of conv layer.\n",
    "      x = F.max_pool2d(x, 2, 2) # Max pooling layer with kernal of 2 and stride of 2\n",
    "      x = F.relu(self.conv2(x))\n",
    "      x = F.max_pool2d(x, 2, 2)\n",
    "      x = F.relu(self.conv3(x))\n",
    "      x = F.max_pool2d(x, 2, 2)\n",
    "      x = x.view(-1, 4*4*64) # flatten our images to 1D to input it to the fully connected layers\n",
    "      x = F.relu(self.fc1(x))\n",
    "      x = self.dropout1(x) # Applying dropout b/t layers which exchange highest parameters. This is a good practice\n",
    "      x = self.fc2(x)\n",
    "      return x\n",
    "    \n",
    "# 3x3 convolution\n",
    "def conv3x3(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
    "                     stride=stride, padding=1, bias=False)\n",
    "\n",
    "# Residual block\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(out_channels, out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "# ResNet\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 16\n",
    "        self.conv = conv3x3(3, 16)\n",
    "        self.bn = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self.make_layer(block, 16, layers[0])\n",
    "        self.layer2 = self.make_layer(block, 32, layers[1], 2)\n",
    "        self.layer3 = self.make_layer(block, 64, layers[2], 2)\n",
    "        self.avg_pool = nn.AvgPool2d(8)\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "\n",
    "    def make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if (stride != 1) or (self.in_channels != out_channels):\n",
    "            downsample = nn.Sequential(\n",
    "                conv3x3(self.in_channels, out_channels, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels))\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# transform_train = transforms.Compose([\n",
    "#     transforms.RandomCrop(32, padding=4),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "# ])\n",
    "\n",
    "# transform_test = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "# ])\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "all_data = torchvision.datasets.CIFAR10(\n",
    "    root='.', train=True, download=True, transform=transform\n",
    ")\n",
    "test_data = torchvision.datasets.CIFAR10(\n",
    "    root='.', train=False, download=True, transform=transform\n",
    ")\n",
    "all_features = np.concatenate([all_data.data, test_data.data], axis=0)\n",
    "all_targets = np.concatenate([all_data.targets, test_data.targets], axis=0)\n",
    "\n",
    "all_data.data = all_features\n",
    "all_data.targets = all_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_subset(dataset: torchvision.datasets, index: List(int)):\n",
    "    \"\"\"Get a subset of the dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset (torchvision.datasets): Whole dataset.\n",
    "        index (list): List of index.\n",
    "    \"\"\"\n",
    "    assert max(index) < len(dataset) and min(index) >= 0, \"Index out of range\"\n",
    "    data = (\n",
    "        torch.from_numpy(dataset.data[index]).float().permute(0, 3, 1, 2) / 255\n",
    "    )  # channel first\n",
    "    targets = list(np.array(dataset.targets)[index])\n",
    "    targets = torch.tensor(targets, dtype=torch.long)\n",
    "    return data, targets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into train, test and population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_index = []\n",
    "train_data, train_targets, test_data, test_targets, audit_data, audit_targets, train_index, test_index = [], [], [], [], [], [], [], []\n",
    "\n",
    "all_index = np.arange(len(all_data))\n",
    "for i in range(clients):\n",
    "  train_i = np.random.choice([i for i in all_index if i not in chosen_index], num_train_points, replace=False)\n",
    "  test_i = np.random.choice([i for i in all_index if i not in train_i and i not in chosen_index], num_test_points, replace=False)\n",
    "  population_index = np.random.choice([i for i in all_index if i not in train_i and i not in test_i and i not in chosen_index], num_population_points, replace=False)\n",
    "  chosen_index = np.concatenate((chosen_index,train_i,test_i,population_index))\n",
    "\n",
    "  train_d, train_t = get_dataset_subset(all_data, train_i)\n",
    "  test_d, test_t = get_dataset_subset(all_data, test_i)\n",
    "  audit_d, audit_t = get_dataset_subset(all_data, population_index)\n",
    "  train_data.insert(i, train_d)\n",
    "  train_targets.insert(i, train_t)\n",
    "  test_data.insert(i, test_d)\n",
    "  test_targets.insert(i, test_t)\n",
    "  audit_data.insert(i, audit_d)\n",
    "  audit_targets.insert(i, audit_t)\n",
    "  train_index.insert(i, train_i)\n",
    "  test_index.insert(i, test_i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the data loader for training the target model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = [], []\n",
    "for i in range(clients):\n",
    "  train_l = torch.utils.data.DataLoader(\n",
    "              torch.utils.data.Subset(all_data,train_index[i]),\n",
    "              batch_size=batch_size,\n",
    "              shuffle=True,\n",
    "              num_workers=4,\n",
    "              pin_memory=True,\n",
    "              persistent_workers=True,\n",
    "              prefetch_factor=16)\n",
    "  test_l = torch.utils.data.DataLoader(\n",
    "              torch.utils.data.Subset(all_data,test_index[i]),\n",
    "              batch_size=batch_size,\n",
    "              shuffle=True,\n",
    "              num_workers=4,\n",
    "              pin_memory=True,\n",
    "              persistent_workers=True,\n",
    "              prefetch_factor=16)\n",
    "  train_loader.insert(i, train_l)\n",
    "  test_loader.insert(i, test_l)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the target model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sec_func(model, criterion, device, train_data, train_targets, test_data, test_targets, audit_data, audit_targets):\n",
    "    target_model = PytorchModelTensor(model_obj=model, loss_fn=criterion, device=device, batch_size=10)\n",
    "\n",
    "    target_dataset = Dataset(\n",
    "    data_dict={\n",
    "        \"train\": {\"x\": train_data, \"y\": train_targets},\n",
    "        \"test\": {\"x\": test_data, \"y\": test_targets},\n",
    "    },\n",
    "    default_input=\"x\",\n",
    "    default_output=\"y\",\n",
    "    )\n",
    "\n",
    "    audit_dataset = Dataset(\n",
    "        data_dict={\"train\": {\"x\": audit_data, \"y\": audit_targets}},\n",
    "        default_input=\"x\",\n",
    "        default_output=\"y\",\n",
    "    )\n",
    "\n",
    "    target_info_source = InformationSource(\n",
    "        models=[target_model], \n",
    "        datasets=[target_dataset]\n",
    "    )\n",
    "\n",
    "    reference_info_source = InformationSource(\n",
    "        models=[target_model],\n",
    "        datasets=[audit_dataset]\n",
    "    )\n",
    "\n",
    "    metric = PopulationMetric(\n",
    "                target_info_source=target_info_source,\n",
    "                reference_info_source=reference_info_source,\n",
    "                signals=[ModelLoss()],\n",
    "                hypothesis_test_func=linear_itp_threshold_func,\n",
    "            )\n",
    "    audit_obj = Audit(\n",
    "        metrics=metric,\n",
    "        inference_game_type=InferenceGame.PRIVACY_LOSS_MODEL,\n",
    "        target_info_sources=target_info_source,\n",
    "        reference_info_sources=reference_info_source,\n",
    "        save_logs= False\n",
    "    )\n",
    "    audit_obj.prepare()\n",
    "    return audit_obj.run()[0]\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.to(device)    \n",
    "    # Validate the performance of the model \n",
    "    model.eval()\n",
    "    # Assigning variables for computing loss and accuracy\n",
    "    loss, acc, criterion = 0, 0, nn.CrossEntropyLoss()\n",
    "\n",
    "    # Disable gradient calculation to save memory\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            # Moving data and target to the device\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # Cast target to long tensor\n",
    "            target = target\n",
    "\n",
    "            # Computing output and loss\n",
    "            output = model(data)\n",
    "            loss += criterion(output, target).item()\n",
    "\n",
    "            # Computing accuracy\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            acc += pred.eq(target.data.view_as(pred)).sum()\n",
    "\n",
    "        # Averaging the losses\n",
    "        loss /= len(test_loader)\n",
    "\n",
    "        # Calculating accuracy\n",
    "        acc = float(acc) / len(test_loader.dataset)\n",
    "\n",
    "    # Move the model back to the CPU to save memory\n",
    "    model.to(\"cpu\")\n",
    "    return loss, 100. * acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_noise(data_shape, s, sigma, device=None):\n",
    "    \"\"\"\n",
    "    Gaussian noise\n",
    "    \"\"\"\n",
    "    return torch.normal(0, sigma * s, data_shape).to(device)\n",
    "\n",
    "def dp_train(model, device, idx, lr, epochs, train_loader, test_loader, train_data, train_targets, test_data, test_targets, audit_data, audit_targets, sec_record, q, BATCH_SIZE, clip, sigma, data_size):\n",
    "    \"\"\"local model update\"\"\"\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    start_time = time.time()\n",
    "    # optimizer = torch.optim.Adam(self.model.parameters())\n",
    "    \n",
    "    for epoch_idx in range(epochs):\n",
    "        # randomly select q fraction samples from data\n",
    "        # according to the privacy analysis of moments accountant\n",
    "        # training \"Lots\" are sampled by poisson sampling\n",
    "        train_loss = 0\n",
    "        data_pos = np.where(np.random.rand(len(train_data)) < q)[0]\n",
    "\n",
    "        sampled_dataset = TensorDataset(train_data[data_pos], train_targets[data_pos])\n",
    "        sample_data_loader = torch.utils.data.DataLoader(\n",
    "              dataset=sampled_dataset,\n",
    "              batch_size=batch_size,\n",
    "              shuffle=True,\n",
    "              num_workers=4,\n",
    "              pin_memory=True,\n",
    "              persistent_workers=True,\n",
    "              prefetch_factor=16)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        clipped_grads = {name: torch.zeros_like(param) for name, param in model.named_parameters()}\n",
    "        for batch_x, batch_y in sample_data_loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            pred_y = model(batch_x.float())\n",
    "            loss = criterion(pred_y, batch_y.long())\n",
    "            \n",
    "            # bound l2 sensitivity (gradient clipping)\n",
    "            # clip each of the gradient in the \"Lot\"\n",
    "            for i in range(loss.size()[0]):\n",
    "                loss[i].backward(retain_graph=True)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip)\n",
    "                for name, param in model.named_parameters():\n",
    "                    clipped_grads[name] += param.grad \n",
    "                model.zero_grad()\n",
    "            # Add the loss to the total loss\n",
    "\n",
    "            train_loss += loss.sum() / len(loss)\n",
    "                \n",
    "        # add Gaussian noise\n",
    "        for name, param in model.named_parameters():\n",
    "            clipped_grads[name] += gaussian_noise(clipped_grads[name].shape, clip, sigma, device=device)\n",
    "            \n",
    "        # scale back\n",
    "        for name, param in model.named_parameters():\n",
    "            clipped_grads[name] /= (data_size * q)\n",
    "        \n",
    "        for name, param in model.named_parameters():\n",
    "            param.grad = clipped_grads[name]\n",
    "        \n",
    "        # update local model\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_audit_results = sec_func(copy.deepcopy(model), criterion, device, train_data, train_targets, test_data, test_targets, audit_data, audit_targets)\n",
    "        # Print the epoch and loss summary\n",
    "        print(f\"ID: {idx} | Epoch: {epoch_idx+1}/{epochs} |\", end=\" \")\n",
    "        print(f\"Loss: {train_loss/len(train_loader):.4f} |\", end=\" \")\n",
    "        print(f\"Attack_acc: {100. * loss_audit_results[0].roc_auc:.2f}%\")\n",
    "    if idx == 0:\n",
    "        loss_audit_results = sec_func(model, criterion, device, train_data, train_targets, test_data, test_targets, audit_data, audit_targets)\n",
    "        sec_record.append(loss_audit_results[0].roc_auc)\n",
    "    test_loss, test_acc = test(copy.deepcopy(model), device, test_loader)\n",
    "    print(f\"Test loss: {test_loss:.4f} | Test Acc: {test_acc:.2f}%\")\n",
    "    print(\"training the target model uses: \", time.time() - start_time)\n",
    "    return model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob_model = ResNet(ResidualBlock, [2, 2, 2])\n",
    "\n",
    "def nor_train(model, device, idx, lr, epochs, train_loader, test_loader, train_data, train_targets, test_data, test_targets, audit_data, audit_targets, sec_record):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    # Set the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    start_time = time.time()\n",
    "    # Loop over each epoch\n",
    "    for epoch_idx in range(epochs):\n",
    "        train_loss = 0\n",
    "        # Loop over the training set\n",
    "        for data, target in train_loader:\n",
    "            # Move data to the device\n",
    "            data, target = data.to(device, non_blocking=True), target.to(device,non_blocking=True)\n",
    "            # Cast target to long tensor\n",
    "            target = target\n",
    "\n",
    "            # Set the gradients to zero\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            # Get the model output\n",
    "            output = model(data)\n",
    "\n",
    "            # Calculate the loss\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # Perform the backward pass\n",
    "            loss.backward()\n",
    "            # Take a step using optimizer\n",
    "            optimizer.step()\n",
    "\n",
    "            # Add the loss to the total loss\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        loss_audit_results = sec_func(copy.deepcopy(model), criterion, device, train_data, train_targets, test_data, test_targets, audit_data, audit_targets)\n",
    "        # Print the epoch and loss summary\n",
    "        print(f\"ID: {idx} | Epoch: {epoch_idx+1}/{epochs} |\", end=\" \")\n",
    "        print(f\"Loss: {train_loss/len(train_loader):.4f} |\", end=\" \")\n",
    "        print(f\"Attack_acc: {100. * loss_audit_results[0].roc_auc:.2f}%\")\n",
    "    if idx == 0:\n",
    "        loss_audit_results = sec_func(model, criterion, device, train_data, train_targets, test_data, test_targets, audit_data, audit_targets)\n",
    "        sec_record.append(loss_audit_results[0].roc_auc)\n",
    "    test_loss, test_acc = test(copy.deepcopy(model), device, test_loader)\n",
    "    print(f\"Test loss: {test_loss:.4f} | Test Acc: {test_acc:.2f}%\")\n",
    "    print(\"training the target model uses: \", time.time() - start_time)\n",
    "    return model.state_dict()\n",
    "\n",
    "def dp_trainv2(model, device, idx, lr, epochs, train_loader, test_loader, train_data, train_targets, test_data, test_targets, audit_data, audit_targets, sec_record, epsilon, delta, glob_epochs, clip):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    # Set the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    start_time = time.time()\n",
    "    # Loop over each epoch\n",
    "    for epoch_idx in range(epochs):\n",
    "        train_loss = 0\n",
    "        # Loop over the training set\n",
    "        for data, target in train_loader:\n",
    "            for param in model.parameters():\n",
    "                param.accumulated_grads = []\n",
    "            # Move data to the device\n",
    "            data, target = data.to(device, non_blocking=True), target.to(device,non_blocking=True)\n",
    "            # Cast target to long tensor\n",
    "            target = target\n",
    "\n",
    "            # Set the gradients to zero\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            # Get the model output\n",
    "            output = model(data)\n",
    "\n",
    "            # Calculate the loss\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # Perform the backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Take a step using optimizer\n",
    "            optimizer.step()\n",
    "\n",
    "            # Add the loss to the total loss\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        loss_audit_results = sec_func(copy.deepcopy(model), criterion, device, train_data, train_targets, test_data, test_targets, audit_data, audit_targets)\n",
    "        # Print the epoch and loss summary\n",
    "        print(f\"ID: {idx} | Epoch: {epoch_idx+1}/{epochs} |\", end=\" \")\n",
    "        print(f\"Loss: {train_loss/len(train_loader):.4f} |\", end=\" \")\n",
    "        print(f\"Attack_acc: {100. * loss_audit_results[0].roc_auc:.2f}%\")\n",
    "    # add Gaussian noise\n",
    "    model_w = model.state_dict()\n",
    "    sensitivity = 2 * epochs * lr  / len(train_data)\n",
    "    # sigma = np.sqrt(2 * np.log(1.25 / (delta / (glob_epochs * epochs)))) * 1 / (epsilon / (glob_epochs * epochs))\n",
    "    sigma = np.sqrt(2 * np.log(1.25 / (delta / glob_epochs))) / (epsilon / glob_epochs) \n",
    "    for name, param in model_w.items():\n",
    "        if 'weight' in name:\n",
    "            model_w[name] += torch.normal(0, sensitivity * sigma, param.shape).to(device)\n",
    "    if idx == 0:\n",
    "        loss_audit_results = sec_func(copy.deepcopy(model), criterion, device, train_data, train_targets, test_data, test_targets, audit_data, audit_targets)\n",
    "        sec_record.append(loss_audit_results[0].roc_auc)\n",
    "    loss_noisy_audit_results = sec_func(copy.deepcopy(model), criterion, device, train_data, train_targets, test_data, test_targets, audit_data, audit_targets)\n",
    "    test_loss, test_acc = test(copy.deepcopy(model), device, test_loader)\n",
    "    print(f\"Test loss: {test_loss:.4f} | Test Acc: {test_acc:.2f}% | Attack Acc: {100 * loss_noisy_audit_results[0].roc_auc:.2f}%\")\n",
    "    print(\"training the target model uses: \", time.time() - start_time)\n",
    "    return model.state_dict()\n",
    "\n",
    "def aggregate(w_locals, clients, device):\n",
    "    \"\"\"FedAvg\"\"\"\n",
    "    new_w = copy.deepcopy(w_locals[0])\n",
    "    for name in new_w:\n",
    "        new_w[name] = torch.zeros(new_w[name].shape).to(device)\n",
    "    for idx in range(clients):\n",
    "        for name in new_w:\n",
    "            new_w[name] += w_locals[idx][name].to(device) * (1 / clients)\n",
    "    return copy.deepcopy(new_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FlatSplitParams(model, split_num):\n",
    "    state_dict = model.state_dict()\n",
    "    l = [torch.flatten(value) for _, value in state_dict.items()]\n",
    "    flat_indice = []\n",
    "    s = 0\n",
    "    for p in l:\n",
    "        size = p.shape[0]\n",
    "        flat_indice.append((s, s+size))\n",
    "        s += size\n",
    "    flat_w = torch.cat(l).view(-1, 1)\n",
    "    split_w = torch.chunk(flat_w, split_num)\n",
    "    split_index = [0]\n",
    "    for i in split_w:\n",
    "        split_index.append(split_index[-1] + len(i))\n",
    "\n",
    "    for k, v in state_dict.items():\n",
    "        state_dict[k] = torch.zeros(v.shape)\n",
    "    return split_index, flat_indice\n",
    "\n",
    "def SliceLocalWeight(model, split_index):\n",
    "    split_num = len(split_index)-1\n",
    "    state_dict = model.state_dict()\n",
    "    flat_w = torch.cat([torch.flatten(value) for _, value in state_dict.items()]).view(-1, 1)\n",
    "    return torch.chunk(flat_w, split_num)\n",
    "\n",
    "def SliceLocalNoise(sensitivity, noise_scale, num_users, flat_indice):\n",
    "    noise_store = torch.tensor([])\n",
    "    for (s, e) in flat_indice:\n",
    "        noise_unit = torch.from_numpy(np.random.normal(loc=0, scale=sensitivity * noise_scale, size=(e-s, 1)))\n",
    "        noise_store = torch.cat((noise_store, noise_unit))\n",
    "    # cut noise\n",
    "    weight_slice = torch.chunk(noise_store, num_users)\n",
    "    return weight_slice\n",
    "\n",
    "def ProtectWeight(local_w, noise_slices, weight_slices, split_index, id, flat_indice, device): # add dp noise & other users' weight\n",
    "    split_num = len(split_index)-1\n",
    "    # flat local_w which wants to add protect mechanism\n",
    "    flat_w = torch.cat([torch.flatten(value) for _, value in local_w.items()]).view(-1, 1)\n",
    "    # bulit add weight sequence\n",
    "    add_sequence = [(id + i) % split_num for i in range(split_num)]\n",
    "    # add dp_noise & weight_slice on slice local_w by index\n",
    "    for i, seq in enumerate(add_sequence):\n",
    "        if weight_slices[seq] == 'D':\n",
    "            flat_w[split_index[i]:split_index[i+1]] += noise_slices[id][i].to(device)\n",
    "        else:\n",
    "            flat_w[split_index[i]:split_index[i+1]] = (flat_w[split_index[i]:split_index[i+1]] + weight_slices[seq][i]) / 2\n",
    "    # unflat protected local_w\n",
    "    l = [flat_w[s:e] for (s, e) in flat_indice]\n",
    "    for index, (key, value) in enumerate(local_w.items()):\n",
    "        local_w[key] = l[index].view(*value.shape)\n",
    "\n",
    "def proposed_train(model, device, idx, lr, epochs, train_loader, test_loader, train_data, train_targets, test_data, test_targets, audit_data, audit_targets, sec_record, epsilon, delta, split_index, flat_indice, num_clients):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    # Set the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    start_time = time.time()\n",
    "    # Loop over each epoch\n",
    "    for epoch_idx in range(epochs):\n",
    "        train_loss = 0\n",
    "        # Loop over the training set\n",
    "        for data, target in train_loader:\n",
    "            # Move data to the device\n",
    "            data, target = data.to(device, non_blocking=True), target.to(device,non_blocking=True)\n",
    "            # Cast target to long tensor\n",
    "            target = target\n",
    "\n",
    "            # Set the gradients to zero\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            # Get the model output\n",
    "            output = model(data)\n",
    "\n",
    "            # Calculate the loss\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # Perform the backward pass\n",
    "            loss.backward()\n",
    "            # Take a step using optimizer\n",
    "            optimizer.step()\n",
    "\n",
    "            # Add the loss to the total loss\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        loss_audit_results = sec_func(copy.deepcopy(model), criterion, device, train_data, train_targets, test_data, test_targets, audit_data, audit_targets)\n",
    "        # Print the epoch and loss summary\n",
    "        print(f\"ID: {idx} | Epoch: {epoch_idx+1}/{epochs} |\", end=\" \")\n",
    "        print(f\"Loss: {train_loss/len(train_loader):.4f} |\", end=\" \")\n",
    "        print(f\"Attack_acc: {100. * loss_audit_results[0].roc_auc:.2f}%\")\n",
    "    if idx == 0:\n",
    "        loss_audit_results = sec_func(model, criterion, device, train_data, train_targets, test_data, test_targets, audit_data, audit_targets)\n",
    "        sec_record.append(loss_audit_results[0].roc_auc)\n",
    "    test_loss, test_acc = test(copy.deepcopy(model), device, test_loader)\n",
    "    print(f\"Test loss: {test_loss:.4f} | Test Acc: {test_acc:.2f}%\")\n",
    "    print(\"training the target model uses: \", time.time() - start_time)\n",
    "\n",
    "    sensitivity = 2 * epochs * lr  / len(train_data)\n",
    "    sigma = np.sqrt(2 * np.log(1.25 / (delta / glob_epochs))) / (epsilon / glob_epochs)\n",
    "\n",
    "    weight_slice = SliceLocalWeight(copy.deepcopy(model), split_index)\n",
    "    noise_slice = SliceLocalNoise(sensitivity, sigma, num_clients, flat_indice)\n",
    "\n",
    "    return model.state_dict(), weight_slice, noise_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Epoch:  0\n",
      "ID: 0 | Epoch: 1/15 | Loss: 2.1142 | Attack_acc: 51.83%\n",
      "ID: 0 | Epoch: 2/15 | Loss: 1.8205 | Attack_acc: 50.78%\n",
      "ID: 0 | Epoch: 3/15 | Loss: 1.6848 | Attack_acc: 51.68%\n",
      "ID: 0 | Epoch: 4/15 | Loss: 1.5709 | Attack_acc: 54.96%\n",
      "ID: 0 | Epoch: 5/15 | Loss: 1.4820 | Attack_acc: 54.09%\n",
      "ID: 0 | Epoch: 6/15 | Loss: 1.4306 | Attack_acc: 54.27%\n",
      "ID: 0 | Epoch: 7/15 | Loss: 1.3717 | Attack_acc: 55.19%\n",
      "ID: 0 | Epoch: 8/15 | Loss: 1.2722 | Attack_acc: 58.30%\n",
      "ID: 0 | Epoch: 9/15 | Loss: 1.1408 | Attack_acc: 55.97%\n",
      "ID: 0 | Epoch: 10/15 | Loss: 1.0863 | Attack_acc: 61.40%\n",
      "ID: 0 | Epoch: 11/15 | Loss: 0.9915 | Attack_acc: 63.11%\n",
      "ID: 0 | Epoch: 12/15 | Loss: 0.8751 | Attack_acc: 58.69%\n",
      "ID: 0 | Epoch: 13/15 | Loss: 0.7723 | Attack_acc: 67.79%\n",
      "ID: 0 | Epoch: 14/15 | Loss: 0.6593 | Attack_acc: 65.88%\n",
      "ID: 0 | Epoch: 15/15 | Loss: 0.5137 | Attack_acc: 70.63%\n",
      "Test loss: 2.3610 | Test Acc: 36.60% | Attack Acc: 69.51%\n",
      "training the target model uses:  20.11732578277588\n",
      "ID: 1 | Epoch: 1/15 | Loss: 2.0907 | Attack_acc: 51.94%\n",
      "ID: 1 | Epoch: 2/15 | Loss: 1.8482 | Attack_acc: 51.16%\n",
      "ID: 1 | Epoch: 3/15 | Loss: 1.7199 | Attack_acc: 52.28%\n",
      "ID: 1 | Epoch: 4/15 | Loss: 1.6426 | Attack_acc: 55.14%\n",
      "ID: 1 | Epoch: 5/15 | Loss: 1.4838 | Attack_acc: 52.37%\n",
      "ID: 1 | Epoch: 6/15 | Loss: 1.4409 | Attack_acc: 52.42%\n",
      "ID: 1 | Epoch: 7/15 | Loss: 1.3644 | Attack_acc: 57.58%\n",
      "ID: 1 | Epoch: 8/15 | Loss: 1.2308 | Attack_acc: 59.45%\n",
      "ID: 1 | Epoch: 9/15 | Loss: 1.1409 | Attack_acc: 62.94%\n",
      "ID: 1 | Epoch: 10/15 | Loss: 1.0612 | Attack_acc: 60.77%\n",
      "ID: 1 | Epoch: 11/15 | Loss: 0.9742 | Attack_acc: 67.97%\n",
      "ID: 1 | Epoch: 12/15 | Loss: 0.7958 | Attack_acc: 64.40%\n",
      "ID: 1 | Epoch: 13/15 | Loss: 0.6954 | Attack_acc: 64.57%\n",
      "ID: 1 | Epoch: 14/15 | Loss: 0.6091 | Attack_acc: 69.23%\n",
      "ID: 1 | Epoch: 15/15 | Loss: 0.5280 | Attack_acc: 76.29%\n",
      "Test loss: 2.4524 | Test Acc: 34.40% | Attack Acc: 72.72%\n",
      "training the target model uses:  18.894636154174805\n",
      "ID: 2 | Epoch: 1/15 | Loss: 2.0886 | Attack_acc: 50.29%\n",
      "ID: 2 | Epoch: 2/15 | Loss: 1.8716 | Attack_acc: 53.19%\n",
      "ID: 2 | Epoch: 3/15 | Loss: 1.6681 | Attack_acc: 51.58%\n",
      "ID: 2 | Epoch: 4/15 | Loss: 1.6062 | Attack_acc: 53.51%\n",
      "ID: 2 | Epoch: 5/15 | Loss: 1.5264 | Attack_acc: 52.44%\n",
      "ID: 2 | Epoch: 6/15 | Loss: 1.4431 | Attack_acc: 56.37%\n",
      "ID: 2 | Epoch: 7/15 | Loss: 1.3491 | Attack_acc: 56.02%\n",
      "ID: 2 | Epoch: 8/15 | Loss: 1.2873 | Attack_acc: 54.84%\n",
      "ID: 2 | Epoch: 9/15 | Loss: 1.1800 | Attack_acc: 58.61%\n",
      "ID: 2 | Epoch: 10/15 | Loss: 1.0929 | Attack_acc: 60.90%\n",
      "ID: 2 | Epoch: 11/15 | Loss: 0.9679 | Attack_acc: 59.08%\n",
      "ID: 2 | Epoch: 12/15 | Loss: 0.9207 | Attack_acc: 62.74%\n",
      "ID: 2 | Epoch: 13/15 | Loss: 0.7978 | Attack_acc: 61.90%\n",
      "ID: 2 | Epoch: 14/15 | Loss: 0.6806 | Attack_acc: 64.95%\n",
      "ID: 2 | Epoch: 15/15 | Loss: 0.5163 | Attack_acc: 70.66%\n",
      "Test loss: 2.3959 | Test Acc: 35.53% | Attack Acc: 69.40%\n",
      "training the target model uses:  19.039915323257446\n",
      "ID: 3 | Epoch: 1/15 | Loss: 2.1006 | Attack_acc: 52.62%\n",
      "ID: 3 | Epoch: 2/15 | Loss: 1.8982 | Attack_acc: 53.96%\n",
      "ID: 3 | Epoch: 3/15 | Loss: 1.6916 | Attack_acc: 52.74%\n",
      "ID: 3 | Epoch: 4/15 | Loss: 1.6163 | Attack_acc: 54.45%\n",
      "ID: 3 | Epoch: 5/15 | Loss: 1.4942 | Attack_acc: 56.98%\n",
      "ID: 3 | Epoch: 6/15 | Loss: 1.4019 | Attack_acc: 57.63%\n",
      "ID: 3 | Epoch: 7/15 | Loss: 1.3014 | Attack_acc: 59.55%\n",
      "ID: 3 | Epoch: 8/15 | Loss: 1.3167 | Attack_acc: 57.46%\n",
      "ID: 3 | Epoch: 9/15 | Loss: 1.1646 | Attack_acc: 59.53%\n",
      "ID: 3 | Epoch: 10/15 | Loss: 1.0490 | Attack_acc: 61.89%\n",
      "ID: 3 | Epoch: 11/15 | Loss: 0.9761 | Attack_acc: 60.80%\n",
      "ID: 3 | Epoch: 12/15 | Loss: 0.8684 | Attack_acc: 65.46%\n",
      "ID: 3 | Epoch: 13/15 | Loss: 0.6744 | Attack_acc: 65.17%\n",
      "ID: 3 | Epoch: 14/15 | Loss: 0.6336 | Attack_acc: 67.05%\n",
      "ID: 3 | Epoch: 15/15 | Loss: 0.5120 | Attack_acc: 65.63%\n",
      "Test loss: 3.4690 | Test Acc: 29.07% | Attack Acc: 62.48%\n",
      "training the target model uses:  18.146043300628662\n",
      "ID: 4 | Epoch: 1/15 | Loss: 2.0782 | Attack_acc: 51.79%\n",
      "ID: 4 | Epoch: 2/15 | Loss: 1.8744 | Attack_acc: 51.68%\n",
      "ID: 4 | Epoch: 3/15 | Loss: 1.8063 | Attack_acc: 52.07%\n",
      "ID: 4 | Epoch: 4/15 | Loss: 1.6794 | Attack_acc: 52.87%\n",
      "ID: 4 | Epoch: 5/15 | Loss: 1.6317 | Attack_acc: 53.87%\n",
      "ID: 4 | Epoch: 6/15 | Loss: 1.5644 | Attack_acc: 54.99%\n",
      "ID: 4 | Epoch: 7/15 | Loss: 1.4615 | Attack_acc: 56.21%\n",
      "ID: 4 | Epoch: 8/15 | Loss: 1.3461 | Attack_acc: 56.52%\n",
      "ID: 4 | Epoch: 9/15 | Loss: 1.3243 | Attack_acc: 54.63%\n",
      "ID: 4 | Epoch: 10/15 | Loss: 1.2238 | Attack_acc: 61.12%\n",
      "ID: 4 | Epoch: 11/15 | Loss: 1.0827 | Attack_acc: 58.02%\n",
      "ID: 4 | Epoch: 12/15 | Loss: 1.0129 | Attack_acc: 58.72%\n",
      "ID: 4 | Epoch: 13/15 | Loss: 0.9220 | Attack_acc: 60.71%\n",
      "ID: 4 | Epoch: 14/15 | Loss: 0.7827 | Attack_acc: 67.51%\n",
      "ID: 4 | Epoch: 15/15 | Loss: 0.7007 | Attack_acc: 68.54%\n",
      "Test loss: 2.0751 | Test Acc: 40.53% | Attack Acc: 68.02%\n",
      "training the target model uses:  18.11372423171997\n",
      "ID: 5 | Epoch: 1/15 | Loss: 2.0587 | Attack_acc: 50.53%\n",
      "ID: 5 | Epoch: 2/15 | Loss: 1.8508 | Attack_acc: 52.20%\n",
      "ID: 5 | Epoch: 3/15 | Loss: 1.7643 | Attack_acc: 52.11%\n",
      "ID: 5 | Epoch: 4/15 | Loss: 1.6562 | Attack_acc: 55.33%\n",
      "ID: 5 | Epoch: 5/15 | Loss: 1.5958 | Attack_acc: 53.08%\n",
      "ID: 5 | Epoch: 6/15 | Loss: 1.4778 | Attack_acc: 55.76%\n",
      "ID: 5 | Epoch: 7/15 | Loss: 1.3740 | Attack_acc: 57.39%\n",
      "ID: 5 | Epoch: 8/15 | Loss: 1.3090 | Attack_acc: 58.15%\n",
      "ID: 5 | Epoch: 9/15 | Loss: 1.2048 | Attack_acc: 59.27%\n",
      "ID: 5 | Epoch: 10/15 | Loss: 1.1284 | Attack_acc: 64.09%\n",
      "ID: 5 | Epoch: 11/15 | Loss: 1.0459 | Attack_acc: 58.99%\n",
      "ID: 5 | Epoch: 12/15 | Loss: 0.9211 | Attack_acc: 69.98%\n",
      "ID: 5 | Epoch: 13/15 | Loss: 0.7839 | Attack_acc: 65.01%\n",
      "ID: 5 | Epoch: 14/15 | Loss: 0.6752 | Attack_acc: 68.76%\n",
      "ID: 5 | Epoch: 15/15 | Loss: 0.6674 | Attack_acc: 67.37%\n",
      "Test loss: 3.2094 | Test Acc: 32.00% | Attack Acc: 64.20%\n",
      "training the target model uses:  18.46516704559326\n",
      "ID: 6 | Epoch: 1/15 | Loss: 2.1111 | Attack_acc: 52.51%\n",
      "ID: 6 | Epoch: 2/15 | Loss: 1.8783 | Attack_acc: 53.33%\n",
      "ID: 6 | Epoch: 3/15 | Loss: 1.7959 | Attack_acc: 53.15%\n",
      "ID: 6 | Epoch: 4/15 | Loss: 1.6314 | Attack_acc: 52.74%\n",
      "ID: 6 | Epoch: 5/15 | Loss: 1.5752 | Attack_acc: 55.14%\n",
      "ID: 6 | Epoch: 6/15 | Loss: 1.4691 | Attack_acc: 56.23%\n",
      "ID: 6 | Epoch: 7/15 | Loss: 1.3769 | Attack_acc: 54.98%\n",
      "ID: 6 | Epoch: 8/15 | Loss: 1.3286 | Attack_acc: 59.20%\n",
      "ID: 6 | Epoch: 9/15 | Loss: 1.2217 | Attack_acc: 60.21%\n",
      "ID: 6 | Epoch: 10/15 | Loss: 1.1322 | Attack_acc: 61.99%\n",
      "ID: 6 | Epoch: 11/15 | Loss: 1.1173 | Attack_acc: 61.47%\n",
      "ID: 6 | Epoch: 12/15 | Loss: 0.9711 | Attack_acc: 62.57%\n",
      "ID: 6 | Epoch: 13/15 | Loss: 0.8335 | Attack_acc: 66.59%\n",
      "ID: 6 | Epoch: 14/15 | Loss: 0.7519 | Attack_acc: 65.24%\n",
      "ID: 6 | Epoch: 15/15 | Loss: 0.5852 | Attack_acc: 70.34%\n",
      "Test loss: 2.5571 | Test Acc: 33.73% | Attack Acc: 69.64%\n",
      "training the target model uses:  18.237979888916016\n",
      "ID: 7 | Epoch: 1/15 | Loss: 2.1154 | Attack_acc: 50.04%\n",
      "ID: 7 | Epoch: 2/15 | Loss: 1.8705 | Attack_acc: 51.57%\n",
      "ID: 7 | Epoch: 3/15 | Loss: 1.7295 | Attack_acc: 51.21%\n",
      "ID: 7 | Epoch: 4/15 | Loss: 1.6604 | Attack_acc: 51.01%\n",
      "ID: 7 | Epoch: 5/15 | Loss: 1.5663 | Attack_acc: 53.63%\n",
      "ID: 7 | Epoch: 6/15 | Loss: 1.4677 | Attack_acc: 54.37%\n",
      "ID: 7 | Epoch: 7/15 | Loss: 1.3696 | Attack_acc: 57.34%\n",
      "ID: 7 | Epoch: 8/15 | Loss: 1.3062 | Attack_acc: 53.76%\n",
      "ID: 7 | Epoch: 9/15 | Loss: 1.2372 | Attack_acc: 58.95%\n",
      "ID: 7 | Epoch: 10/15 | Loss: 1.1057 | Attack_acc: 60.42%\n",
      "ID: 7 | Epoch: 11/15 | Loss: 1.0021 | Attack_acc: 67.38%\n",
      "ID: 7 | Epoch: 12/15 | Loss: 0.8645 | Attack_acc: 65.02%\n",
      "ID: 7 | Epoch: 13/15 | Loss: 0.8052 | Attack_acc: 67.24%\n",
      "ID: 7 | Epoch: 14/15 | Loss: 0.6827 | Attack_acc: 68.95%\n",
      "ID: 7 | Epoch: 15/15 | Loss: 0.5672 | Attack_acc: 71.73%\n",
      "Test loss: 2.9302 | Test Acc: 30.80% | Attack Acc: 67.73%\n",
      "training the target model uses:  18.228524208068848\n",
      "ID: 8 | Epoch: 1/15 | Loss: 2.0785 | Attack_acc: 53.23%\n",
      "ID: 8 | Epoch: 2/15 | Loss: 1.8441 | Attack_acc: 53.25%\n",
      "ID: 8 | Epoch: 3/15 | Loss: 1.7521 | Attack_acc: 54.10%\n",
      "ID: 8 | Epoch: 4/15 | Loss: 1.6407 | Attack_acc: 53.26%\n",
      "ID: 8 | Epoch: 5/15 | Loss: 1.5358 | Attack_acc: 55.80%\n",
      "ID: 8 | Epoch: 6/15 | Loss: 1.4712 | Attack_acc: 57.88%\n",
      "ID: 8 | Epoch: 7/15 | Loss: 1.4142 | Attack_acc: 56.13%\n",
      "ID: 8 | Epoch: 8/15 | Loss: 1.3470 | Attack_acc: 61.52%\n",
      "ID: 8 | Epoch: 9/15 | Loss: 1.2491 | Attack_acc: 60.73%\n",
      "ID: 8 | Epoch: 10/15 | Loss: 1.1513 | Attack_acc: 61.34%\n",
      "ID: 8 | Epoch: 11/15 | Loss: 1.0216 | Attack_acc: 61.95%\n",
      "ID: 8 | Epoch: 12/15 | Loss: 0.9286 | Attack_acc: 64.82%\n",
      "ID: 8 | Epoch: 13/15 | Loss: 0.8525 | Attack_acc: 62.64%\n",
      "ID: 8 | Epoch: 14/15 | Loss: 0.7347 | Attack_acc: 72.05%\n",
      "ID: 8 | Epoch: 15/15 | Loss: 0.6152 | Attack_acc: 68.74%\n",
      "Test loss: 2.6294 | Test Acc: 36.93% | Attack Acc: 67.40%\n",
      "training the target model uses:  18.482576847076416\n",
      "ID: 9 | Epoch: 1/15 | Loss: 2.0630 | Attack_acc: 50.80%\n",
      "ID: 9 | Epoch: 2/15 | Loss: 1.8227 | Attack_acc: 50.93%\n",
      "ID: 9 | Epoch: 3/15 | Loss: 1.7133 | Attack_acc: 52.04%\n",
      "ID: 9 | Epoch: 4/15 | Loss: 1.5718 | Attack_acc: 52.13%\n",
      "ID: 9 | Epoch: 5/15 | Loss: 1.5081 | Attack_acc: 54.17%\n",
      "ID: 9 | Epoch: 6/15 | Loss: 1.4014 | Attack_acc: 53.82%\n",
      "ID: 9 | Epoch: 7/15 | Loss: 1.2896 | Attack_acc: 56.03%\n",
      "ID: 9 | Epoch: 8/15 | Loss: 1.2096 | Attack_acc: 59.10%\n",
      "ID: 9 | Epoch: 9/15 | Loss: 1.1200 | Attack_acc: 56.55%\n",
      "ID: 9 | Epoch: 10/15 | Loss: 1.0023 | Attack_acc: 59.38%\n",
      "ID: 9 | Epoch: 11/15 | Loss: 0.8524 | Attack_acc: 65.59%\n",
      "ID: 9 | Epoch: 12/15 | Loss: 0.7653 | Attack_acc: 64.12%\n",
      "ID: 9 | Epoch: 13/15 | Loss: 0.6360 | Attack_acc: 69.01%\n",
      "ID: 9 | Epoch: 14/15 | Loss: 0.4526 | Attack_acc: 72.73%\n",
      "ID: 9 | Epoch: 15/15 | Loss: 0.3649 | Attack_acc: 64.60%\n",
      "Test loss: 3.8031 | Test Acc: 26.27% | Attack Acc: 65.65%\n",
      "training the target model uses:  18.738688230514526\n",
      "Global epoch 0: Test loss: 4.6661 | Test Acc: 12.27%\n",
      "Global Epoch:  1\n",
      "ID: 0 | Epoch: 1/15 | Loss: 1.7125 | Attack_acc: 52.45%\n",
      "ID: 0 | Epoch: 2/15 | Loss: 1.3876 | Attack_acc: 55.21%\n",
      "ID: 0 | Epoch: 3/15 | Loss: 1.1390 | Attack_acc: 59.37%\n",
      "ID: 0 | Epoch: 4/15 | Loss: 0.9473 | Attack_acc: 55.38%\n",
      "ID: 0 | Epoch: 5/15 | Loss: 0.7895 | Attack_acc: 66.40%\n",
      "ID: 0 | Epoch: 6/15 | Loss: 0.6505 | Attack_acc: 66.19%\n",
      "ID: 0 | Epoch: 7/15 | Loss: 0.4994 | Attack_acc: 70.47%\n",
      "ID: 0 | Epoch: 8/15 | Loss: 0.3935 | Attack_acc: 68.39%\n",
      "ID: 0 | Epoch: 9/15 | Loss: 0.2579 | Attack_acc: 83.74%\n",
      "ID: 0 | Epoch: 10/15 | Loss: 0.1540 | Attack_acc: 85.89%\n",
      "ID: 0 | Epoch: 11/15 | Loss: 0.0990 | Attack_acc: 87.42%\n",
      "ID: 0 | Epoch: 12/15 | Loss: 0.0556 | Attack_acc: 89.15%\n",
      "ID: 0 | Epoch: 13/15 | Loss: 0.0321 | Attack_acc: 89.91%\n",
      "ID: 0 | Epoch: 14/15 | Loss: 0.0283 | Attack_acc: 91.64%\n",
      "ID: 0 | Epoch: 15/15 | Loss: 0.0150 | Attack_acc: 94.34%\n",
      "Test loss: 2.2792 | Test Acc: 45.40% | Attack Acc: 86.40%\n",
      "training the target model uses:  19.14127206802368\n",
      "ID: 1 | Epoch: 1/15 | Loss: 1.7691 | Attack_acc: 52.34%\n",
      "ID: 1 | Epoch: 2/15 | Loss: 1.4010 | Attack_acc: 57.02%\n",
      "ID: 1 | Epoch: 3/15 | Loss: 1.1814 | Attack_acc: 57.77%\n",
      "ID: 1 | Epoch: 4/15 | Loss: 1.0391 | Attack_acc: 60.96%\n",
      "ID: 1 | Epoch: 5/15 | Loss: 0.8353 | Attack_acc: 66.31%\n",
      "ID: 1 | Epoch: 6/15 | Loss: 0.6497 | Attack_acc: 70.22%\n",
      "ID: 1 | Epoch: 7/15 | Loss: 0.4950 | Attack_acc: 68.13%\n",
      "ID: 1 | Epoch: 8/15 | Loss: 0.3624 | Attack_acc: 81.43%\n",
      "ID: 1 | Epoch: 9/15 | Loss: 0.2808 | Attack_acc: 78.92%\n",
      "ID: 1 | Epoch: 10/15 | Loss: 0.1779 | Attack_acc: 83.36%\n",
      "ID: 1 | Epoch: 11/15 | Loss: 0.1135 | Attack_acc: 84.97%\n",
      "ID: 1 | Epoch: 12/15 | Loss: 0.0628 | Attack_acc: 81.85%\n",
      "ID: 1 | Epoch: 13/15 | Loss: 0.0458 | Attack_acc: 90.78%\n",
      "ID: 1 | Epoch: 14/15 | Loss: 0.0214 | Attack_acc: 93.83%\n",
      "ID: 1 | Epoch: 15/15 | Loss: 0.0123 | Attack_acc: 93.48%\n",
      "Test loss: 1.9877 | Test Acc: 47.27% | Attack Acc: 88.85%\n",
      "training the target model uses:  17.77104640007019\n",
      "ID: 2 | Epoch: 1/15 | Loss: 1.7003 | Attack_acc: 54.38%\n",
      "ID: 2 | Epoch: 2/15 | Loss: 1.3466 | Attack_acc: 56.71%\n",
      "ID: 2 | Epoch: 3/15 | Loss: 1.1497 | Attack_acc: 57.08%\n",
      "ID: 2 | Epoch: 4/15 | Loss: 1.0144 | Attack_acc: 62.59%\n",
      "ID: 2 | Epoch: 5/15 | Loss: 0.7803 | Attack_acc: 60.15%\n",
      "ID: 2 | Epoch: 6/15 | Loss: 0.5895 | Attack_acc: 70.34%\n",
      "ID: 2 | Epoch: 7/15 | Loss: 0.4685 | Attack_acc: 69.80%\n",
      "ID: 2 | Epoch: 8/15 | Loss: 0.3512 | Attack_acc: 74.73%\n",
      "ID: 2 | Epoch: 9/15 | Loss: 0.2301 | Attack_acc: 76.79%\n",
      "ID: 2 | Epoch: 10/15 | Loss: 0.1462 | Attack_acc: 83.85%\n",
      "ID: 2 | Epoch: 11/15 | Loss: 0.0902 | Attack_acc: 87.53%\n",
      "ID: 2 | Epoch: 12/15 | Loss: 0.0472 | Attack_acc: 90.17%\n",
      "ID: 2 | Epoch: 13/15 | Loss: 0.0259 | Attack_acc: 91.76%\n",
      "ID: 2 | Epoch: 14/15 | Loss: 0.0148 | Attack_acc: 93.70%\n",
      "ID: 2 | Epoch: 15/15 | Loss: 0.0097 | Attack_acc: 93.84%\n",
      "Test loss: 1.9801 | Test Acc: 46.67% | Attack Acc: 88.08%\n",
      "training the target model uses:  18.09329605102539\n",
      "ID: 3 | Epoch: 1/15 | Loss: 1.7952 | Attack_acc: 52.62%\n",
      "ID: 3 | Epoch: 2/15 | Loss: 1.3415 | Attack_acc: 61.32%\n",
      "ID: 3 | Epoch: 3/15 | Loss: 1.1151 | Attack_acc: 61.77%\n",
      "ID: 3 | Epoch: 4/15 | Loss: 0.9610 | Attack_acc: 63.45%\n",
      "ID: 3 | Epoch: 5/15 | Loss: 0.7717 | Attack_acc: 68.63%\n",
      "ID: 3 | Epoch: 6/15 | Loss: 0.6440 | Attack_acc: 70.69%\n",
      "ID: 3 | Epoch: 7/15 | Loss: 0.4674 | Attack_acc: 73.48%\n",
      "ID: 3 | Epoch: 8/15 | Loss: 0.3468 | Attack_acc: 77.77%\n",
      "ID: 3 | Epoch: 9/15 | Loss: 0.2037 | Attack_acc: 81.59%\n",
      "ID: 3 | Epoch: 10/15 | Loss: 0.1161 | Attack_acc: 82.86%\n",
      "ID: 3 | Epoch: 11/15 | Loss: 0.0661 | Attack_acc: 82.94%\n",
      "ID: 3 | Epoch: 12/15 | Loss: 0.0431 | Attack_acc: 91.24%\n",
      "ID: 3 | Epoch: 13/15 | Loss: 0.0226 | Attack_acc: 94.13%\n",
      "ID: 3 | Epoch: 14/15 | Loss: 0.0163 | Attack_acc: 94.61%\n",
      "ID: 3 | Epoch: 15/15 | Loss: 0.0085 | Attack_acc: 95.89%\n",
      "Test loss: 2.4419 | Test Acc: 43.80% | Attack Acc: 86.84%\n",
      "training the target model uses:  18.169114112854004\n",
      "ID: 4 | Epoch: 1/15 | Loss: 1.8382 | Attack_acc: 53.46%\n",
      "ID: 4 | Epoch: 2/15 | Loss: 1.3970 | Attack_acc: 57.41%\n",
      "ID: 4 | Epoch: 3/15 | Loss: 1.1663 | Attack_acc: 60.40%\n",
      "ID: 4 | Epoch: 4/15 | Loss: 0.9707 | Attack_acc: 61.21%\n",
      "ID: 4 | Epoch: 5/15 | Loss: 0.7978 | Attack_acc: 63.45%\n",
      "ID: 4 | Epoch: 6/15 | Loss: 0.6638 | Attack_acc: 69.44%\n",
      "ID: 4 | Epoch: 7/15 | Loss: 0.4808 | Attack_acc: 70.44%\n",
      "ID: 4 | Epoch: 8/15 | Loss: 0.3132 | Attack_acc: 82.29%\n",
      "ID: 4 | Epoch: 9/15 | Loss: 0.2401 | Attack_acc: 78.23%\n",
      "ID: 4 | Epoch: 10/15 | Loss: 0.2018 | Attack_acc: 74.00%\n",
      "ID: 4 | Epoch: 11/15 | Loss: 0.1057 | Attack_acc: 86.54%\n",
      "ID: 4 | Epoch: 12/15 | Loss: 0.0596 | Attack_acc: 89.15%\n",
      "ID: 4 | Epoch: 13/15 | Loss: 0.0284 | Attack_acc: 90.29%\n",
      "ID: 4 | Epoch: 14/15 | Loss: 0.0171 | Attack_acc: 94.85%\n",
      "ID: 4 | Epoch: 15/15 | Loss: 0.0117 | Attack_acc: 94.73%\n",
      "Test loss: 2.1950 | Test Acc: 44.80% | Attack Acc: 89.16%\n",
      "training the target model uses:  18.032298803329468\n",
      "ID: 5 | Epoch: 1/15 | Loss: 1.8052 | Attack_acc: 54.47%\n",
      "ID: 5 | Epoch: 2/15 | Loss: 1.4388 | Attack_acc: 57.86%\n",
      "ID: 5 | Epoch: 3/15 | Loss: 1.2328 | Attack_acc: 57.71%\n",
      "ID: 5 | Epoch: 4/15 | Loss: 1.0545 | Attack_acc: 60.34%\n",
      "ID: 5 | Epoch: 5/15 | Loss: 0.8888 | Attack_acc: 59.95%\n",
      "ID: 5 | Epoch: 6/15 | Loss: 0.7620 | Attack_acc: 67.40%\n",
      "ID: 5 | Epoch: 7/15 | Loss: 0.6153 | Attack_acc: 73.22%\n",
      "ID: 5 | Epoch: 8/15 | Loss: 0.4162 | Attack_acc: 74.20%\n",
      "ID: 5 | Epoch: 9/15 | Loss: 0.3297 | Attack_acc: 68.83%\n",
      "ID: 5 | Epoch: 10/15 | Loss: 0.2352 | Attack_acc: 84.27%\n",
      "ID: 5 | Epoch: 11/15 | Loss: 0.1394 | Attack_acc: 81.13%\n",
      "ID: 5 | Epoch: 12/15 | Loss: 0.1069 | Attack_acc: 88.41%\n",
      "ID: 5 | Epoch: 13/15 | Loss: 0.0560 | Attack_acc: 88.56%\n",
      "ID: 5 | Epoch: 14/15 | Loss: 0.0436 | Attack_acc: 89.95%\n",
      "ID: 5 | Epoch: 15/15 | Loss: 0.0260 | Attack_acc: 86.40%\n",
      "Test loss: 3.2640 | Test Acc: 37.00% | Attack Acc: 79.32%\n",
      "training the target model uses:  17.993902444839478\n",
      "ID: 6 | Epoch: 1/15 | Loss: 1.7886 | Attack_acc: 53.48%\n",
      "ID: 6 | Epoch: 2/15 | Loss: 1.4413 | Attack_acc: 56.83%\n",
      "ID: 6 | Epoch: 3/15 | Loss: 1.2202 | Attack_acc: 56.83%\n",
      "ID: 6 | Epoch: 4/15 | Loss: 1.0296 | Attack_acc: 59.01%\n",
      "ID: 6 | Epoch: 5/15 | Loss: 0.8479 | Attack_acc: 60.17%\n",
      "ID: 6 | Epoch: 6/15 | Loss: 0.6918 | Attack_acc: 71.24%\n",
      "ID: 6 | Epoch: 7/15 | Loss: 0.5246 | Attack_acc: 62.54%\n",
      "ID: 6 | Epoch: 8/15 | Loss: 0.4267 | Attack_acc: 69.37%\n",
      "ID: 6 | Epoch: 9/15 | Loss: 0.3092 | Attack_acc: 72.64%\n",
      "ID: 6 | Epoch: 10/15 | Loss: 0.2163 | Attack_acc: 82.19%\n",
      "ID: 6 | Epoch: 11/15 | Loss: 0.1268 | Attack_acc: 87.23%\n",
      "ID: 6 | Epoch: 12/15 | Loss: 0.0608 | Attack_acc: 83.81%\n",
      "ID: 6 | Epoch: 13/15 | Loss: 0.0263 | Attack_acc: 93.27%\n",
      "ID: 6 | Epoch: 14/15 | Loss: 0.0157 | Attack_acc: 93.81%\n",
      "ID: 6 | Epoch: 15/15 | Loss: 0.0134 | Attack_acc: 94.67%\n",
      "Test loss: 2.6138 | Test Acc: 39.27% | Attack Acc: 86.74%\n",
      "training the target model uses:  18.07536816596985\n",
      "ID: 7 | Epoch: 1/15 | Loss: 1.7771 | Attack_acc: 53.09%\n",
      "ID: 7 | Epoch: 2/15 | Loss: 1.4314 | Attack_acc: 56.79%\n",
      "ID: 7 | Epoch: 3/15 | Loss: 1.2016 | Attack_acc: 56.99%\n",
      "ID: 7 | Epoch: 4/15 | Loss: 1.0053 | Attack_acc: 61.80%\n",
      "ID: 7 | Epoch: 5/15 | Loss: 0.8834 | Attack_acc: 62.97%\n",
      "ID: 7 | Epoch: 6/15 | Loss: 0.6841 | Attack_acc: 68.66%\n",
      "ID: 7 | Epoch: 7/15 | Loss: 0.5419 | Attack_acc: 63.02%\n",
      "ID: 7 | Epoch: 8/15 | Loss: 0.4015 | Attack_acc: 70.61%\n",
      "ID: 7 | Epoch: 9/15 | Loss: 0.2770 | Attack_acc: 78.12%\n",
      "ID: 7 | Epoch: 10/15 | Loss: 0.1600 | Attack_acc: 83.70%\n",
      "ID: 7 | Epoch: 11/15 | Loss: 0.0988 | Attack_acc: 83.29%\n",
      "ID: 7 | Epoch: 12/15 | Loss: 0.0723 | Attack_acc: 89.95%\n",
      "ID: 7 | Epoch: 13/15 | Loss: 0.0519 | Attack_acc: 89.34%\n",
      "ID: 7 | Epoch: 14/15 | Loss: 0.0304 | Attack_acc: 89.67%\n",
      "ID: 7 | Epoch: 15/15 | Loss: 0.0168 | Attack_acc: 92.77%\n",
      "Test loss: 2.1017 | Test Acc: 46.53% | Attack Acc: 87.04%\n",
      "training the target model uses:  18.542088985443115\n",
      "ID: 8 | Epoch: 1/15 | Loss: 1.6905 | Attack_acc: 53.56%\n",
      "ID: 8 | Epoch: 2/15 | Loss: 1.3579 | Attack_acc: 59.04%\n",
      "ID: 8 | Epoch: 3/15 | Loss: 1.0780 | Attack_acc: 59.40%\n",
      "ID: 8 | Epoch: 4/15 | Loss: 0.9519 | Attack_acc: 65.18%\n",
      "ID: 8 | Epoch: 5/15 | Loss: 0.8032 | Attack_acc: 64.62%\n",
      "ID: 8 | Epoch: 6/15 | Loss: 0.6650 | Attack_acc: 71.43%\n",
      "ID: 8 | Epoch: 7/15 | Loss: 0.4829 | Attack_acc: 69.77%\n",
      "ID: 8 | Epoch: 8/15 | Loss: 0.3368 | Attack_acc: 74.95%\n",
      "ID: 8 | Epoch: 9/15 | Loss: 0.2538 | Attack_acc: 74.80%\n",
      "ID: 8 | Epoch: 10/15 | Loss: 0.1687 | Attack_acc: 79.94%\n",
      "ID: 8 | Epoch: 11/15 | Loss: 0.1231 | Attack_acc: 84.10%\n",
      "ID: 8 | Epoch: 12/15 | Loss: 0.0775 | Attack_acc: 82.93%\n",
      "ID: 8 | Epoch: 13/15 | Loss: 0.0519 | Attack_acc: 85.24%\n",
      "ID: 8 | Epoch: 14/15 | Loss: 0.0316 | Attack_acc: 91.62%\n",
      "ID: 8 | Epoch: 15/15 | Loss: 0.0134 | Attack_acc: 93.83%\n",
      "Test loss: 2.4342 | Test Acc: 44.47% | Attack Acc: 83.79%\n",
      "training the target model uses:  18.57370901107788\n",
      "ID: 9 | Epoch: 1/15 | Loss: 1.7734 | Attack_acc: 52.03%\n",
      "ID: 9 | Epoch: 2/15 | Loss: 1.4100 | Attack_acc: 57.88%\n",
      "ID: 9 | Epoch: 3/15 | Loss: 1.1267 | Attack_acc: 60.93%\n",
      "ID: 9 | Epoch: 4/15 | Loss: 0.9686 | Attack_acc: 63.89%\n",
      "ID: 9 | Epoch: 5/15 | Loss: 0.8539 | Attack_acc: 67.47%\n",
      "ID: 9 | Epoch: 6/15 | Loss: 0.6626 | Attack_acc: 72.34%\n",
      "ID: 9 | Epoch: 7/15 | Loss: 0.4113 | Attack_acc: 70.93%\n",
      "ID: 9 | Epoch: 8/15 | Loss: 0.2814 | Attack_acc: 78.53%\n",
      "ID: 9 | Epoch: 9/15 | Loss: 0.2110 | Attack_acc: 83.51%\n",
      "ID: 9 | Epoch: 10/15 | Loss: 0.1377 | Attack_acc: 82.65%\n",
      "ID: 9 | Epoch: 11/15 | Loss: 0.0924 | Attack_acc: 89.82%\n",
      "ID: 9 | Epoch: 12/15 | Loss: 0.0480 | Attack_acc: 92.08%\n",
      "ID: 9 | Epoch: 13/15 | Loss: 0.0261 | Attack_acc: 93.65%\n",
      "ID: 9 | Epoch: 14/15 | Loss: 0.0191 | Attack_acc: 94.13%\n",
      "ID: 9 | Epoch: 15/15 | Loss: 0.0108 | Attack_acc: 95.32%\n",
      "Test loss: 2.5257 | Test Acc: 41.93% | Attack Acc: 88.60%\n",
      "training the target model uses:  18.482736825942993\n",
      "Global epoch 1: Test loss: 3.4387 | Test Acc: 36.00%\n",
      "Global Epoch:  2\n",
      "ID: 0 | Epoch: 1/15 | Loss: 1.5957 | Attack_acc: 56.44%\n",
      "ID: 0 | Epoch: 2/15 | Loss: 1.0238 | Attack_acc: 61.97%\n",
      "ID: 0 | Epoch: 3/15 | Loss: 0.7124 | Attack_acc: 69.08%\n",
      "ID: 0 | Epoch: 4/15 | Loss: 0.5310 | Attack_acc: 69.16%\n",
      "ID: 0 | Epoch: 5/15 | Loss: 0.3320 | Attack_acc: 72.92%\n",
      "ID: 0 | Epoch: 6/15 | Loss: 0.1705 | Attack_acc: 78.09%\n",
      "ID: 0 | Epoch: 7/15 | Loss: 0.0823 | Attack_acc: 88.46%\n",
      "ID: 0 | Epoch: 8/15 | Loss: 0.0519 | Attack_acc: 89.97%\n",
      "ID: 0 | Epoch: 9/15 | Loss: 0.0263 | Attack_acc: 91.30%\n",
      "ID: 0 | Epoch: 10/15 | Loss: 0.0172 | Attack_acc: 92.45%\n",
      "ID: 0 | Epoch: 11/15 | Loss: 0.0105 | Attack_acc: 93.17%\n",
      "ID: 0 | Epoch: 12/15 | Loss: 0.0091 | Attack_acc: 93.60%\n",
      "ID: 0 | Epoch: 13/15 | Loss: 0.0069 | Attack_acc: 93.82%\n",
      "ID: 0 | Epoch: 14/15 | Loss: 0.0067 | Attack_acc: 94.28%\n",
      "ID: 0 | Epoch: 15/15 | Loss: 0.0053 | Attack_acc: 94.23%\n",
      "Test loss: 2.2119 | Test Acc: 49.07% | Attack Acc: 84.72%\n",
      "training the target model uses:  18.65478754043579\n",
      "ID: 1 | Epoch: 1/15 | Loss: 1.5722 | Attack_acc: 53.66%\n",
      "ID: 1 | Epoch: 2/15 | Loss: 1.0739 | Attack_acc: 61.89%\n",
      "ID: 1 | Epoch: 3/15 | Loss: 0.7946 | Attack_acc: 61.21%\n",
      "ID: 1 | Epoch: 4/15 | Loss: 0.5682 | Attack_acc: 73.61%\n",
      "ID: 1 | Epoch: 5/15 | Loss: 0.3243 | Attack_acc: 70.22%\n",
      "ID: 1 | Epoch: 6/15 | Loss: 0.2643 | Attack_acc: 80.15%\n",
      "ID: 1 | Epoch: 7/15 | Loss: 0.1719 | Attack_acc: 77.80%\n",
      "ID: 1 | Epoch: 8/15 | Loss: 0.1061 | Attack_acc: 81.96%\n",
      "ID: 1 | Epoch: 9/15 | Loss: 0.0545 | Attack_acc: 89.24%\n",
      "ID: 1 | Epoch: 10/15 | Loss: 0.0224 | Attack_acc: 92.16%\n",
      "ID: 1 | Epoch: 11/15 | Loss: 0.0114 | Attack_acc: 93.10%\n",
      "ID: 1 | Epoch: 12/15 | Loss: 0.0094 | Attack_acc: 93.60%\n",
      "ID: 1 | Epoch: 13/15 | Loss: 0.0065 | Attack_acc: 94.30%\n",
      "ID: 1 | Epoch: 14/15 | Loss: 0.0055 | Attack_acc: 94.36%\n",
      "ID: 1 | Epoch: 15/15 | Loss: 0.0042 | Attack_acc: 94.73%\n",
      "Test loss: 2.2284 | Test Acc: 49.40% | Attack Acc: 87.29%\n",
      "training the target model uses:  18.525323629379272\n",
      "ID: 2 | Epoch: 1/15 | Loss: 1.5972 | Attack_acc: 55.52%\n",
      "ID: 2 | Epoch: 2/15 | Loss: 1.1012 | Attack_acc: 57.91%\n",
      "ID: 2 | Epoch: 3/15 | Loss: 0.7049 | Attack_acc: 68.68%\n",
      "ID: 2 | Epoch: 4/15 | Loss: 0.4645 | Attack_acc: 69.99%\n",
      "ID: 2 | Epoch: 5/15 | Loss: 0.2858 | Attack_acc: 75.80%\n",
      "ID: 2 | Epoch: 6/15 | Loss: 0.1806 | Attack_acc: 78.11%\n",
      "ID: 2 | Epoch: 7/15 | Loss: 0.1093 | Attack_acc: 83.87%\n",
      "ID: 2 | Epoch: 8/15 | Loss: 0.0585 | Attack_acc: 84.70%\n",
      "ID: 2 | Epoch: 9/15 | Loss: 0.0375 | Attack_acc: 90.74%\n",
      "ID: 2 | Epoch: 10/15 | Loss: 0.0214 | Attack_acc: 91.34%\n",
      "ID: 2 | Epoch: 11/15 | Loss: 0.0155 | Attack_acc: 91.32%\n",
      "ID: 2 | Epoch: 12/15 | Loss: 0.0110 | Attack_acc: 92.07%\n",
      "ID: 2 | Epoch: 13/15 | Loss: 0.0073 | Attack_acc: 93.25%\n",
      "ID: 2 | Epoch: 14/15 | Loss: 0.0052 | Attack_acc: 93.68%\n",
      "ID: 2 | Epoch: 15/15 | Loss: 0.0063 | Attack_acc: 92.65%\n",
      "Test loss: 2.3401 | Test Acc: 46.40% | Attack Acc: 86.81%\n",
      "training the target model uses:  17.935766458511353\n",
      "ID: 3 | Epoch: 1/15 | Loss: 1.6384 | Attack_acc: 53.75%\n",
      "ID: 3 | Epoch: 2/15 | Loss: 1.0495 | Attack_acc: 64.26%\n",
      "ID: 3 | Epoch: 3/15 | Loss: 0.7542 | Attack_acc: 67.87%\n",
      "ID: 3 | Epoch: 4/15 | Loss: 0.5648 | Attack_acc: 70.51%\n",
      "ID: 3 | Epoch: 5/15 | Loss: 0.4134 | Attack_acc: 76.54%\n",
      "ID: 3 | Epoch: 6/15 | Loss: 0.2063 | Attack_acc: 81.09%\n",
      "ID: 3 | Epoch: 7/15 | Loss: 0.1033 | Attack_acc: 84.91%\n",
      "ID: 3 | Epoch: 8/15 | Loss: 0.0441 | Attack_acc: 89.21%\n",
      "ID: 3 | Epoch: 9/15 | Loss: 0.0262 | Attack_acc: 91.43%\n",
      "ID: 3 | Epoch: 10/15 | Loss: 0.0177 | Attack_acc: 91.63%\n",
      "ID: 3 | Epoch: 11/15 | Loss: 0.0131 | Attack_acc: 92.61%\n",
      "ID: 3 | Epoch: 12/15 | Loss: 0.0095 | Attack_acc: 92.62%\n",
      "ID: 3 | Epoch: 13/15 | Loss: 0.0079 | Attack_acc: 93.67%\n",
      "ID: 3 | Epoch: 14/15 | Loss: 0.0046 | Attack_acc: 93.92%\n",
      "ID: 3 | Epoch: 15/15 | Loss: 0.0056 | Attack_acc: 94.37%\n",
      "Test loss: 3.2603 | Test Acc: 36.87% | Attack Acc: 80.49%\n",
      "training the target model uses:  18.12442660331726\n",
      "ID: 4 | Epoch: 1/15 | Loss: 1.5994 | Attack_acc: 55.93%\n",
      "ID: 4 | Epoch: 2/15 | Loss: 1.0818 | Attack_acc: 62.80%\n",
      "ID: 4 | Epoch: 3/15 | Loss: 0.7184 | Attack_acc: 69.02%\n",
      "ID: 4 | Epoch: 4/15 | Loss: 0.4670 | Attack_acc: 74.98%\n",
      "ID: 4 | Epoch: 5/15 | Loss: 0.3165 | Attack_acc: 71.81%\n",
      "ID: 4 | Epoch: 6/15 | Loss: 0.2132 | Attack_acc: 81.14%\n",
      "ID: 4 | Epoch: 7/15 | Loss: 0.1139 | Attack_acc: 84.02%\n",
      "ID: 4 | Epoch: 8/15 | Loss: 0.0611 | Attack_acc: 83.44%\n",
      "ID: 4 | Epoch: 9/15 | Loss: 0.0356 | Attack_acc: 86.63%\n",
      "ID: 4 | Epoch: 10/15 | Loss: 0.0157 | Attack_acc: 92.42%\n",
      "ID: 4 | Epoch: 11/15 | Loss: 0.0097 | Attack_acc: 92.73%\n",
      "ID: 4 | Epoch: 12/15 | Loss: 0.0077 | Attack_acc: 93.55%\n",
      "ID: 4 | Epoch: 13/15 | Loss: 0.0054 | Attack_acc: 93.81%\n",
      "ID: 4 | Epoch: 14/15 | Loss: 0.0053 | Attack_acc: 94.54%\n",
      "ID: 4 | Epoch: 15/15 | Loss: 0.0050 | Attack_acc: 94.37%\n",
      "Test loss: 2.6106 | Test Acc: 48.40% | Attack Acc: 84.08%\n",
      "training the target model uses:  17.69957423210144\n",
      "ID: 5 | Epoch: 1/15 | Loss: 1.6017 | Attack_acc: 56.34%\n",
      "ID: 5 | Epoch: 2/15 | Loss: 1.0381 | Attack_acc: 63.50%\n",
      "ID: 5 | Epoch: 3/15 | Loss: 0.7411 | Attack_acc: 68.77%\n",
      "ID: 5 | Epoch: 4/15 | Loss: 0.5247 | Attack_acc: 72.79%\n",
      "ID: 5 | Epoch: 5/15 | Loss: 0.3404 | Attack_acc: 78.48%\n",
      "ID: 5 | Epoch: 6/15 | Loss: 0.2309 | Attack_acc: 69.93%\n",
      "ID: 5 | Epoch: 7/15 | Loss: 0.1186 | Attack_acc: 82.54%\n",
      "ID: 5 | Epoch: 8/15 | Loss: 0.0609 | Attack_acc: 83.82%\n",
      "ID: 5 | Epoch: 9/15 | Loss: 0.0381 | Attack_acc: 89.48%\n",
      "ID: 5 | Epoch: 10/15 | Loss: 0.0217 | Attack_acc: 90.43%\n",
      "ID: 5 | Epoch: 11/15 | Loss: 0.0116 | Attack_acc: 91.83%\n",
      "ID: 5 | Epoch: 12/15 | Loss: 0.0079 | Attack_acc: 92.49%\n",
      "ID: 5 | Epoch: 13/15 | Loss: 0.0059 | Attack_acc: 92.72%\n",
      "ID: 5 | Epoch: 14/15 | Loss: 0.0071 | Attack_acc: 92.40%\n",
      "ID: 5 | Epoch: 15/15 | Loss: 0.0045 | Attack_acc: 93.09%\n",
      "Test loss: 2.0507 | Test Acc: 50.93% | Attack Acc: 89.72%\n",
      "training the target model uses:  17.910350561141968\n",
      "ID: 6 | Epoch: 1/15 | Loss: 1.6162 | Attack_acc: 56.93%\n",
      "ID: 6 | Epoch: 2/15 | Loss: 1.0382 | Attack_acc: 60.85%\n",
      "ID: 6 | Epoch: 3/15 | Loss: 0.7095 | Attack_acc: 68.78%\n",
      "ID: 6 | Epoch: 4/15 | Loss: 0.4805 | Attack_acc: 72.16%\n",
      "ID: 6 | Epoch: 5/15 | Loss: 0.3294 | Attack_acc: 77.41%\n",
      "ID: 6 | Epoch: 6/15 | Loss: 0.1727 | Attack_acc: 76.52%\n",
      "ID: 6 | Epoch: 7/15 | Loss: 0.1123 | Attack_acc: 83.91%\n",
      "ID: 6 | Epoch: 8/15 | Loss: 0.0616 | Attack_acc: 85.72%\n",
      "ID: 6 | Epoch: 9/15 | Loss: 0.0474 | Attack_acc: 86.39%\n",
      "ID: 6 | Epoch: 10/15 | Loss: 0.0237 | Attack_acc: 91.19%\n",
      "ID: 6 | Epoch: 11/15 | Loss: 0.0141 | Attack_acc: 92.31%\n",
      "ID: 6 | Epoch: 12/15 | Loss: 0.0081 | Attack_acc: 93.29%\n",
      "ID: 6 | Epoch: 13/15 | Loss: 0.0059 | Attack_acc: 94.10%\n",
      "ID: 6 | Epoch: 14/15 | Loss: 0.0051 | Attack_acc: 94.38%\n",
      "ID: 6 | Epoch: 15/15 | Loss: 0.0050 | Attack_acc: 94.27%\n",
      "Test loss: 2.6803 | Test Acc: 43.07% | Attack Acc: 83.62%\n",
      "training the target model uses:  17.745041847229004\n",
      "ID: 7 | Epoch: 1/15 | Loss: 1.6300 | Attack_acc: 56.20%\n",
      "ID: 7 | Epoch: 2/15 | Loss: 1.0445 | Attack_acc: 63.59%\n",
      "ID: 7 | Epoch: 3/15 | Loss: 0.7566 | Attack_acc: 65.88%\n",
      "ID: 7 | Epoch: 4/15 | Loss: 0.5168 | Attack_acc: 74.02%\n",
      "ID: 7 | Epoch: 5/15 | Loss: 0.3447 | Attack_acc: 74.15%\n",
      "ID: 7 | Epoch: 6/15 | Loss: 0.2041 | Attack_acc: 75.87%\n",
      "ID: 7 | Epoch: 7/15 | Loss: 0.1546 | Attack_acc: 80.93%\n",
      "ID: 7 | Epoch: 8/15 | Loss: 0.0708 | Attack_acc: 86.07%\n",
      "ID: 7 | Epoch: 9/15 | Loss: 0.0388 | Attack_acc: 90.46%\n",
      "ID: 7 | Epoch: 10/15 | Loss: 0.0213 | Attack_acc: 90.28%\n",
      "ID: 7 | Epoch: 11/15 | Loss: 0.0120 | Attack_acc: 92.78%\n",
      "ID: 7 | Epoch: 12/15 | Loss: 0.0073 | Attack_acc: 92.81%\n",
      "ID: 7 | Epoch: 13/15 | Loss: 0.0049 | Attack_acc: 93.81%\n",
      "ID: 7 | Epoch: 14/15 | Loss: 0.0055 | Attack_acc: 93.40%\n",
      "ID: 7 | Epoch: 15/15 | Loss: 0.0040 | Attack_acc: 93.57%\n",
      "Test loss: 2.4393 | Test Acc: 46.47% | Attack Acc: 83.25%\n",
      "training the target model uses:  17.83842658996582\n",
      "ID: 8 | Epoch: 1/15 | Loss: 1.5501 | Attack_acc: 56.82%\n",
      "ID: 8 | Epoch: 2/15 | Loss: 1.0302 | Attack_acc: 59.49%\n",
      "ID: 8 | Epoch: 3/15 | Loss: 0.7776 | Attack_acc: 60.65%\n",
      "ID: 8 | Epoch: 4/15 | Loss: 0.5576 | Attack_acc: 70.43%\n",
      "ID: 8 | Epoch: 5/15 | Loss: 0.3325 | Attack_acc: 73.82%\n",
      "ID: 8 | Epoch: 6/15 | Loss: 0.1995 | Attack_acc: 82.59%\n",
      "ID: 8 | Epoch: 7/15 | Loss: 0.1489 | Attack_acc: 75.54%\n",
      "ID: 8 | Epoch: 8/15 | Loss: 0.1255 | Attack_acc: 82.67%\n",
      "ID: 8 | Epoch: 9/15 | Loss: 0.0658 | Attack_acc: 83.33%\n",
      "ID: 8 | Epoch: 10/15 | Loss: 0.0346 | Attack_acc: 90.06%\n",
      "ID: 8 | Epoch: 11/15 | Loss: 0.0160 | Attack_acc: 93.51%\n",
      "ID: 8 | Epoch: 12/15 | Loss: 0.0094 | Attack_acc: 93.76%\n",
      "ID: 8 | Epoch: 13/15 | Loss: 0.0063 | Attack_acc: 94.54%\n",
      "ID: 8 | Epoch: 14/15 | Loss: 0.0057 | Attack_acc: 94.81%\n",
      "ID: 8 | Epoch: 15/15 | Loss: 0.0050 | Attack_acc: 95.04%\n",
      "Test loss: 2.2514 | Test Acc: 48.60% | Attack Acc: 88.94%\n",
      "training the target model uses:  18.95107126235962\n",
      "ID: 9 | Epoch: 1/15 | Loss: 1.6193 | Attack_acc: 54.65%\n",
      "ID: 9 | Epoch: 2/15 | Loss: 1.0588 | Attack_acc: 64.60%\n",
      "ID: 9 | Epoch: 3/15 | Loss: 0.7687 | Attack_acc: 64.44%\n",
      "ID: 9 | Epoch: 4/15 | Loss: 0.6133 | Attack_acc: 65.45%\n",
      "ID: 9 | Epoch: 5/15 | Loss: 0.4145 | Attack_acc: 69.03%\n",
      "ID: 9 | Epoch: 6/15 | Loss: 0.2377 | Attack_acc: 75.30%\n",
      "ID: 9 | Epoch: 7/15 | Loss: 0.1198 | Attack_acc: 84.73%\n",
      "ID: 9 | Epoch: 8/15 | Loss: 0.0511 | Attack_acc: 90.94%\n",
      "ID: 9 | Epoch: 9/15 | Loss: 0.0253 | Attack_acc: 91.73%\n",
      "ID: 9 | Epoch: 10/15 | Loss: 0.0179 | Attack_acc: 93.06%\n",
      "ID: 9 | Epoch: 11/15 | Loss: 0.0140 | Attack_acc: 93.08%\n",
      "ID: 9 | Epoch: 12/15 | Loss: 0.0092 | Attack_acc: 94.30%\n",
      "ID: 9 | Epoch: 13/15 | Loss: 0.0062 | Attack_acc: 94.30%\n",
      "ID: 9 | Epoch: 14/15 | Loss: 0.0054 | Attack_acc: 94.96%\n",
      "ID: 9 | Epoch: 15/15 | Loss: 0.0050 | Attack_acc: 95.10%\n",
      "Test loss: 2.0416 | Test Acc: 47.00% | Attack Acc: 89.33%\n",
      "training the target model uses:  18.756643533706665\n",
      "Global epoch 2: Test loss: 2.1774 | Test Acc: 52.93%\n",
      "Global Epoch:  3\n",
      "ID: 0 | Epoch: 1/15 | Loss: 1.3781 | Attack_acc: 55.46%\n",
      "ID: 0 | Epoch: 2/15 | Loss: 0.8419 | Attack_acc: 65.90%\n",
      "ID: 0 | Epoch: 3/15 | Loss: 0.4375 | Attack_acc: 65.78%\n",
      "ID: 0 | Epoch: 4/15 | Loss: 0.2748 | Attack_acc: 76.16%\n",
      "ID: 0 | Epoch: 5/15 | Loss: 0.1447 | Attack_acc: 81.81%\n",
      "ID: 0 | Epoch: 6/15 | Loss: 0.0702 | Attack_acc: 81.71%\n",
      "ID: 0 | Epoch: 7/15 | Loss: 0.0425 | Attack_acc: 88.43%\n",
      "ID: 0 | Epoch: 8/15 | Loss: 0.0219 | Attack_acc: 89.92%\n",
      "ID: 0 | Epoch: 9/15 | Loss: 0.0090 | Attack_acc: 92.16%\n",
      "ID: 0 | Epoch: 10/15 | Loss: 0.0066 | Attack_acc: 91.85%\n",
      "ID: 0 | Epoch: 11/15 | Loss: 0.0061 | Attack_acc: 92.05%\n",
      "ID: 0 | Epoch: 12/15 | Loss: 0.0046 | Attack_acc: 92.64%\n",
      "ID: 0 | Epoch: 13/15 | Loss: 0.0048 | Attack_acc: 92.99%\n",
      "ID: 0 | Epoch: 14/15 | Loss: 0.0041 | Attack_acc: 93.22%\n",
      "ID: 0 | Epoch: 15/15 | Loss: 0.0037 | Attack_acc: 93.39%\n",
      "Test loss: 2.0180 | Test Acc: 54.13% | Attack Acc: 85.40%\n",
      "training the target model uses:  19.802106142044067\n",
      "ID: 1 | Epoch: 1/15 | Loss: 1.3673 | Attack_acc: 57.14%\n",
      "ID: 1 | Epoch: 2/15 | Loss: 0.8240 | Attack_acc: 66.02%\n",
      "ID: 1 | Epoch: 3/15 | Loss: 0.5158 | Attack_acc: 73.14%\n",
      "ID: 1 | Epoch: 4/15 | Loss: 0.2820 | Attack_acc: 77.09%\n",
      "ID: 1 | Epoch: 5/15 | Loss: 0.1464 | Attack_acc: 79.92%\n",
      "ID: 1 | Epoch: 6/15 | Loss: 0.1146 | Attack_acc: 76.16%\n",
      "ID: 1 | Epoch: 7/15 | Loss: 0.1000 | Attack_acc: 84.40%\n",
      "ID: 1 | Epoch: 8/15 | Loss: 0.0749 | Attack_acc: 84.78%\n",
      "ID: 1 | Epoch: 9/15 | Loss: 0.0382 | Attack_acc: 90.03%\n",
      "ID: 1 | Epoch: 10/15 | Loss: 0.0165 | Attack_acc: 90.37%\n",
      "ID: 1 | Epoch: 11/15 | Loss: 0.0096 | Attack_acc: 93.34%\n",
      "ID: 1 | Epoch: 12/15 | Loss: 0.0052 | Attack_acc: 93.08%\n",
      "ID: 1 | Epoch: 13/15 | Loss: 0.0048 | Attack_acc: 93.54%\n",
      "ID: 1 | Epoch: 14/15 | Loss: 0.0037 | Attack_acc: 93.91%\n",
      "ID: 1 | Epoch: 15/15 | Loss: 0.0027 | Attack_acc: 93.89%\n",
      "Test loss: 2.3648 | Test Acc: 45.67% | Attack Acc: 86.13%\n",
      "training the target model uses:  18.57958149909973\n",
      "ID: 2 | Epoch: 1/15 | Loss: 1.4090 | Attack_acc: 57.47%\n",
      "ID: 2 | Epoch: 2/15 | Loss: 0.8172 | Attack_acc: 70.18%\n",
      "ID: 2 | Epoch: 3/15 | Loss: 0.4531 | Attack_acc: 67.75%\n",
      "ID: 2 | Epoch: 4/15 | Loss: 0.2553 | Attack_acc: 74.04%\n",
      "ID: 2 | Epoch: 5/15 | Loss: 0.1287 | Attack_acc: 83.43%\n",
      "ID: 2 | Epoch: 6/15 | Loss: 0.0849 | Attack_acc: 78.76%\n",
      "ID: 2 | Epoch: 7/15 | Loss: 0.0395 | Attack_acc: 85.27%\n",
      "ID: 2 | Epoch: 8/15 | Loss: 0.0250 | Attack_acc: 89.18%\n",
      "ID: 2 | Epoch: 9/15 | Loss: 0.0123 | Attack_acc: 90.25%\n",
      "ID: 2 | Epoch: 10/15 | Loss: 0.0082 | Attack_acc: 92.31%\n",
      "ID: 2 | Epoch: 11/15 | Loss: 0.0060 | Attack_acc: 91.98%\n",
      "ID: 2 | Epoch: 12/15 | Loss: 0.0054 | Attack_acc: 92.79%\n",
      "ID: 2 | Epoch: 13/15 | Loss: 0.0036 | Attack_acc: 93.02%\n",
      "ID: 2 | Epoch: 14/15 | Loss: 0.0043 | Attack_acc: 93.24%\n",
      "ID: 2 | Epoch: 15/15 | Loss: 0.0031 | Attack_acc: 93.35%\n",
      "Test loss: 2.1895 | Test Acc: 52.13% | Attack Acc: 85.48%\n",
      "training the target model uses:  19.042526483535767\n",
      "ID: 3 | Epoch: 1/15 | Loss: 1.4062 | Attack_acc: 57.57%\n",
      "ID: 3 | Epoch: 2/15 | Loss: 0.8411 | Attack_acc: 61.84%\n",
      "ID: 3 | Epoch: 3/15 | Loss: 0.5431 | Attack_acc: 69.92%\n",
      "ID: 3 | Epoch: 4/15 | Loss: 0.3798 | Attack_acc: 67.97%\n",
      "ID: 3 | Epoch: 5/15 | Loss: 0.1832 | Attack_acc: 81.33%\n",
      "ID: 3 | Epoch: 6/15 | Loss: 0.0942 | Attack_acc: 83.39%\n",
      "ID: 3 | Epoch: 7/15 | Loss: 0.0414 | Attack_acc: 87.88%\n",
      "ID: 3 | Epoch: 8/15 | Loss: 0.0188 | Attack_acc: 89.08%\n",
      "ID: 3 | Epoch: 9/15 | Loss: 0.0114 | Attack_acc: 90.95%\n",
      "ID: 3 | Epoch: 10/15 | Loss: 0.0072 | Attack_acc: 92.36%\n",
      "ID: 3 | Epoch: 11/15 | Loss: 0.0056 | Attack_acc: 92.15%\n",
      "ID: 3 | Epoch: 12/15 | Loss: 0.0063 | Attack_acc: 92.19%\n",
      "ID: 3 | Epoch: 13/15 | Loss: 0.0051 | Attack_acc: 92.51%\n",
      "ID: 3 | Epoch: 14/15 | Loss: 0.0038 | Attack_acc: 92.87%\n",
      "ID: 3 | Epoch: 15/15 | Loss: 0.0036 | Attack_acc: 92.86%\n",
      "Test loss: 2.4626 | Test Acc: 46.93% | Attack Acc: 85.28%\n",
      "training the target model uses:  18.660515785217285\n",
      "ID: 4 | Epoch: 1/15 | Loss: 1.4109 | Attack_acc: 58.83%\n",
      "ID: 4 | Epoch: 2/15 | Loss: 0.7844 | Attack_acc: 65.68%\n",
      "ID: 4 | Epoch: 3/15 | Loss: 0.4608 | Attack_acc: 74.75%\n",
      "ID: 4 | Epoch: 4/15 | Loss: 0.2510 | Attack_acc: 74.11%\n",
      "ID: 4 | Epoch: 5/15 | Loss: 0.1645 | Attack_acc: 79.34%\n",
      "ID: 4 | Epoch: 6/15 | Loss: 0.1054 | Attack_acc: 77.94%\n",
      "ID: 4 | Epoch: 7/15 | Loss: 0.0918 | Attack_acc: 79.86%\n",
      "ID: 4 | Epoch: 8/15 | Loss: 0.0445 | Attack_acc: 87.58%\n",
      "ID: 4 | Epoch: 9/15 | Loss: 0.0160 | Attack_acc: 90.88%\n",
      "ID: 4 | Epoch: 10/15 | Loss: 0.0101 | Attack_acc: 90.97%\n",
      "ID: 4 | Epoch: 11/15 | Loss: 0.0063 | Attack_acc: 91.85%\n",
      "ID: 4 | Epoch: 12/15 | Loss: 0.0057 | Attack_acc: 92.42%\n",
      "ID: 4 | Epoch: 13/15 | Loss: 0.0043 | Attack_acc: 92.88%\n",
      "ID: 4 | Epoch: 14/15 | Loss: 0.0032 | Attack_acc: 93.05%\n",
      "ID: 4 | Epoch: 15/15 | Loss: 0.0037 | Attack_acc: 92.86%\n",
      "Test loss: 2.5681 | Test Acc: 46.13% | Attack Acc: 82.54%\n",
      "training the target model uses:  18.597108602523804\n",
      "ID: 5 | Epoch: 1/15 | Loss: 1.4200 | Attack_acc: 60.70%\n",
      "ID: 5 | Epoch: 2/15 | Loss: 0.8471 | Attack_acc: 64.42%\n",
      "ID: 5 | Epoch: 3/15 | Loss: 0.5086 | Attack_acc: 71.20%\n",
      "ID: 5 | Epoch: 4/15 | Loss: 0.3188 | Attack_acc: 74.66%\n",
      "ID: 5 | Epoch: 5/15 | Loss: 0.1705 | Attack_acc: 77.39%\n",
      "ID: 5 | Epoch: 6/15 | Loss: 0.1044 | Attack_acc: 81.53%\n",
      "ID: 5 | Epoch: 7/15 | Loss: 0.0458 | Attack_acc: 85.16%\n",
      "ID: 5 | Epoch: 8/15 | Loss: 0.0253 | Attack_acc: 88.11%\n",
      "ID: 5 | Epoch: 9/15 | Loss: 0.0133 | Attack_acc: 88.61%\n",
      "ID: 5 | Epoch: 10/15 | Loss: 0.0093 | Attack_acc: 91.01%\n",
      "ID: 5 | Epoch: 11/15 | Loss: 0.0068 | Attack_acc: 91.60%\n",
      "ID: 5 | Epoch: 12/15 | Loss: 0.0054 | Attack_acc: 91.88%\n",
      "ID: 5 | Epoch: 13/15 | Loss: 0.0043 | Attack_acc: 91.74%\n",
      "ID: 5 | Epoch: 14/15 | Loss: 0.0046 | Attack_acc: 92.38%\n",
      "ID: 5 | Epoch: 15/15 | Loss: 0.0034 | Attack_acc: 92.54%\n",
      "Test loss: 2.2241 | Test Acc: 51.33% | Attack Acc: 85.27%\n",
      "training the target model uses:  18.438267469406128\n",
      "ID: 6 | Epoch: 1/15 | Loss: 1.3914 | Attack_acc: 59.09%\n",
      "ID: 6 | Epoch: 2/15 | Loss: 0.8269 | Attack_acc: 64.06%\n",
      "ID: 6 | Epoch: 3/15 | Loss: 0.4977 | Attack_acc: 69.86%\n",
      "ID: 6 | Epoch: 4/15 | Loss: 0.2788 | Attack_acc: 81.83%\n",
      "ID: 6 | Epoch: 5/15 | Loss: 0.1418 | Attack_acc: 82.46%\n",
      "ID: 6 | Epoch: 6/15 | Loss: 0.0776 | Attack_acc: 85.57%\n",
      "ID: 6 | Epoch: 7/15 | Loss: 0.0485 | Attack_acc: 85.87%\n",
      "ID: 6 | Epoch: 8/15 | Loss: 0.0305 | Attack_acc: 87.67%\n",
      "ID: 6 | Epoch: 9/15 | Loss: 0.0173 | Attack_acc: 91.27%\n",
      "ID: 6 | Epoch: 10/15 | Loss: 0.0099 | Attack_acc: 92.00%\n",
      "ID: 6 | Epoch: 11/15 | Loss: 0.0064 | Attack_acc: 92.59%\n",
      "ID: 6 | Epoch: 12/15 | Loss: 0.0051 | Attack_acc: 93.26%\n",
      "ID: 6 | Epoch: 13/15 | Loss: 0.0041 | Attack_acc: 93.15%\n",
      "ID: 6 | Epoch: 14/15 | Loss: 0.0041 | Attack_acc: 93.68%\n",
      "ID: 6 | Epoch: 15/15 | Loss: 0.0037 | Attack_acc: 93.85%\n",
      "Test loss: 2.3060 | Test Acc: 46.67% | Attack Acc: 88.40%\n",
      "training the target model uses:  18.569265604019165\n",
      "ID: 7 | Epoch: 1/15 | Loss: 1.4069 | Attack_acc: 58.13%\n",
      "ID: 7 | Epoch: 2/15 | Loss: 0.8474 | Attack_acc: 62.47%\n",
      "ID: 7 | Epoch: 3/15 | Loss: 0.4756 | Attack_acc: 73.62%\n",
      "ID: 7 | Epoch: 4/15 | Loss: 0.3128 | Attack_acc: 74.76%\n",
      "ID: 7 | Epoch: 5/15 | Loss: 0.2293 | Attack_acc: 77.51%\n",
      "ID: 7 | Epoch: 6/15 | Loss: 0.1785 | Attack_acc: 79.20%\n",
      "ID: 7 | Epoch: 7/15 | Loss: 0.1069 | Attack_acc: 81.60%\n",
      "ID: 7 | Epoch: 8/15 | Loss: 0.0594 | Attack_acc: 82.65%\n",
      "ID: 7 | Epoch: 9/15 | Loss: 0.0274 | Attack_acc: 90.18%\n",
      "ID: 7 | Epoch: 10/15 | Loss: 0.0098 | Attack_acc: 92.01%\n",
      "ID: 7 | Epoch: 11/15 | Loss: 0.0077 | Attack_acc: 92.11%\n",
      "ID: 7 | Epoch: 12/15 | Loss: 0.0046 | Attack_acc: 92.77%\n",
      "ID: 7 | Epoch: 13/15 | Loss: 0.0044 | Attack_acc: 93.08%\n",
      "ID: 7 | Epoch: 14/15 | Loss: 0.0038 | Attack_acc: 93.18%\n",
      "ID: 7 | Epoch: 15/15 | Loss: 0.0028 | Attack_acc: 93.44%\n",
      "Test loss: 2.2148 | Test Acc: 48.20% | Attack Acc: 85.41%\n",
      "training the target model uses:  18.815621376037598\n",
      "ID: 8 | Epoch: 1/15 | Loss: 1.3627 | Attack_acc: 58.97%\n",
      "ID: 8 | Epoch: 2/15 | Loss: 0.7842 | Attack_acc: 69.05%\n",
      "ID: 8 | Epoch: 3/15 | Loss: 0.4999 | Attack_acc: 67.92%\n",
      "ID: 8 | Epoch: 4/15 | Loss: 0.2844 | Attack_acc: 74.68%\n",
      "ID: 8 | Epoch: 5/15 | Loss: 0.1564 | Attack_acc: 80.62%\n",
      "ID: 8 | Epoch: 6/15 | Loss: 0.0637 | Attack_acc: 86.51%\n",
      "ID: 8 | Epoch: 7/15 | Loss: 0.0489 | Attack_acc: 88.13%\n",
      "ID: 8 | Epoch: 8/15 | Loss: 0.0226 | Attack_acc: 91.46%\n",
      "ID: 8 | Epoch: 9/15 | Loss: 0.0140 | Attack_acc: 91.70%\n",
      "ID: 8 | Epoch: 10/15 | Loss: 0.0107 | Attack_acc: 91.47%\n",
      "ID: 8 | Epoch: 11/15 | Loss: 0.0064 | Attack_acc: 93.10%\n",
      "ID: 8 | Epoch: 12/15 | Loss: 0.0059 | Attack_acc: 93.67%\n",
      "ID: 8 | Epoch: 13/15 | Loss: 0.0044 | Attack_acc: 93.65%\n",
      "ID: 8 | Epoch: 14/15 | Loss: 0.0056 | Attack_acc: 93.18%\n",
      "ID: 8 | Epoch: 15/15 | Loss: 0.0051 | Attack_acc: 93.94%\n",
      "Test loss: 1.9484 | Test Acc: 51.13% | Attack Acc: 88.30%\n",
      "training the target model uses:  18.390284538269043\n",
      "ID: 9 | Epoch: 1/15 | Loss: 1.4627 | Attack_acc: 55.82%\n",
      "ID: 9 | Epoch: 2/15 | Loss: 0.8861 | Attack_acc: 69.01%\n",
      "ID: 9 | Epoch: 3/15 | Loss: 0.5350 | Attack_acc: 64.64%\n",
      "ID: 9 | Epoch: 4/15 | Loss: 0.3536 | Attack_acc: 70.25%\n",
      "ID: 9 | Epoch: 5/15 | Loss: 0.2104 | Attack_acc: 79.12%\n",
      "ID: 9 | Epoch: 6/15 | Loss: 0.1162 | Attack_acc: 82.87%\n",
      "ID: 9 | Epoch: 7/15 | Loss: 0.0657 | Attack_acc: 86.46%\n",
      "ID: 9 | Epoch: 8/15 | Loss: 0.0257 | Attack_acc: 88.59%\n",
      "ID: 9 | Epoch: 9/15 | Loss: 0.0128 | Attack_acc: 90.82%\n",
      "ID: 9 | Epoch: 10/15 | Loss: 0.0082 | Attack_acc: 92.40%\n",
      "ID: 9 | Epoch: 11/15 | Loss: 0.0047 | Attack_acc: 92.96%\n",
      "ID: 9 | Epoch: 12/15 | Loss: 0.0059 | Attack_acc: 92.90%\n",
      "ID: 9 | Epoch: 13/15 | Loss: 0.0046 | Attack_acc: 93.06%\n",
      "ID: 9 | Epoch: 14/15 | Loss: 0.0031 | Attack_acc: 93.41%\n",
      "ID: 9 | Epoch: 15/15 | Loss: 0.0037 | Attack_acc: 93.76%\n",
      "Test loss: 2.4454 | Test Acc: 45.80% | Attack Acc: 83.54%\n",
      "training the target model uses:  18.563453435897827\n",
      "Global epoch 3: Test loss: 1.6441 | Test Acc: 58.67%\n",
      "Global Epoch:  4\n",
      "ID: 0 | Epoch: 1/15 | Loss: 1.2245 | Attack_acc: 59.11%\n",
      "ID: 0 | Epoch: 2/15 | Loss: 0.6157 | Attack_acc: 65.67%\n",
      "ID: 0 | Epoch: 3/15 | Loss: 0.2945 | Attack_acc: 78.60%\n",
      "ID: 0 | Epoch: 4/15 | Loss: 0.1566 | Attack_acc: 79.01%\n",
      "ID: 0 | Epoch: 5/15 | Loss: 0.0596 | Attack_acc: 86.37%\n",
      "ID: 0 | Epoch: 6/15 | Loss: 0.0255 | Attack_acc: 88.21%\n",
      "ID: 0 | Epoch: 7/15 | Loss: 0.0146 | Attack_acc: 90.00%\n",
      "ID: 0 | Epoch: 8/15 | Loss: 0.0099 | Attack_acc: 88.85%\n",
      "ID: 0 | Epoch: 9/15 | Loss: 0.0070 | Attack_acc: 91.14%\n",
      "ID: 0 | Epoch: 10/15 | Loss: 0.0043 | Attack_acc: 91.82%\n",
      "ID: 0 | Epoch: 11/15 | Loss: 0.0052 | Attack_acc: 91.84%\n",
      "ID: 0 | Epoch: 12/15 | Loss: 0.0038 | Attack_acc: 92.11%\n",
      "ID: 0 | Epoch: 13/15 | Loss: 0.0032 | Attack_acc: 92.51%\n",
      "ID: 0 | Epoch: 14/15 | Loss: 0.0030 | Attack_acc: 92.30%\n",
      "ID: 0 | Epoch: 15/15 | Loss: 0.0022 | Attack_acc: 92.50%\n",
      "Test loss: 1.9776 | Test Acc: 54.20% | Attack Acc: 84.73%\n",
      "training the target model uses:  19.872302532196045\n",
      "ID: 1 | Epoch: 1/15 | Loss: 1.2094 | Attack_acc: 59.09%\n",
      "ID: 1 | Epoch: 2/15 | Loss: 0.6044 | Attack_acc: 66.14%\n",
      "ID: 1 | Epoch: 3/15 | Loss: 0.2913 | Attack_acc: 77.01%\n",
      "ID: 1 | Epoch: 4/15 | Loss: 0.1733 | Attack_acc: 79.43%\n",
      "ID: 1 | Epoch: 5/15 | Loss: 0.0978 | Attack_acc: 83.48%\n",
      "ID: 1 | Epoch: 6/15 | Loss: 0.0581 | Attack_acc: 83.27%\n",
      "ID: 1 | Epoch: 7/15 | Loss: 0.0249 | Attack_acc: 90.24%\n",
      "ID: 1 | Epoch: 8/15 | Loss: 0.0123 | Attack_acc: 90.46%\n",
      "ID: 1 | Epoch: 9/15 | Loss: 0.0066 | Attack_acc: 91.68%\n",
      "ID: 1 | Epoch: 10/15 | Loss: 0.0047 | Attack_acc: 92.18%\n",
      "ID: 1 | Epoch: 11/15 | Loss: 0.0055 | Attack_acc: 92.65%\n",
      "ID: 1 | Epoch: 12/15 | Loss: 0.0032 | Attack_acc: 92.62%\n",
      "ID: 1 | Epoch: 13/15 | Loss: 0.0033 | Attack_acc: 92.48%\n",
      "ID: 1 | Epoch: 14/15 | Loss: 0.0027 | Attack_acc: 92.92%\n",
      "ID: 1 | Epoch: 15/15 | Loss: 0.0032 | Attack_acc: 93.09%\n",
      "Test loss: 2.8649 | Test Acc: 47.00% | Attack Acc: 81.40%\n",
      "training the target model uses:  18.905060529708862\n",
      "ID: 2 | Epoch: 1/15 | Loss: 1.1954 | Attack_acc: 59.55%\n",
      "ID: 2 | Epoch: 2/15 | Loss: 0.6532 | Attack_acc: 70.78%\n",
      "ID: 2 | Epoch: 3/15 | Loss: 0.3126 | Attack_acc: 69.35%\n",
      "ID: 2 | Epoch: 4/15 | Loss: 0.1609 | Attack_acc: 79.56%\n",
      "ID: 2 | Epoch: 5/15 | Loss: 0.0837 | Attack_acc: 81.94%\n",
      "ID: 2 | Epoch: 6/15 | Loss: 0.0512 | Attack_acc: 86.09%\n",
      "ID: 2 | Epoch: 7/15 | Loss: 0.0188 | Attack_acc: 89.23%\n",
      "ID: 2 | Epoch: 8/15 | Loss: 0.0111 | Attack_acc: 90.52%\n",
      "ID: 2 | Epoch: 9/15 | Loss: 0.0096 | Attack_acc: 90.87%\n",
      "ID: 2 | Epoch: 10/15 | Loss: 0.0087 | Attack_acc: 90.42%\n",
      "ID: 2 | Epoch: 11/15 | Loss: 0.0070 | Attack_acc: 91.07%\n",
      "ID: 2 | Epoch: 12/15 | Loss: 0.0038 | Attack_acc: 91.53%\n",
      "ID: 2 | Epoch: 13/15 | Loss: 0.0035 | Attack_acc: 91.90%\n",
      "ID: 2 | Epoch: 14/15 | Loss: 0.0028 | Attack_acc: 91.63%\n",
      "ID: 2 | Epoch: 15/15 | Loss: 0.0029 | Attack_acc: 92.14%\n",
      "Test loss: 2.0409 | Test Acc: 53.47% | Attack Acc: 86.20%\n",
      "training the target model uses:  18.38098120689392\n",
      "ID: 3 | Epoch: 1/15 | Loss: 1.1927 | Attack_acc: 58.07%\n",
      "ID: 3 | Epoch: 2/15 | Loss: 0.6735 | Attack_acc: 66.09%\n",
      "ID: 3 | Epoch: 3/15 | Loss: 0.3485 | Attack_acc: 63.78%\n",
      "ID: 3 | Epoch: 4/15 | Loss: 0.2179 | Attack_acc: 71.05%\n",
      "ID: 3 | Epoch: 5/15 | Loss: 0.1229 | Attack_acc: 79.98%\n",
      "ID: 3 | Epoch: 6/15 | Loss: 0.0638 | Attack_acc: 80.52%\n",
      "ID: 3 | Epoch: 7/15 | Loss: 0.0250 | Attack_acc: 88.65%\n",
      "ID: 3 | Epoch: 8/15 | Loss: 0.0155 | Attack_acc: 89.50%\n",
      "ID: 3 | Epoch: 9/15 | Loss: 0.0089 | Attack_acc: 90.54%\n",
      "ID: 3 | Epoch: 10/15 | Loss: 0.0062 | Attack_acc: 90.17%\n",
      "ID: 3 | Epoch: 11/15 | Loss: 0.0043 | Attack_acc: 90.76%\n",
      "ID: 3 | Epoch: 12/15 | Loss: 0.0038 | Attack_acc: 91.14%\n",
      "ID: 3 | Epoch: 13/15 | Loss: 0.0039 | Attack_acc: 91.09%\n",
      "ID: 3 | Epoch: 14/15 | Loss: 0.0029 | Attack_acc: 90.96%\n",
      "ID: 3 | Epoch: 15/15 | Loss: 0.0029 | Attack_acc: 91.39%\n",
      "Test loss: 2.0283 | Test Acc: 53.87% | Attack Acc: 86.02%\n",
      "training the target model uses:  18.376214742660522\n",
      "ID: 4 | Epoch: 1/15 | Loss: 1.2136 | Attack_acc: 61.62%\n",
      "ID: 4 | Epoch: 2/15 | Loss: 0.6137 | Attack_acc: 64.43%\n",
      "ID: 4 | Epoch: 3/15 | Loss: 0.2740 | Attack_acc: 74.48%\n",
      "ID: 4 | Epoch: 4/15 | Loss: 0.1144 | Attack_acc: 78.45%\n",
      "ID: 4 | Epoch: 5/15 | Loss: 0.0726 | Attack_acc: 78.73%\n",
      "ID: 4 | Epoch: 6/15 | Loss: 0.0377 | Attack_acc: 86.09%\n",
      "ID: 4 | Epoch: 7/15 | Loss: 0.0177 | Attack_acc: 89.80%\n",
      "ID: 4 | Epoch: 8/15 | Loss: 0.0118 | Attack_acc: 90.47%\n",
      "ID: 4 | Epoch: 9/15 | Loss: 0.0068 | Attack_acc: 91.19%\n",
      "ID: 4 | Epoch: 10/15 | Loss: 0.0059 | Attack_acc: 91.31%\n",
      "ID: 4 | Epoch: 11/15 | Loss: 0.0037 | Attack_acc: 91.84%\n",
      "ID: 4 | Epoch: 12/15 | Loss: 0.0033 | Attack_acc: 92.86%\n",
      "ID: 4 | Epoch: 13/15 | Loss: 0.0032 | Attack_acc: 92.46%\n",
      "ID: 4 | Epoch: 14/15 | Loss: 0.0026 | Attack_acc: 92.90%\n",
      "ID: 4 | Epoch: 15/15 | Loss: 0.0024 | Attack_acc: 93.05%\n",
      "Test loss: 2.0581 | Test Acc: 52.53% | Attack Acc: 85.91%\n",
      "training the target model uses:  18.21683430671692\n",
      "ID: 5 | Epoch: 1/15 | Loss: 1.1979 | Attack_acc: 63.21%\n",
      "ID: 5 | Epoch: 2/15 | Loss: 0.6112 | Attack_acc: 69.21%\n",
      "ID: 5 | Epoch: 3/15 | Loss: 0.3072 | Attack_acc: 74.68%\n",
      "ID: 5 | Epoch: 4/15 | Loss: 0.1993 | Attack_acc: 75.05%\n",
      "ID: 5 | Epoch: 5/15 | Loss: 0.1222 | Attack_acc: 82.28%\n",
      "ID: 5 | Epoch: 6/15 | Loss: 0.0740 | Attack_acc: 85.24%\n",
      "ID: 5 | Epoch: 7/15 | Loss: 0.0345 | Attack_acc: 85.69%\n",
      "ID: 5 | Epoch: 8/15 | Loss: 0.0161 | Attack_acc: 88.94%\n",
      "ID: 5 | Epoch: 9/15 | Loss: 0.0090 | Attack_acc: 89.22%\n",
      "ID: 5 | Epoch: 10/15 | Loss: 0.0085 | Attack_acc: 90.49%\n",
      "ID: 5 | Epoch: 11/15 | Loss: 0.0054 | Attack_acc: 90.91%\n",
      "ID: 5 | Epoch: 12/15 | Loss: 0.0037 | Attack_acc: 91.10%\n",
      "ID: 5 | Epoch: 13/15 | Loss: 0.0036 | Attack_acc: 91.45%\n",
      "ID: 5 | Epoch: 14/15 | Loss: 0.0029 | Attack_acc: 91.55%\n",
      "ID: 5 | Epoch: 15/15 | Loss: 0.0031 | Attack_acc: 91.72%\n",
      "Test loss: 2.4009 | Test Acc: 46.80% | Attack Acc: 82.44%\n",
      "training the target model uses:  17.78044033050537\n",
      "ID: 6 | Epoch: 1/15 | Loss: 1.2521 | Attack_acc: 57.84%\n",
      "ID: 6 | Epoch: 2/15 | Loss: 0.6904 | Attack_acc: 65.84%\n",
      "ID: 6 | Epoch: 3/15 | Loss: 0.3654 | Attack_acc: 73.26%\n",
      "ID: 6 | Epoch: 4/15 | Loss: 0.1694 | Attack_acc: 78.19%\n",
      "ID: 6 | Epoch: 5/15 | Loss: 0.0714 | Attack_acc: 84.64%\n",
      "ID: 6 | Epoch: 6/15 | Loss: 0.0327 | Attack_acc: 89.00%\n",
      "ID: 6 | Epoch: 7/15 | Loss: 0.0241 | Attack_acc: 88.48%\n",
      "ID: 6 | Epoch: 8/15 | Loss: 0.0186 | Attack_acc: 90.07%\n",
      "ID: 6 | Epoch: 9/15 | Loss: 0.0086 | Attack_acc: 91.12%\n",
      "ID: 6 | Epoch: 10/15 | Loss: 0.0075 | Attack_acc: 91.65%\n",
      "ID: 6 | Epoch: 11/15 | Loss: 0.0055 | Attack_acc: 92.04%\n",
      "ID: 6 | Epoch: 12/15 | Loss: 0.0041 | Attack_acc: 92.89%\n",
      "ID: 6 | Epoch: 13/15 | Loss: 0.0034 | Attack_acc: 92.88%\n",
      "ID: 6 | Epoch: 14/15 | Loss: 0.0032 | Attack_acc: 93.01%\n",
      "ID: 6 | Epoch: 15/15 | Loss: 0.0033 | Attack_acc: 93.08%\n",
      "Test loss: 2.7223 | Test Acc: 46.13% | Attack Acc: 81.76%\n",
      "training the target model uses:  18.10162091255188\n",
      "ID: 7 | Epoch: 1/15 | Loss: 1.2907 | Attack_acc: 60.87%\n",
      "ID: 7 | Epoch: 2/15 | Loss: 0.7157 | Attack_acc: 69.25%\n",
      "ID: 7 | Epoch: 3/15 | Loss: 0.3430 | Attack_acc: 72.09%\n",
      "ID: 7 | Epoch: 4/15 | Loss: 0.1579 | Attack_acc: 78.69%\n",
      "ID: 7 | Epoch: 5/15 | Loss: 0.0878 | Attack_acc: 85.11%\n",
      "ID: 7 | Epoch: 6/15 | Loss: 0.0378 | Attack_acc: 87.65%\n",
      "ID: 7 | Epoch: 7/15 | Loss: 0.0161 | Attack_acc: 89.53%\n",
      "ID: 7 | Epoch: 8/15 | Loss: 0.0164 | Attack_acc: 87.28%\n",
      "ID: 7 | Epoch: 9/15 | Loss: 0.0131 | Attack_acc: 89.34%\n",
      "ID: 7 | Epoch: 10/15 | Loss: 0.0078 | Attack_acc: 91.48%\n",
      "ID: 7 | Epoch: 11/15 | Loss: 0.0044 | Attack_acc: 91.51%\n",
      "ID: 7 | Epoch: 12/15 | Loss: 0.0034 | Attack_acc: 92.09%\n",
      "ID: 7 | Epoch: 13/15 | Loss: 0.0037 | Attack_acc: 92.59%\n",
      "ID: 7 | Epoch: 14/15 | Loss: 0.0032 | Attack_acc: 91.74%\n",
      "ID: 7 | Epoch: 15/15 | Loss: 0.0030 | Attack_acc: 92.38%\n",
      "Test loss: 2.3637 | Test Acc: 48.47% | Attack Acc: 83.64%\n",
      "training the target model uses:  18.03817319869995\n",
      "ID: 8 | Epoch: 1/15 | Loss: 1.2494 | Attack_acc: 59.79%\n",
      "ID: 8 | Epoch: 2/15 | Loss: 0.6583 | Attack_acc: 71.72%\n",
      "ID: 8 | Epoch: 3/15 | Loss: 0.2923 | Attack_acc: 78.93%\n",
      "ID: 8 | Epoch: 4/15 | Loss: 0.1689 | Attack_acc: 70.73%\n",
      "ID: 8 | Epoch: 5/15 | Loss: 0.0763 | Attack_acc: 85.39%\n",
      "ID: 8 | Epoch: 6/15 | Loss: 0.0469 | Attack_acc: 83.69%\n",
      "ID: 8 | Epoch: 7/15 | Loss: 0.0220 | Attack_acc: 88.44%\n",
      "ID: 8 | Epoch: 8/15 | Loss: 0.0119 | Attack_acc: 89.34%\n",
      "ID: 8 | Epoch: 9/15 | Loss: 0.0123 | Attack_acc: 91.54%\n",
      "ID: 8 | Epoch: 10/15 | Loss: 0.0060 | Attack_acc: 91.74%\n",
      "ID: 8 | Epoch: 11/15 | Loss: 0.0043 | Attack_acc: 92.32%\n",
      "ID: 8 | Epoch: 12/15 | Loss: 0.0052 | Attack_acc: 92.80%\n",
      "ID: 8 | Epoch: 13/15 | Loss: 0.0034 | Attack_acc: 92.68%\n",
      "ID: 8 | Epoch: 14/15 | Loss: 0.0029 | Attack_acc: 92.98%\n",
      "ID: 8 | Epoch: 15/15 | Loss: 0.0027 | Attack_acc: 93.09%\n",
      "Test loss: 2.4596 | Test Acc: 45.27% | Attack Acc: 83.57%\n",
      "training the target model uses:  18.09061312675476\n",
      "ID: 9 | Epoch: 1/15 | Loss: 1.2717 | Attack_acc: 57.26%\n",
      "ID: 9 | Epoch: 2/15 | Loss: 0.7122 | Attack_acc: 69.07%\n",
      "ID: 9 | Epoch: 3/15 | Loss: 0.3671 | Attack_acc: 71.24%\n",
      "ID: 9 | Epoch: 4/15 | Loss: 0.2266 | Attack_acc: 81.00%\n",
      "ID: 9 | Epoch: 5/15 | Loss: 0.1199 | Attack_acc: 78.96%\n",
      "ID: 9 | Epoch: 6/15 | Loss: 0.0600 | Attack_acc: 85.89%\n",
      "ID: 9 | Epoch: 7/15 | Loss: 0.0253 | Attack_acc: 88.40%\n",
      "ID: 9 | Epoch: 8/15 | Loss: 0.0125 | Attack_acc: 89.74%\n",
      "ID: 9 | Epoch: 9/15 | Loss: 0.0082 | Attack_acc: 91.04%\n",
      "ID: 9 | Epoch: 10/15 | Loss: 0.0063 | Attack_acc: 91.24%\n",
      "ID: 9 | Epoch: 11/15 | Loss: 0.0057 | Attack_acc: 91.79%\n",
      "ID: 9 | Epoch: 12/15 | Loss: 0.0047 | Attack_acc: 91.51%\n",
      "ID: 9 | Epoch: 13/15 | Loss: 0.0035 | Attack_acc: 92.29%\n",
      "ID: 9 | Epoch: 14/15 | Loss: 0.0030 | Attack_acc: 92.20%\n",
      "ID: 9 | Epoch: 15/15 | Loss: 0.0031 | Attack_acc: 92.60%\n",
      "Test loss: 2.3511 | Test Acc: 49.33% | Attack Acc: 84.10%\n",
      "training the target model uses:  18.50484800338745\n",
      "Global epoch 4: Test loss: 1.7097 | Test Acc: 61.20%\n",
      "Global Epoch:  5\n",
      "ID: 0 | Epoch: 1/15 | Loss: 1.1580 | Attack_acc: 60.50%\n",
      "ID: 0 | Epoch: 2/15 | Loss: 0.4985 | Attack_acc: 69.45%\n",
      "ID: 0 | Epoch: 3/15 | Loss: 0.2145 | Attack_acc: 72.60%\n",
      "ID: 0 | Epoch: 4/15 | Loss: 0.1076 | Attack_acc: 80.93%\n",
      "ID: 0 | Epoch: 5/15 | Loss: 0.0470 | Attack_acc: 85.14%\n",
      "ID: 0 | Epoch: 6/15 | Loss: 0.0242 | Attack_acc: 88.12%\n",
      "ID: 0 | Epoch: 7/15 | Loss: 0.0154 | Attack_acc: 88.39%\n",
      "ID: 0 | Epoch: 8/15 | Loss: 0.0078 | Attack_acc: 90.46%\n",
      "ID: 0 | Epoch: 9/15 | Loss: 0.0063 | Attack_acc: 91.20%\n",
      "ID: 0 | Epoch: 10/15 | Loss: 0.0055 | Attack_acc: 90.88%\n",
      "ID: 0 | Epoch: 11/15 | Loss: 0.0037 | Attack_acc: 91.74%\n",
      "ID: 0 | Epoch: 12/15 | Loss: 0.0031 | Attack_acc: 91.99%\n",
      "ID: 0 | Epoch: 13/15 | Loss: 0.0028 | Attack_acc: 91.92%\n",
      "ID: 0 | Epoch: 14/15 | Loss: 0.0026 | Attack_acc: 92.14%\n",
      "ID: 0 | Epoch: 15/15 | Loss: 0.0024 | Attack_acc: 92.43%\n",
      "Test loss: 1.8331 | Test Acc: 55.80% | Attack Acc: 89.01%\n",
      "training the target model uses:  19.249853134155273\n",
      "ID: 1 | Epoch: 1/15 | Loss: 1.1118 | Attack_acc: 62.21%\n",
      "ID: 1 | Epoch: 2/15 | Loss: 0.5592 | Attack_acc: 65.97%\n",
      "ID: 1 | Epoch: 3/15 | Loss: 0.2760 | Attack_acc: 73.03%\n",
      "ID: 1 | Epoch: 4/15 | Loss: 0.1194 | Attack_acc: 82.69%\n",
      "ID: 1 | Epoch: 5/15 | Loss: 0.0377 | Attack_acc: 86.65%\n",
      "ID: 1 | Epoch: 6/15 | Loss: 0.0173 | Attack_acc: 88.85%\n",
      "ID: 1 | Epoch: 7/15 | Loss: 0.0107 | Attack_acc: 89.24%\n",
      "ID: 1 | Epoch: 8/15 | Loss: 0.0055 | Attack_acc: 89.99%\n",
      "ID: 1 | Epoch: 9/15 | Loss: 0.0059 | Attack_acc: 90.87%\n",
      "ID: 1 | Epoch: 10/15 | Loss: 0.0050 | Attack_acc: 90.84%\n",
      "ID: 1 | Epoch: 11/15 | Loss: 0.0036 | Attack_acc: 91.28%\n",
      "ID: 1 | Epoch: 12/15 | Loss: 0.0029 | Attack_acc: 91.60%\n",
      "ID: 1 | Epoch: 13/15 | Loss: 0.0034 | Attack_acc: 92.04%\n",
      "ID: 1 | Epoch: 14/15 | Loss: 0.0032 | Attack_acc: 91.72%\n",
      "ID: 1 | Epoch: 15/15 | Loss: 0.0025 | Attack_acc: 91.88%\n",
      "Test loss: 1.9798 | Test Acc: 55.27% | Attack Acc: 85.03%\n",
      "training the target model uses:  17.868834495544434\n",
      "ID: 2 | Epoch: 1/15 | Loss: 1.1271 | Attack_acc: 60.26%\n",
      "ID: 2 | Epoch: 2/15 | Loss: 0.4924 | Attack_acc: 68.18%\n",
      "ID: 2 | Epoch: 3/15 | Loss: 0.2293 | Attack_acc: 73.27%\n",
      "ID: 2 | Epoch: 4/15 | Loss: 0.1083 | Attack_acc: 80.22%\n",
      "ID: 2 | Epoch: 5/15 | Loss: 0.0551 | Attack_acc: 83.89%\n",
      "ID: 2 | Epoch: 6/15 | Loss: 0.0276 | Attack_acc: 82.32%\n",
      "ID: 2 | Epoch: 7/15 | Loss: 0.0181 | Attack_acc: 88.06%\n",
      "ID: 2 | Epoch: 8/15 | Loss: 0.0093 | Attack_acc: 88.27%\n",
      "ID: 2 | Epoch: 9/15 | Loss: 0.0066 | Attack_acc: 88.61%\n",
      "ID: 2 | Epoch: 10/15 | Loss: 0.0052 | Attack_acc: 88.45%\n",
      "ID: 2 | Epoch: 11/15 | Loss: 0.0040 | Attack_acc: 89.27%\n",
      "ID: 2 | Epoch: 12/15 | Loss: 0.0036 | Attack_acc: 89.39%\n",
      "ID: 2 | Epoch: 13/15 | Loss: 0.0035 | Attack_acc: 89.85%\n",
      "ID: 2 | Epoch: 14/15 | Loss: 0.0030 | Attack_acc: 90.17%\n",
      "ID: 2 | Epoch: 15/15 | Loss: 0.0024 | Attack_acc: 90.34%\n",
      "Test loss: 2.0031 | Test Acc: 52.80% | Attack Acc: 84.42%\n",
      "training the target model uses:  17.994261741638184\n",
      "ID: 3 | Epoch: 1/15 | Loss: 1.1430 | Attack_acc: 60.42%\n",
      "ID: 3 | Epoch: 2/15 | Loss: 0.5188 | Attack_acc: 68.30%\n",
      "ID: 3 | Epoch: 3/15 | Loss: 0.2182 | Attack_acc: 76.46%\n",
      "ID: 3 | Epoch: 4/15 | Loss: 0.1075 | Attack_acc: 83.69%\n",
      "ID: 3 | Epoch: 5/15 | Loss: 0.0540 | Attack_acc: 84.35%\n",
      "ID: 3 | Epoch: 6/15 | Loss: 0.0365 | Attack_acc: 85.70%\n",
      "ID: 3 | Epoch: 7/15 | Loss: 0.0241 | Attack_acc: 86.94%\n",
      "ID: 3 | Epoch: 8/15 | Loss: 0.0098 | Attack_acc: 88.32%\n",
      "ID: 3 | Epoch: 9/15 | Loss: 0.0053 | Attack_acc: 89.96%\n",
      "ID: 3 | Epoch: 10/15 | Loss: 0.0053 | Attack_acc: 89.72%\n",
      "ID: 3 | Epoch: 11/15 | Loss: 0.0049 | Attack_acc: 90.22%\n",
      "ID: 3 | Epoch: 12/15 | Loss: 0.0033 | Attack_acc: 90.56%\n",
      "ID: 3 | Epoch: 13/15 | Loss: 0.0032 | Attack_acc: 90.95%\n",
      "ID: 3 | Epoch: 14/15 | Loss: 0.0045 | Attack_acc: 90.97%\n",
      "ID: 3 | Epoch: 15/15 | Loss: 0.0026 | Attack_acc: 90.94%\n",
      "Test loss: 2.1513 | Test Acc: 51.60% | Attack Acc: 85.96%\n",
      "training the target model uses:  18.266101360321045\n",
      "ID: 4 | Epoch: 1/15 | Loss: 1.0728 | Attack_acc: 59.13%\n",
      "ID: 4 | Epoch: 2/15 | Loss: 0.4423 | Attack_acc: 74.02%\n",
      "ID: 4 | Epoch: 3/15 | Loss: 0.2086 | Attack_acc: 77.61%\n",
      "ID: 4 | Epoch: 4/15 | Loss: 0.1000 | Attack_acc: 84.12%\n",
      "ID: 4 | Epoch: 5/15 | Loss: 0.0437 | Attack_acc: 83.53%\n",
      "ID: 4 | Epoch: 6/15 | Loss: 0.0189 | Attack_acc: 88.84%\n",
      "ID: 4 | Epoch: 7/15 | Loss: 0.0110 | Attack_acc: 90.37%\n",
      "ID: 4 | Epoch: 8/15 | Loss: 0.0073 | Attack_acc: 90.49%\n",
      "ID: 4 | Epoch: 9/15 | Loss: 0.0052 | Attack_acc: 91.14%\n",
      "ID: 4 | Epoch: 10/15 | Loss: 0.0045 | Attack_acc: 91.45%\n",
      "ID: 4 | Epoch: 11/15 | Loss: 0.0038 | Attack_acc: 91.41%\n",
      "ID: 4 | Epoch: 12/15 | Loss: 0.0035 | Attack_acc: 91.64%\n",
      "ID: 4 | Epoch: 13/15 | Loss: 0.0025 | Attack_acc: 91.87%\n",
      "ID: 4 | Epoch: 14/15 | Loss: 0.0029 | Attack_acc: 91.76%\n",
      "ID: 4 | Epoch: 15/15 | Loss: 0.0033 | Attack_acc: 91.99%\n",
      "Test loss: 2.6108 | Test Acc: 48.20% | Attack Acc: 82.72%\n",
      "training the target model uses:  18.3441219329834\n",
      "ID: 5 | Epoch: 1/15 | Loss: 1.1325 | Attack_acc: 59.01%\n",
      "ID: 5 | Epoch: 2/15 | Loss: 0.5632 | Attack_acc: 69.95%\n",
      "ID: 5 | Epoch: 3/15 | Loss: 0.2275 | Attack_acc: 70.78%\n",
      "ID: 5 | Epoch: 4/15 | Loss: 0.0971 | Attack_acc: 80.92%\n",
      "ID: 5 | Epoch: 5/15 | Loss: 0.0737 | Attack_acc: 84.16%\n",
      "ID: 5 | Epoch: 6/15 | Loss: 0.0327 | Attack_acc: 84.71%\n",
      "ID: 5 | Epoch: 7/15 | Loss: 0.0119 | Attack_acc: 87.59%\n",
      "ID: 5 | Epoch: 8/15 | Loss: 0.0086 | Attack_acc: 88.85%\n",
      "ID: 5 | Epoch: 9/15 | Loss: 0.0071 | Attack_acc: 89.32%\n",
      "ID: 5 | Epoch: 10/15 | Loss: 0.0052 | Attack_acc: 89.35%\n",
      "ID: 5 | Epoch: 11/15 | Loss: 0.0039 | Attack_acc: 90.19%\n",
      "ID: 5 | Epoch: 12/15 | Loss: 0.0031 | Attack_acc: 90.58%\n",
      "ID: 5 | Epoch: 13/15 | Loss: 0.0032 | Attack_acc: 90.75%\n",
      "ID: 5 | Epoch: 14/15 | Loss: 0.0025 | Attack_acc: 90.93%\n",
      "ID: 5 | Epoch: 15/15 | Loss: 0.0033 | Attack_acc: 91.02%\n",
      "Test loss: 2.1987 | Test Acc: 49.33% | Attack Acc: 83.42%\n",
      "training the target model uses:  17.99577236175537\n",
      "ID: 6 | Epoch: 1/15 | Loss: 1.1313 | Attack_acc: 61.31%\n",
      "ID: 6 | Epoch: 2/15 | Loss: 0.5083 | Attack_acc: 68.78%\n",
      "ID: 6 | Epoch: 3/15 | Loss: 0.2371 | Attack_acc: 71.77%\n",
      "ID: 6 | Epoch: 4/15 | Loss: 0.1098 | Attack_acc: 78.23%\n",
      "ID: 6 | Epoch: 5/15 | Loss: 0.0778 | Attack_acc: 83.91%\n",
      "ID: 6 | Epoch: 6/15 | Loss: 0.0421 | Attack_acc: 83.87%\n",
      "ID: 6 | Epoch: 7/15 | Loss: 0.0146 | Attack_acc: 89.78%\n",
      "ID: 6 | Epoch: 8/15 | Loss: 0.0078 | Attack_acc: 90.38%\n",
      "ID: 6 | Epoch: 9/15 | Loss: 0.0078 | Attack_acc: 90.81%\n",
      "ID: 6 | Epoch: 10/15 | Loss: 0.0045 | Attack_acc: 91.43%\n",
      "ID: 6 | Epoch: 11/15 | Loss: 0.0038 | Attack_acc: 91.91%\n",
      "ID: 6 | Epoch: 12/15 | Loss: 0.0034 | Attack_acc: 92.18%\n",
      "ID: 6 | Epoch: 13/15 | Loss: 0.0028 | Attack_acc: 92.17%\n",
      "ID: 6 | Epoch: 14/15 | Loss: 0.0030 | Attack_acc: 92.34%\n",
      "ID: 6 | Epoch: 15/15 | Loss: 0.0026 | Attack_acc: 92.35%\n",
      "Test loss: 3.0311 | Test Acc: 44.00% | Attack Acc: 79.90%\n",
      "training the target model uses:  17.78039312362671\n",
      "ID: 7 | Epoch: 1/15 | Loss: 1.1749 | Attack_acc: 62.10%\n",
      "ID: 7 | Epoch: 2/15 | Loss: 0.5516 | Attack_acc: 68.50%\n",
      "ID: 7 | Epoch: 3/15 | Loss: 0.2472 | Attack_acc: 72.44%\n",
      "ID: 7 | Epoch: 4/15 | Loss: 0.1141 | Attack_acc: 76.99%\n",
      "ID: 7 | Epoch: 5/15 | Loss: 0.0645 | Attack_acc: 83.96%\n",
      "ID: 7 | Epoch: 6/15 | Loss: 0.0410 | Attack_acc: 84.40%\n",
      "ID: 7 | Epoch: 7/15 | Loss: 0.0188 | Attack_acc: 87.79%\n",
      "ID: 7 | Epoch: 8/15 | Loss: 0.0126 | Attack_acc: 88.58%\n",
      "ID: 7 | Epoch: 9/15 | Loss: 0.0113 | Attack_acc: 88.40%\n",
      "ID: 7 | Epoch: 10/15 | Loss: 0.0060 | Attack_acc: 90.00%\n",
      "ID: 7 | Epoch: 11/15 | Loss: 0.0044 | Attack_acc: 90.60%\n",
      "ID: 7 | Epoch: 12/15 | Loss: 0.0033 | Attack_acc: 90.99%\n",
      "ID: 7 | Epoch: 13/15 | Loss: 0.0026 | Attack_acc: 91.51%\n",
      "ID: 7 | Epoch: 14/15 | Loss: 0.0033 | Attack_acc: 91.50%\n",
      "ID: 7 | Epoch: 15/15 | Loss: 0.0020 | Attack_acc: 91.74%\n",
      "Test loss: 2.0171 | Test Acc: 52.73% | Attack Acc: 85.98%\n",
      "training the target model uses:  18.668461561203003\n",
      "ID: 8 | Epoch: 1/15 | Loss: 1.1387 | Attack_acc: 64.87%\n",
      "ID: 8 | Epoch: 2/15 | Loss: 0.5193 | Attack_acc: 72.10%\n",
      "ID: 8 | Epoch: 3/15 | Loss: 0.2423 | Attack_acc: 73.47%\n",
      "ID: 8 | Epoch: 4/15 | Loss: 0.1577 | Attack_acc: 79.53%\n",
      "ID: 8 | Epoch: 5/15 | Loss: 0.0697 | Attack_acc: 86.18%\n",
      "ID: 8 | Epoch: 6/15 | Loss: 0.0444 | Attack_acc: 83.75%\n",
      "ID: 8 | Epoch: 7/15 | Loss: 0.0194 | Attack_acc: 88.96%\n",
      "ID: 8 | Epoch: 8/15 | Loss: 0.0114 | Attack_acc: 91.13%\n",
      "ID: 8 | Epoch: 9/15 | Loss: 0.0082 | Attack_acc: 91.49%\n",
      "ID: 8 | Epoch: 10/15 | Loss: 0.0048 | Attack_acc: 92.30%\n",
      "ID: 8 | Epoch: 11/15 | Loss: 0.0040 | Attack_acc: 92.27%\n",
      "ID: 8 | Epoch: 12/15 | Loss: 0.0031 | Attack_acc: 92.29%\n",
      "ID: 8 | Epoch: 13/15 | Loss: 0.0029 | Attack_acc: 93.03%\n",
      "ID: 8 | Epoch: 14/15 | Loss: 0.0027 | Attack_acc: 92.76%\n",
      "ID: 8 | Epoch: 15/15 | Loss: 0.0022 | Attack_acc: 92.91%\n",
      "Test loss: 2.0872 | Test Acc: 52.33% | Attack Acc: 88.47%\n",
      "training the target model uses:  17.906073570251465\n",
      "ID: 9 | Epoch: 1/15 | Loss: 1.1368 | Attack_acc: 61.33%\n",
      "ID: 9 | Epoch: 2/15 | Loss: 0.5264 | Attack_acc: 67.99%\n",
      "ID: 9 | Epoch: 3/15 | Loss: 0.2492 | Attack_acc: 76.35%\n",
      "ID: 9 | Epoch: 4/15 | Loss: 0.1090 | Attack_acc: 80.26%\n",
      "ID: 9 | Epoch: 5/15 | Loss: 0.0497 | Attack_acc: 84.29%\n",
      "ID: 9 | Epoch: 6/15 | Loss: 0.0269 | Attack_acc: 88.79%\n",
      "ID: 9 | Epoch: 7/15 | Loss: 0.0144 | Attack_acc: 89.13%\n",
      "ID: 9 | Epoch: 8/15 | Loss: 0.0086 | Attack_acc: 90.29%\n",
      "ID: 9 | Epoch: 9/15 | Loss: 0.0089 | Attack_acc: 90.65%\n",
      "ID: 9 | Epoch: 10/15 | Loss: 0.0055 | Attack_acc: 91.46%\n",
      "ID: 9 | Epoch: 11/15 | Loss: 0.0047 | Attack_acc: 91.24%\n",
      "ID: 9 | Epoch: 12/15 | Loss: 0.0043 | Attack_acc: 91.88%\n",
      "ID: 9 | Epoch: 13/15 | Loss: 0.0027 | Attack_acc: 91.86%\n",
      "ID: 9 | Epoch: 14/15 | Loss: 0.0036 | Attack_acc: 92.18%\n",
      "ID: 9 | Epoch: 15/15 | Loss: 0.0029 | Attack_acc: 92.24%\n",
      "Test loss: 2.0702 | Test Acc: 51.60% | Attack Acc: 86.74%\n",
      "training the target model uses:  17.658772230148315\n",
      "Global epoch 5: Test loss: 1.3921 | Test Acc: 65.00%\n",
      "Global Epoch:  6\n",
      "ID: 0 | Epoch: 1/15 | Loss: 0.9455 | Attack_acc: 60.73%\n",
      "ID: 0 | Epoch: 2/15 | Loss: 0.3845 | Attack_acc: 73.66%\n",
      "ID: 0 | Epoch: 3/15 | Loss: 0.1523 | Attack_acc: 78.53%\n",
      "ID: 0 | Epoch: 4/15 | Loss: 0.0684 | Attack_acc: 82.89%\n",
      "ID: 0 | Epoch: 5/15 | Loss: 0.0366 | Attack_acc: 78.23%\n",
      "ID: 0 | Epoch: 6/15 | Loss: 0.0206 | Attack_acc: 86.37%\n",
      "ID: 0 | Epoch: 7/15 | Loss: 0.0106 | Attack_acc: 89.01%\n",
      "ID: 0 | Epoch: 8/15 | Loss: 0.0077 | Attack_acc: 89.24%\n",
      "ID: 0 | Epoch: 9/15 | Loss: 0.0052 | Attack_acc: 90.46%\n",
      "ID: 0 | Epoch: 10/15 | Loss: 0.0050 | Attack_acc: 91.34%\n",
      "ID: 0 | Epoch: 11/15 | Loss: 0.0040 | Attack_acc: 91.44%\n",
      "ID: 0 | Epoch: 12/15 | Loss: 0.0029 | Attack_acc: 91.23%\n",
      "ID: 0 | Epoch: 13/15 | Loss: 0.0025 | Attack_acc: 91.89%\n",
      "ID: 0 | Epoch: 14/15 | Loss: 0.0022 | Attack_acc: 91.84%\n",
      "ID: 0 | Epoch: 15/15 | Loss: 0.0030 | Attack_acc: 91.28%\n",
      "Test loss: 1.9811 | Test Acc: 57.93% | Attack Acc: 84.09%\n",
      "training the target model uses:  19.016490936279297\n",
      "ID: 1 | Epoch: 1/15 | Loss: 1.0637 | Attack_acc: 61.69%\n",
      "ID: 1 | Epoch: 2/15 | Loss: 0.5258 | Attack_acc: 70.93%\n",
      "ID: 1 | Epoch: 3/15 | Loss: 0.1955 | Attack_acc: 73.37%\n",
      "ID: 1 | Epoch: 4/15 | Loss: 0.0748 | Attack_acc: 83.91%\n",
      "ID: 1 | Epoch: 5/15 | Loss: 0.0216 | Attack_acc: 87.90%\n",
      "ID: 1 | Epoch: 6/15 | Loss: 0.0157 | Attack_acc: 89.02%\n",
      "ID: 1 | Epoch: 7/15 | Loss: 0.0092 | Attack_acc: 89.92%\n",
      "ID: 1 | Epoch: 8/15 | Loss: 0.0069 | Attack_acc: 90.39%\n",
      "ID: 1 | Epoch: 9/15 | Loss: 0.0064 | Attack_acc: 90.90%\n",
      "ID: 1 | Epoch: 10/15 | Loss: 0.0043 | Attack_acc: 91.34%\n",
      "ID: 1 | Epoch: 11/15 | Loss: 0.0036 | Attack_acc: 91.65%\n",
      "ID: 1 | Epoch: 12/15 | Loss: 0.0029 | Attack_acc: 92.03%\n",
      "ID: 1 | Epoch: 13/15 | Loss: 0.0026 | Attack_acc: 92.19%\n",
      "ID: 1 | Epoch: 14/15 | Loss: 0.0024 | Attack_acc: 92.40%\n",
      "ID: 1 | Epoch: 15/15 | Loss: 0.0021 | Attack_acc: 92.77%\n",
      "Test loss: 2.2401 | Test Acc: 49.47% | Attack Acc: 84.24%\n",
      "training the target model uses:  18.164942502975464\n",
      "ID: 2 | Epoch: 1/15 | Loss: 1.0052 | Attack_acc: 64.66%\n",
      "ID: 2 | Epoch: 2/15 | Loss: 0.4073 | Attack_acc: 74.01%\n",
      "ID: 2 | Epoch: 3/15 | Loss: 0.1829 | Attack_acc: 76.97%\n",
      "ID: 2 | Epoch: 4/15 | Loss: 0.0860 | Attack_acc: 79.94%\n",
      "ID: 2 | Epoch: 5/15 | Loss: 0.0414 | Attack_acc: 85.49%\n",
      "ID: 2 | Epoch: 6/15 | Loss: 0.0189 | Attack_acc: 87.36%\n",
      "ID: 2 | Epoch: 7/15 | Loss: 0.0105 | Attack_acc: 87.95%\n",
      "ID: 2 | Epoch: 8/15 | Loss: 0.0084 | Attack_acc: 88.53%\n",
      "ID: 2 | Epoch: 9/15 | Loss: 0.0047 | Attack_acc: 89.09%\n",
      "ID: 2 | Epoch: 10/15 | Loss: 0.0038 | Attack_acc: 89.67%\n",
      "ID: 2 | Epoch: 11/15 | Loss: 0.0031 | Attack_acc: 89.81%\n",
      "ID: 2 | Epoch: 12/15 | Loss: 0.0029 | Attack_acc: 89.85%\n",
      "ID: 2 | Epoch: 13/15 | Loss: 0.0027 | Attack_acc: 90.08%\n",
      "ID: 2 | Epoch: 14/15 | Loss: 0.0024 | Attack_acc: 90.23%\n",
      "ID: 2 | Epoch: 15/15 | Loss: 0.0025 | Attack_acc: 90.36%\n",
      "Test loss: 2.3085 | Test Acc: 54.20% | Attack Acc: 82.31%\n",
      "training the target model uses:  18.600892782211304\n",
      "ID: 3 | Epoch: 1/15 | Loss: 1.0167 | Attack_acc: 63.48%\n",
      "ID: 3 | Epoch: 2/15 | Loss: 0.3866 | Attack_acc: 66.77%\n",
      "ID: 3 | Epoch: 3/15 | Loss: 0.1364 | Attack_acc: 78.63%\n",
      "ID: 3 | Epoch: 4/15 | Loss: 0.0700 | Attack_acc: 81.89%\n",
      "ID: 3 | Epoch: 5/15 | Loss: 0.0335 | Attack_acc: 83.59%\n",
      "ID: 3 | Epoch: 6/15 | Loss: 0.0166 | Attack_acc: 86.54%\n",
      "ID: 3 | Epoch: 7/15 | Loss: 0.0100 | Attack_acc: 87.38%\n",
      "ID: 3 | Epoch: 8/15 | Loss: 0.0066 | Attack_acc: 88.63%\n",
      "ID: 3 | Epoch: 9/15 | Loss: 0.0042 | Attack_acc: 88.99%\n",
      "ID: 3 | Epoch: 10/15 | Loss: 0.0042 | Attack_acc: 89.25%\n",
      "ID: 3 | Epoch: 11/15 | Loss: 0.0038 | Attack_acc: 89.24%\n",
      "ID: 3 | Epoch: 12/15 | Loss: 0.0032 | Attack_acc: 89.76%\n",
      "ID: 3 | Epoch: 13/15 | Loss: 0.0039 | Attack_acc: 89.31%\n",
      "ID: 3 | Epoch: 14/15 | Loss: 0.0027 | Attack_acc: 89.78%\n",
      "ID: 3 | Epoch: 15/15 | Loss: 0.0030 | Attack_acc: 90.06%\n",
      "Test loss: 1.8537 | Test Acc: 56.40% | Attack Acc: 87.82%\n",
      "training the target model uses:  17.998098134994507\n",
      "ID: 4 | Epoch: 1/15 | Loss: 0.9296 | Attack_acc: 58.80%\n",
      "ID: 4 | Epoch: 2/15 | Loss: 0.4120 | Attack_acc: 75.39%\n",
      "ID: 4 | Epoch: 3/15 | Loss: 0.1733 | Attack_acc: 74.33%\n",
      "ID: 4 | Epoch: 4/15 | Loss: 0.0768 | Attack_acc: 82.30%\n",
      "ID: 4 | Epoch: 5/15 | Loss: 0.0279 | Attack_acc: 86.94%\n",
      "ID: 4 | Epoch: 6/15 | Loss: 0.0208 | Attack_acc: 85.24%\n",
      "ID: 4 | Epoch: 7/15 | Loss: 0.0112 | Attack_acc: 89.52%\n",
      "ID: 4 | Epoch: 8/15 | Loss: 0.0069 | Attack_acc: 89.95%\n",
      "ID: 4 | Epoch: 9/15 | Loss: 0.0053 | Attack_acc: 90.24%\n",
      "ID: 4 | Epoch: 10/15 | Loss: 0.0045 | Attack_acc: 89.74%\n",
      "ID: 4 | Epoch: 11/15 | Loss: 0.0047 | Attack_acc: 91.14%\n",
      "ID: 4 | Epoch: 12/15 | Loss: 0.0031 | Attack_acc: 91.57%\n",
      "ID: 4 | Epoch: 13/15 | Loss: 0.0027 | Attack_acc: 91.35%\n",
      "ID: 4 | Epoch: 14/15 | Loss: 0.0022 | Attack_acc: 91.56%\n",
      "ID: 4 | Epoch: 15/15 | Loss: 0.0020 | Attack_acc: 91.35%\n",
      "Test loss: 2.0051 | Test Acc: 54.47% | Attack Acc: 86.43%\n",
      "training the target model uses:  18.024593830108643\n",
      "ID: 5 | Epoch: 1/15 | Loss: 0.9829 | Attack_acc: 59.47%\n",
      "ID: 5 | Epoch: 2/15 | Loss: 0.4298 | Attack_acc: 68.22%\n",
      "ID: 5 | Epoch: 3/15 | Loss: 0.1970 | Attack_acc: 74.40%\n",
      "ID: 5 | Epoch: 4/15 | Loss: 0.1101 | Attack_acc: 76.34%\n",
      "ID: 5 | Epoch: 5/15 | Loss: 0.0456 | Attack_acc: 82.27%\n",
      "ID: 5 | Epoch: 6/15 | Loss: 0.0214 | Attack_acc: 87.19%\n",
      "ID: 5 | Epoch: 7/15 | Loss: 0.0124 | Attack_acc: 87.97%\n",
      "ID: 5 | Epoch: 8/15 | Loss: 0.0088 | Attack_acc: 89.11%\n",
      "ID: 5 | Epoch: 9/15 | Loss: 0.0063 | Attack_acc: 90.57%\n",
      "ID: 5 | Epoch: 10/15 | Loss: 0.0040 | Attack_acc: 90.84%\n",
      "ID: 5 | Epoch: 11/15 | Loss: 0.0029 | Attack_acc: 91.07%\n",
      "ID: 5 | Epoch: 12/15 | Loss: 0.0031 | Attack_acc: 90.92%\n",
      "ID: 5 | Epoch: 13/15 | Loss: 0.0030 | Attack_acc: 90.94%\n",
      "ID: 5 | Epoch: 14/15 | Loss: 0.0022 | Attack_acc: 91.27%\n",
      "ID: 5 | Epoch: 15/15 | Loss: 0.0022 | Attack_acc: 91.59%\n",
      "Test loss: 1.9474 | Test Acc: 56.07% | Attack Acc: 87.42%\n",
      "training the target model uses:  18.87828230857849\n",
      "ID: 6 | Epoch: 1/15 | Loss: 1.0029 | Attack_acc: 65.79%\n",
      "ID: 6 | Epoch: 2/15 | Loss: 0.4008 | Attack_acc: 70.67%\n",
      "ID: 6 | Epoch: 3/15 | Loss: 0.1656 | Attack_acc: 76.55%\n",
      "ID: 6 | Epoch: 4/15 | Loss: 0.0668 | Attack_acc: 84.08%\n",
      "ID: 6 | Epoch: 5/15 | Loss: 0.0281 | Attack_acc: 86.18%\n",
      "ID: 6 | Epoch: 6/15 | Loss: 0.0124 | Attack_acc: 88.51%\n",
      "ID: 6 | Epoch: 7/15 | Loss: 0.0063 | Attack_acc: 89.09%\n",
      "ID: 6 | Epoch: 8/15 | Loss: 0.0067 | Attack_acc: 88.19%\n",
      "ID: 6 | Epoch: 9/15 | Loss: 0.0059 | Attack_acc: 89.57%\n",
      "ID: 6 | Epoch: 10/15 | Loss: 0.0039 | Attack_acc: 90.41%\n",
      "ID: 6 | Epoch: 11/15 | Loss: 0.0042 | Attack_acc: 90.36%\n",
      "ID: 6 | Epoch: 12/15 | Loss: 0.0030 | Attack_acc: 89.87%\n",
      "ID: 6 | Epoch: 13/15 | Loss: 0.0040 | Attack_acc: 90.81%\n",
      "ID: 6 | Epoch: 14/15 | Loss: 0.0028 | Attack_acc: 90.92%\n",
      "ID: 6 | Epoch: 15/15 | Loss: 0.0030 | Attack_acc: 90.34%\n",
      "Test loss: 2.1632 | Test Acc: 53.20% | Attack Acc: 82.64%\n",
      "training the target model uses:  18.59755253791809\n",
      "ID: 7 | Epoch: 1/15 | Loss: 1.1119 | Attack_acc: 60.56%\n",
      "ID: 7 | Epoch: 2/15 | Loss: 0.4815 | Attack_acc: 74.22%\n",
      "ID: 7 | Epoch: 3/15 | Loss: 0.1720 | Attack_acc: 77.61%\n",
      "ID: 7 | Epoch: 4/15 | Loss: 0.0881 | Attack_acc: 82.87%\n",
      "ID: 7 | Epoch: 5/15 | Loss: 0.0378 | Attack_acc: 85.12%\n",
      "ID: 7 | Epoch: 6/15 | Loss: 0.0181 | Attack_acc: 86.62%\n",
      "ID: 7 | Epoch: 7/15 | Loss: 0.0105 | Attack_acc: 88.10%\n",
      "ID: 7 | Epoch: 8/15 | Loss: 0.0058 | Attack_acc: 89.07%\n",
      "ID: 7 | Epoch: 9/15 | Loss: 0.0058 | Attack_acc: 89.19%\n",
      "ID: 7 | Epoch: 10/15 | Loss: 0.0042 | Attack_acc: 90.07%\n",
      "ID: 7 | Epoch: 11/15 | Loss: 0.0037 | Attack_acc: 89.86%\n",
      "ID: 7 | Epoch: 12/15 | Loss: 0.0038 | Attack_acc: 89.79%\n",
      "ID: 7 | Epoch: 13/15 | Loss: 0.0026 | Attack_acc: 90.15%\n",
      "ID: 7 | Epoch: 14/15 | Loss: 0.0024 | Attack_acc: 90.83%\n",
      "ID: 7 | Epoch: 15/15 | Loss: 0.0027 | Attack_acc: 90.55%\n",
      "Test loss: 2.3217 | Test Acc: 48.53% | Attack Acc: 81.48%\n",
      "training the target model uses:  18.5174663066864\n",
      "ID: 8 | Epoch: 1/15 | Loss: 1.0141 | Attack_acc: 63.31%\n",
      "ID: 8 | Epoch: 2/15 | Loss: 0.4662 | Attack_acc: 73.37%\n",
      "ID: 8 | Epoch: 3/15 | Loss: 0.1812 | Attack_acc: 79.25%\n",
      "ID: 8 | Epoch: 4/15 | Loss: 0.1037 | Attack_acc: 83.48%\n",
      "ID: 8 | Epoch: 5/15 | Loss: 0.0439 | Attack_acc: 85.48%\n",
      "ID: 8 | Epoch: 6/15 | Loss: 0.0214 | Attack_acc: 87.22%\n",
      "ID: 8 | Epoch: 7/15 | Loss: 0.0149 | Attack_acc: 89.40%\n",
      "ID: 8 | Epoch: 8/15 | Loss: 0.0070 | Attack_acc: 90.28%\n",
      "ID: 8 | Epoch: 9/15 | Loss: 0.0044 | Attack_acc: 91.03%\n",
      "ID: 8 | Epoch: 10/15 | Loss: 0.0044 | Attack_acc: 91.50%\n",
      "ID: 8 | Epoch: 11/15 | Loss: 0.0035 | Attack_acc: 91.39%\n",
      "ID: 8 | Epoch: 12/15 | Loss: 0.0028 | Attack_acc: 91.82%\n",
      "ID: 8 | Epoch: 13/15 | Loss: 0.0029 | Attack_acc: 92.15%\n",
      "ID: 8 | Epoch: 14/15 | Loss: 0.0032 | Attack_acc: 92.14%\n",
      "ID: 8 | Epoch: 15/15 | Loss: 0.0018 | Attack_acc: 92.54%\n",
      "Test loss: 1.8334 | Test Acc: 54.73% | Attack Acc: 88.16%\n",
      "training the target model uses:  18.079464197158813\n",
      "ID: 9 | Epoch: 1/15 | Loss: 1.0511 | Attack_acc: 60.43%\n",
      "ID: 9 | Epoch: 2/15 | Loss: 0.5231 | Attack_acc: 70.74%\n",
      "ID: 9 | Epoch: 3/15 | Loss: 0.2197 | Attack_acc: 73.35%\n",
      "ID: 9 | Epoch: 4/15 | Loss: 0.1027 | Attack_acc: 78.09%\n",
      "ID: 9 | Epoch: 5/15 | Loss: 0.0471 | Attack_acc: 85.14%\n",
      "ID: 9 | Epoch: 6/15 | Loss: 0.0223 | Attack_acc: 87.44%\n",
      "ID: 9 | Epoch: 7/15 | Loss: 0.0138 | Attack_acc: 89.48%\n",
      "ID: 9 | Epoch: 8/15 | Loss: 0.0061 | Attack_acc: 89.82%\n",
      "ID: 9 | Epoch: 9/15 | Loss: 0.0061 | Attack_acc: 90.54%\n",
      "ID: 9 | Epoch: 10/15 | Loss: 0.0042 | Attack_acc: 90.60%\n",
      "ID: 9 | Epoch: 11/15 | Loss: 0.0038 | Attack_acc: 91.05%\n",
      "ID: 9 | Epoch: 12/15 | Loss: 0.0031 | Attack_acc: 90.83%\n",
      "ID: 9 | Epoch: 13/15 | Loss: 0.0031 | Attack_acc: 91.41%\n",
      "ID: 9 | Epoch: 14/15 | Loss: 0.0025 | Attack_acc: 91.94%\n",
      "ID: 9 | Epoch: 15/15 | Loss: 0.0025 | Attack_acc: 91.68%\n",
      "Test loss: 1.8671 | Test Acc: 55.13% | Attack Acc: 88.52%\n",
      "training the target model uses:  18.813318014144897\n",
      "Global epoch 6: Test loss: 1.4403 | Test Acc: 65.00%\n",
      "Global Epoch:  7\n",
      "ID: 0 | Epoch: 1/15 | Loss: 0.8810 | Attack_acc: 61.88%\n",
      "ID: 0 | Epoch: 2/15 | Loss: 0.3412 | Attack_acc: 72.48%\n",
      "ID: 0 | Epoch: 3/15 | Loss: 0.1217 | Attack_acc: 82.77%\n",
      "ID: 0 | Epoch: 4/15 | Loss: 0.0364 | Attack_acc: 85.83%\n",
      "ID: 0 | Epoch: 5/15 | Loss: 0.0167 | Attack_acc: 86.26%\n",
      "ID: 0 | Epoch: 6/15 | Loss: 0.0115 | Attack_acc: 87.93%\n",
      "ID: 0 | Epoch: 7/15 | Loss: 0.0076 | Attack_acc: 88.96%\n",
      "ID: 0 | Epoch: 8/15 | Loss: 0.0055 | Attack_acc: 89.88%\n",
      "ID: 0 | Epoch: 9/15 | Loss: 0.0039 | Attack_acc: 90.00%\n",
      "ID: 0 | Epoch: 10/15 | Loss: 0.0046 | Attack_acc: 90.13%\n",
      "ID: 0 | Epoch: 11/15 | Loss: 0.0042 | Attack_acc: 89.38%\n",
      "ID: 0 | Epoch: 12/15 | Loss: 0.0035 | Attack_acc: 90.00%\n",
      "ID: 0 | Epoch: 13/15 | Loss: 0.0030 | Attack_acc: 90.64%\n",
      "ID: 0 | Epoch: 14/15 | Loss: 0.0026 | Attack_acc: 90.76%\n",
      "ID: 0 | Epoch: 15/15 | Loss: 0.0025 | Attack_acc: 91.12%\n",
      "Test loss: 1.8705 | Test Acc: 58.20% | Attack Acc: 87.03%\n",
      "training the target model uses:  18.96662425994873\n",
      "ID: 1 | Epoch: 1/15 | Loss: 0.9104 | Attack_acc: 64.52%\n",
      "ID: 1 | Epoch: 2/15 | Loss: 0.4138 | Attack_acc: 72.84%\n",
      "ID: 1 | Epoch: 3/15 | Loss: 0.1383 | Attack_acc: 80.44%\n",
      "ID: 1 | Epoch: 4/15 | Loss: 0.0757 | Attack_acc: 77.97%\n",
      "ID: 1 | Epoch: 5/15 | Loss: 0.0305 | Attack_acc: 84.68%\n",
      "ID: 1 | Epoch: 6/15 | Loss: 0.0201 | Attack_acc: 85.81%\n",
      "ID: 1 | Epoch: 7/15 | Loss: 0.0106 | Attack_acc: 88.82%\n",
      "ID: 1 | Epoch: 8/15 | Loss: 0.0050 | Attack_acc: 89.21%\n",
      "ID: 1 | Epoch: 9/15 | Loss: 0.0036 | Attack_acc: 90.32%\n",
      "ID: 1 | Epoch: 10/15 | Loss: 0.0037 | Attack_acc: 90.60%\n",
      "ID: 1 | Epoch: 11/15 | Loss: 0.0033 | Attack_acc: 90.40%\n",
      "ID: 1 | Epoch: 12/15 | Loss: 0.0031 | Attack_acc: 91.09%\n",
      "ID: 1 | Epoch: 13/15 | Loss: 0.0026 | Attack_acc: 91.12%\n",
      "ID: 1 | Epoch: 14/15 | Loss: 0.0021 | Attack_acc: 91.38%\n",
      "ID: 1 | Epoch: 15/15 | Loss: 0.0020 | Attack_acc: 91.72%\n",
      "Test loss: 2.1001 | Test Acc: 54.00% | Attack Acc: 87.27%\n",
      "training the target model uses:  18.002103805541992\n",
      "ID: 2 | Epoch: 1/15 | Loss: 0.8678 | Attack_acc: 64.07%\n",
      "ID: 2 | Epoch: 2/15 | Loss: 0.4019 | Attack_acc: 72.97%\n",
      "ID: 2 | Epoch: 3/15 | Loss: 0.1508 | Attack_acc: 75.64%\n",
      "ID: 2 | Epoch: 4/15 | Loss: 0.0656 | Attack_acc: 78.30%\n",
      "ID: 2 | Epoch: 5/15 | Loss: 0.0297 | Attack_acc: 82.88%\n",
      "ID: 2 | Epoch: 6/15 | Loss: 0.0152 | Attack_acc: 86.04%\n",
      "ID: 2 | Epoch: 7/15 | Loss: 0.0100 | Attack_acc: 86.98%\n",
      "ID: 2 | Epoch: 8/15 | Loss: 0.0076 | Attack_acc: 87.90%\n",
      "ID: 2 | Epoch: 9/15 | Loss: 0.0042 | Attack_acc: 88.66%\n",
      "ID: 2 | Epoch: 10/15 | Loss: 0.0042 | Attack_acc: 88.66%\n",
      "ID: 2 | Epoch: 11/15 | Loss: 0.0037 | Attack_acc: 88.72%\n",
      "ID: 2 | Epoch: 12/15 | Loss: 0.0037 | Attack_acc: 89.31%\n",
      "ID: 2 | Epoch: 13/15 | Loss: 0.0024 | Attack_acc: 89.27%\n",
      "ID: 2 | Epoch: 14/15 | Loss: 0.0022 | Attack_acc: 89.49%\n",
      "ID: 2 | Epoch: 15/15 | Loss: 0.0022 | Attack_acc: 89.29%\n",
      "Test loss: 2.0237 | Test Acc: 56.60% | Attack Acc: 83.55%\n",
      "training the target model uses:  18.585633993148804\n",
      "ID: 3 | Epoch: 1/15 | Loss: 0.8961 | Attack_acc: 62.44%\n",
      "ID: 3 | Epoch: 2/15 | Loss: 0.3447 | Attack_acc: 71.05%\n",
      "ID: 3 | Epoch: 3/15 | Loss: 0.1349 | Attack_acc: 81.66%\n",
      "ID: 3 | Epoch: 4/15 | Loss: 0.0509 | Attack_acc: 84.32%\n",
      "ID: 3 | Epoch: 5/15 | Loss: 0.0291 | Attack_acc: 85.90%\n",
      "ID: 3 | Epoch: 6/15 | Loss: 0.0127 | Attack_acc: 87.95%\n",
      "ID: 3 | Epoch: 7/15 | Loss: 0.0073 | Attack_acc: 88.35%\n",
      "ID: 3 | Epoch: 8/15 | Loss: 0.0054 | Attack_acc: 89.27%\n",
      "ID: 3 | Epoch: 9/15 | Loss: 0.0036 | Attack_acc: 89.38%\n",
      "ID: 3 | Epoch: 10/15 | Loss: 0.0042 | Attack_acc: 89.80%\n",
      "ID: 3 | Epoch: 11/15 | Loss: 0.0028 | Attack_acc: 90.02%\n",
      "ID: 3 | Epoch: 12/15 | Loss: 0.0021 | Attack_acc: 90.11%\n",
      "ID: 3 | Epoch: 13/15 | Loss: 0.0022 | Attack_acc: 89.99%\n",
      "ID: 3 | Epoch: 14/15 | Loss: 0.0028 | Attack_acc: 90.13%\n",
      "ID: 3 | Epoch: 15/15 | Loss: 0.0024 | Attack_acc: 90.70%\n",
      "Test loss: 2.0294 | Test Acc: 54.93% | Attack Acc: 86.89%\n",
      "training the target model uses:  17.84895348548889\n",
      "ID: 4 | Epoch: 1/15 | Loss: 0.8962 | Attack_acc: 59.93%\n",
      "ID: 4 | Epoch: 2/15 | Loss: 0.3708 | Attack_acc: 75.29%\n",
      "ID: 4 | Epoch: 3/15 | Loss: 0.1306 | Attack_acc: 75.89%\n",
      "ID: 4 | Epoch: 4/15 | Loss: 0.0545 | Attack_acc: 80.44%\n",
      "ID: 4 | Epoch: 5/15 | Loss: 0.0221 | Attack_acc: 85.69%\n",
      "ID: 4 | Epoch: 6/15 | Loss: 0.0097 | Attack_acc: 88.12%\n",
      "ID: 4 | Epoch: 7/15 | Loss: 0.0070 | Attack_acc: 88.66%\n",
      "ID: 4 | Epoch: 8/15 | Loss: 0.0049 | Attack_acc: 89.54%\n",
      "ID: 4 | Epoch: 9/15 | Loss: 0.0043 | Attack_acc: 88.44%\n",
      "ID: 4 | Epoch: 10/15 | Loss: 0.0043 | Attack_acc: 89.67%\n",
      "ID: 4 | Epoch: 11/15 | Loss: 0.0030 | Attack_acc: 89.92%\n",
      "ID: 4 | Epoch: 12/15 | Loss: 0.0028 | Attack_acc: 90.55%\n",
      "ID: 4 | Epoch: 13/15 | Loss: 0.0029 | Attack_acc: 90.53%\n",
      "ID: 4 | Epoch: 14/15 | Loss: 0.0020 | Attack_acc: 90.16%\n",
      "ID: 4 | Epoch: 15/15 | Loss: 0.0020 | Attack_acc: 90.74%\n",
      "Test loss: 2.1669 | Test Acc: 54.67% | Attack Acc: 86.48%\n",
      "training the target model uses:  18.56084132194519\n",
      "ID: 5 | Epoch: 1/15 | Loss: 0.8836 | Attack_acc: 62.54%\n",
      "ID: 5 | Epoch: 2/15 | Loss: 0.4092 | Attack_acc: 73.58%\n",
      "ID: 5 | Epoch: 3/15 | Loss: 0.1786 | Attack_acc: 76.91%\n",
      "ID: 5 | Epoch: 4/15 | Loss: 0.0811 | Attack_acc: 85.19%\n",
      "ID: 5 | Epoch: 5/15 | Loss: 0.0238 | Attack_acc: 86.54%\n",
      "ID: 5 | Epoch: 6/15 | Loss: 0.0103 | Attack_acc: 88.09%\n",
      "ID: 5 | Epoch: 7/15 | Loss: 0.0067 | Attack_acc: 88.94%\n",
      "ID: 5 | Epoch: 8/15 | Loss: 0.0062 | Attack_acc: 88.96%\n",
      "ID: 5 | Epoch: 9/15 | Loss: 0.0038 | Attack_acc: 89.79%\n",
      "ID: 5 | Epoch: 10/15 | Loss: 0.0038 | Attack_acc: 90.18%\n",
      "ID: 5 | Epoch: 11/15 | Loss: 0.0031 | Attack_acc: 90.25%\n",
      "ID: 5 | Epoch: 12/15 | Loss: 0.0028 | Attack_acc: 90.57%\n",
      "ID: 5 | Epoch: 13/15 | Loss: 0.0030 | Attack_acc: 90.50%\n",
      "ID: 5 | Epoch: 14/15 | Loss: 0.0030 | Attack_acc: 90.64%\n",
      "ID: 5 | Epoch: 15/15 | Loss: 0.0022 | Attack_acc: 90.49%\n",
      "Test loss: 2.3393 | Test Acc: 49.80% | Attack Acc: 83.55%\n",
      "training the target model uses:  18.161784648895264\n",
      "ID: 6 | Epoch: 1/15 | Loss: 0.9181 | Attack_acc: 61.91%\n",
      "ID: 6 | Epoch: 2/15 | Loss: 0.3756 | Attack_acc: 75.39%\n",
      "ID: 6 | Epoch: 3/15 | Loss: 0.1458 | Attack_acc: 78.15%\n",
      "ID: 6 | Epoch: 4/15 | Loss: 0.0659 | Attack_acc: 82.92%\n",
      "ID: 6 | Epoch: 5/15 | Loss: 0.0318 | Attack_acc: 85.93%\n",
      "ID: 6 | Epoch: 6/15 | Loss: 0.0139 | Attack_acc: 87.60%\n",
      "ID: 6 | Epoch: 7/15 | Loss: 0.0100 | Attack_acc: 88.05%\n",
      "ID: 6 | Epoch: 8/15 | Loss: 0.0058 | Attack_acc: 89.14%\n",
      "ID: 6 | Epoch: 9/15 | Loss: 0.0054 | Attack_acc: 89.44%\n",
      "ID: 6 | Epoch: 10/15 | Loss: 0.0044 | Attack_acc: 89.11%\n",
      "ID: 6 | Epoch: 11/15 | Loss: 0.0039 | Attack_acc: 89.65%\n",
      "ID: 6 | Epoch: 12/15 | Loss: 0.0031 | Attack_acc: 90.17%\n",
      "ID: 6 | Epoch: 13/15 | Loss: 0.0030 | Attack_acc: 90.22%\n",
      "ID: 6 | Epoch: 14/15 | Loss: 0.0029 | Attack_acc: 90.74%\n",
      "ID: 6 | Epoch: 15/15 | Loss: 0.0019 | Attack_acc: 91.16%\n",
      "Test loss: 2.4594 | Test Acc: 50.00% | Attack Acc: 82.66%\n",
      "training the target model uses:  18.519564628601074\n",
      "ID: 7 | Epoch: 1/15 | Loss: 0.9521 | Attack_acc: 59.33%\n",
      "ID: 7 | Epoch: 2/15 | Loss: 0.3824 | Attack_acc: 75.00%\n",
      "ID: 7 | Epoch: 3/15 | Loss: 0.1206 | Attack_acc: 79.23%\n",
      "ID: 7 | Epoch: 4/15 | Loss: 0.0599 | Attack_acc: 81.67%\n",
      "ID: 7 | Epoch: 5/15 | Loss: 0.0249 | Attack_acc: 84.77%\n",
      "ID: 7 | Epoch: 6/15 | Loss: 0.0156 | Attack_acc: 87.53%\n",
      "ID: 7 | Epoch: 7/15 | Loss: 0.0097 | Attack_acc: 88.04%\n",
      "ID: 7 | Epoch: 8/15 | Loss: 0.0072 | Attack_acc: 89.01%\n",
      "ID: 7 | Epoch: 9/15 | Loss: 0.0043 | Attack_acc: 88.98%\n",
      "ID: 7 | Epoch: 10/15 | Loss: 0.0043 | Attack_acc: 89.47%\n",
      "ID: 7 | Epoch: 11/15 | Loss: 0.0025 | Attack_acc: 89.44%\n",
      "ID: 7 | Epoch: 12/15 | Loss: 0.0033 | Attack_acc: 89.88%\n",
      "ID: 7 | Epoch: 13/15 | Loss: 0.0028 | Attack_acc: 90.13%\n",
      "ID: 7 | Epoch: 14/15 | Loss: 0.0036 | Attack_acc: 90.02%\n",
      "ID: 7 | Epoch: 15/15 | Loss: 0.0024 | Attack_acc: 90.63%\n",
      "Test loss: 1.9925 | Test Acc: 54.93% | Attack Acc: 86.03%\n",
      "training the target model uses:  18.199761152267456\n",
      "ID: 8 | Epoch: 1/15 | Loss: 0.9683 | Attack_acc: 64.53%\n",
      "ID: 8 | Epoch: 2/15 | Loss: 0.4190 | Attack_acc: 74.34%\n",
      "ID: 8 | Epoch: 3/15 | Loss: 0.1501 | Attack_acc: 79.53%\n",
      "ID: 8 | Epoch: 4/15 | Loss: 0.0670 | Attack_acc: 83.35%\n",
      "ID: 8 | Epoch: 5/15 | Loss: 0.0275 | Attack_acc: 87.56%\n",
      "ID: 8 | Epoch: 6/15 | Loss: 0.0137 | Attack_acc: 87.99%\n",
      "ID: 8 | Epoch: 7/15 | Loss: 0.0069 | Attack_acc: 90.06%\n",
      "ID: 8 | Epoch: 8/15 | Loss: 0.0052 | Attack_acc: 90.35%\n",
      "ID: 8 | Epoch: 9/15 | Loss: 0.0046 | Attack_acc: 90.84%\n",
      "ID: 8 | Epoch: 10/15 | Loss: 0.0044 | Attack_acc: 90.77%\n",
      "ID: 8 | Epoch: 11/15 | Loss: 0.0030 | Attack_acc: 91.11%\n",
      "ID: 8 | Epoch: 12/15 | Loss: 0.0025 | Attack_acc: 91.16%\n",
      "ID: 8 | Epoch: 13/15 | Loss: 0.0032 | Attack_acc: 91.42%\n",
      "ID: 8 | Epoch: 14/15 | Loss: 0.0029 | Attack_acc: 91.23%\n",
      "ID: 8 | Epoch: 15/15 | Loss: 0.0023 | Attack_acc: 91.53%\n",
      "Test loss: 2.2018 | Test Acc: 55.27% | Attack Acc: 84.96%\n",
      "training the target model uses:  17.97450089454651\n",
      "ID: 9 | Epoch: 1/15 | Loss: 0.9432 | Attack_acc: 63.81%\n",
      "ID: 9 | Epoch: 2/15 | Loss: 0.4027 | Attack_acc: 71.60%\n",
      "ID: 9 | Epoch: 3/15 | Loss: 0.1547 | Attack_acc: 77.07%\n",
      "ID: 9 | Epoch: 4/15 | Loss: 0.0866 | Attack_acc: 81.80%\n",
      "ID: 9 | Epoch: 5/15 | Loss: 0.0366 | Attack_acc: 84.87%\n",
      "ID: 9 | Epoch: 6/15 | Loss: 0.0161 | Attack_acc: 88.11%\n",
      "ID: 9 | Epoch: 7/15 | Loss: 0.0103 | Attack_acc: 87.81%\n",
      "ID: 9 | Epoch: 8/15 | Loss: 0.0082 | Attack_acc: 88.41%\n",
      "ID: 9 | Epoch: 9/15 | Loss: 0.0047 | Attack_acc: 89.23%\n",
      "ID: 9 | Epoch: 10/15 | Loss: 0.0047 | Attack_acc: 90.15%\n",
      "ID: 9 | Epoch: 11/15 | Loss: 0.0036 | Attack_acc: 90.39%\n",
      "ID: 9 | Epoch: 12/15 | Loss: 0.0033 | Attack_acc: 91.13%\n",
      "ID: 9 | Epoch: 13/15 | Loss: 0.0031 | Attack_acc: 90.71%\n",
      "ID: 9 | Epoch: 14/15 | Loss: 0.0021 | Attack_acc: 90.75%\n",
      "ID: 9 | Epoch: 15/15 | Loss: 0.0020 | Attack_acc: 91.51%\n",
      "Test loss: 2.3538 | Test Acc: 53.20% | Attack Acc: 83.21%\n",
      "training the target model uses:  18.27016592025757\n",
      "Global epoch 7: Test loss: 1.5585 | Test Acc: 64.53%\n",
      "Global Epoch:  8\n",
      "ID: 0 | Epoch: 1/15 | Loss: 0.7165 | Attack_acc: 63.82%\n",
      "ID: 0 | Epoch: 2/15 | Loss: 0.3079 | Attack_acc: 74.08%\n",
      "ID: 0 | Epoch: 3/15 | Loss: 0.1338 | Attack_acc: 78.66%\n",
      "ID: 0 | Epoch: 4/15 | Loss: 0.0566 | Attack_acc: 82.59%\n",
      "ID: 0 | Epoch: 5/15 | Loss: 0.0240 | Attack_acc: 86.89%\n",
      "ID: 0 | Epoch: 6/15 | Loss: 0.0085 | Attack_acc: 86.19%\n",
      "ID: 0 | Epoch: 7/15 | Loss: 0.0066 | Attack_acc: 88.03%\n",
      "ID: 0 | Epoch: 8/15 | Loss: 0.0057 | Attack_acc: 88.84%\n",
      "ID: 0 | Epoch: 9/15 | Loss: 0.0044 | Attack_acc: 89.23%\n",
      "ID: 0 | Epoch: 10/15 | Loss: 0.0032 | Attack_acc: 89.60%\n",
      "ID: 0 | Epoch: 11/15 | Loss: 0.0025 | Attack_acc: 89.94%\n",
      "ID: 0 | Epoch: 12/15 | Loss: 0.0027 | Attack_acc: 90.00%\n",
      "ID: 0 | Epoch: 13/15 | Loss: 0.0024 | Attack_acc: 90.20%\n",
      "ID: 0 | Epoch: 14/15 | Loss: 0.0018 | Attack_acc: 90.21%\n",
      "ID: 0 | Epoch: 15/15 | Loss: 0.0020 | Attack_acc: 90.56%\n",
      "Test loss: 1.6262 | Test Acc: 62.27% | Attack Acc: 84.11%\n",
      "training the target model uses:  19.798563241958618\n",
      "ID: 1 | Epoch: 1/15 | Loss: 0.8477 | Attack_acc: 67.22%\n",
      "ID: 1 | Epoch: 2/15 | Loss: 0.3503 | Attack_acc: 75.64%\n",
      "ID: 1 | Epoch: 3/15 | Loss: 0.1034 | Attack_acc: 81.67%\n",
      "ID: 1 | Epoch: 4/15 | Loss: 0.0351 | Attack_acc: 86.59%\n",
      "ID: 1 | Epoch: 5/15 | Loss: 0.0159 | Attack_acc: 88.04%\n",
      "ID: 1 | Epoch: 6/15 | Loss: 0.0087 | Attack_acc: 88.48%\n",
      "ID: 1 | Epoch: 7/15 | Loss: 0.0060 | Attack_acc: 89.23%\n",
      "ID: 1 | Epoch: 8/15 | Loss: 0.0063 | Attack_acc: 89.90%\n",
      "ID: 1 | Epoch: 9/15 | Loss: 0.0057 | Attack_acc: 89.81%\n",
      "ID: 1 | Epoch: 10/15 | Loss: 0.0033 | Attack_acc: 89.72%\n",
      "ID: 1 | Epoch: 11/15 | Loss: 0.0033 | Attack_acc: 90.19%\n",
      "ID: 1 | Epoch: 12/15 | Loss: 0.0024 | Attack_acc: 90.23%\n",
      "ID: 1 | Epoch: 13/15 | Loss: 0.0019 | Attack_acc: 90.33%\n",
      "ID: 1 | Epoch: 14/15 | Loss: 0.0027 | Attack_acc: 90.84%\n",
      "ID: 1 | Epoch: 15/15 | Loss: 0.0024 | Attack_acc: 91.01%\n",
      "Test loss: 1.9488 | Test Acc: 56.33% | Attack Acc: 84.73%\n",
      "training the target model uses:  18.37169075012207\n",
      "ID: 2 | Epoch: 1/15 | Loss: 0.7753 | Attack_acc: 65.49%\n",
      "ID: 2 | Epoch: 2/15 | Loss: 0.3410 | Attack_acc: 73.39%\n",
      "ID: 2 | Epoch: 3/15 | Loss: 0.1216 | Attack_acc: 78.50%\n",
      "ID: 2 | Epoch: 4/15 | Loss: 0.0356 | Attack_acc: 83.71%\n",
      "ID: 2 | Epoch: 5/15 | Loss: 0.0176 | Attack_acc: 85.38%\n",
      "ID: 2 | Epoch: 6/15 | Loss: 0.0101 | Attack_acc: 86.39%\n",
      "ID: 2 | Epoch: 7/15 | Loss: 0.0065 | Attack_acc: 87.13%\n",
      "ID: 2 | Epoch: 8/15 | Loss: 0.0050 | Attack_acc: 87.54%\n",
      "ID: 2 | Epoch: 9/15 | Loss: 0.0041 | Attack_acc: 87.70%\n",
      "ID: 2 | Epoch: 10/15 | Loss: 0.0034 | Attack_acc: 88.08%\n",
      "ID: 2 | Epoch: 11/15 | Loss: 0.0032 | Attack_acc: 88.66%\n",
      "ID: 2 | Epoch: 12/15 | Loss: 0.0022 | Attack_acc: 88.53%\n",
      "ID: 2 | Epoch: 13/15 | Loss: 0.0020 | Attack_acc: 88.80%\n",
      "ID: 2 | Epoch: 14/15 | Loss: 0.0019 | Attack_acc: 89.12%\n",
      "ID: 2 | Epoch: 15/15 | Loss: 0.0021 | Attack_acc: 89.22%\n",
      "Test loss: 2.5295 | Test Acc: 47.73% | Attack Acc: 78.82%\n",
      "training the target model uses:  18.353245735168457\n",
      "ID: 3 | Epoch: 1/15 | Loss: 0.8140 | Attack_acc: 61.68%\n",
      "ID: 3 | Epoch: 2/15 | Loss: 0.3564 | Attack_acc: 74.56%\n",
      "ID: 3 | Epoch: 3/15 | Loss: 0.1160 | Attack_acc: 79.78%\n",
      "ID: 3 | Epoch: 4/15 | Loss: 0.0499 | Attack_acc: 80.91%\n",
      "ID: 3 | Epoch: 5/15 | Loss: 0.0200 | Attack_acc: 86.62%\n",
      "ID: 3 | Epoch: 6/15 | Loss: 0.0113 | Attack_acc: 86.88%\n",
      "ID: 3 | Epoch: 7/15 | Loss: 0.0078 | Attack_acc: 88.11%\n",
      "ID: 3 | Epoch: 8/15 | Loss: 0.0041 | Attack_acc: 88.39%\n",
      "ID: 3 | Epoch: 9/15 | Loss: 0.0052 | Attack_acc: 88.78%\n",
      "ID: 3 | Epoch: 10/15 | Loss: 0.0032 | Attack_acc: 88.77%\n",
      "ID: 3 | Epoch: 11/15 | Loss: 0.0028 | Attack_acc: 89.21%\n",
      "ID: 3 | Epoch: 12/15 | Loss: 0.0026 | Attack_acc: 89.55%\n",
      "ID: 3 | Epoch: 13/15 | Loss: 0.0022 | Attack_acc: 89.47%\n",
      "ID: 3 | Epoch: 14/15 | Loss: 0.0019 | Attack_acc: 89.90%\n",
      "ID: 3 | Epoch: 15/15 | Loss: 0.0018 | Attack_acc: 89.85%\n",
      "Test loss: 2.2090 | Test Acc: 54.60% | Attack Acc: 81.14%\n",
      "training the target model uses:  18.969956636428833\n",
      "ID: 4 | Epoch: 1/15 | Loss: 0.7559 | Attack_acc: 63.44%\n",
      "ID: 4 | Epoch: 2/15 | Loss: 0.3445 | Attack_acc: 72.96%\n",
      "ID: 4 | Epoch: 3/15 | Loss: 0.1195 | Attack_acc: 78.12%\n",
      "ID: 4 | Epoch: 4/15 | Loss: 0.0536 | Attack_acc: 80.94%\n",
      "ID: 4 | Epoch: 5/15 | Loss: 0.0273 | Attack_acc: 84.51%\n",
      "ID: 4 | Epoch: 6/15 | Loss: 0.0196 | Attack_acc: 86.49%\n",
      "ID: 4 | Epoch: 7/15 | Loss: 0.0080 | Attack_acc: 87.95%\n",
      "ID: 4 | Epoch: 8/15 | Loss: 0.0068 | Attack_acc: 88.56%\n",
      "ID: 4 | Epoch: 9/15 | Loss: 0.0041 | Attack_acc: 88.73%\n",
      "ID: 4 | Epoch: 10/15 | Loss: 0.0043 | Attack_acc: 89.17%\n",
      "ID: 4 | Epoch: 11/15 | Loss: 0.0033 | Attack_acc: 89.77%\n",
      "ID: 4 | Epoch: 12/15 | Loss: 0.0030 | Attack_acc: 89.97%\n",
      "ID: 4 | Epoch: 13/15 | Loss: 0.0036 | Attack_acc: 90.11%\n",
      "ID: 4 | Epoch: 14/15 | Loss: 0.0026 | Attack_acc: 90.10%\n",
      "ID: 4 | Epoch: 15/15 | Loss: 0.0022 | Attack_acc: 90.07%\n",
      "Test loss: 1.9479 | Test Acc: 57.00% | Attack Acc: 85.81%\n",
      "training the target model uses:  18.693881511688232\n",
      "ID: 5 | Epoch: 1/15 | Loss: 0.8237 | Attack_acc: 66.92%\n",
      "ID: 5 | Epoch: 2/15 | Loss: 0.3931 | Attack_acc: 76.79%\n",
      "ID: 5 | Epoch: 3/15 | Loss: 0.1288 | Attack_acc: 79.53%\n",
      "ID: 5 | Epoch: 4/15 | Loss: 0.0411 | Attack_acc: 84.96%\n",
      "ID: 5 | Epoch: 5/15 | Loss: 0.0163 | Attack_acc: 87.11%\n",
      "ID: 5 | Epoch: 6/15 | Loss: 0.0113 | Attack_acc: 87.44%\n",
      "ID: 5 | Epoch: 7/15 | Loss: 0.0062 | Attack_acc: 88.48%\n",
      "ID: 5 | Epoch: 8/15 | Loss: 0.0055 | Attack_acc: 88.99%\n",
      "ID: 5 | Epoch: 9/15 | Loss: 0.0039 | Attack_acc: 89.37%\n",
      "ID: 5 | Epoch: 10/15 | Loss: 0.0036 | Attack_acc: 89.55%\n",
      "ID: 5 | Epoch: 11/15 | Loss: 0.0030 | Attack_acc: 90.12%\n",
      "ID: 5 | Epoch: 12/15 | Loss: 0.0026 | Attack_acc: 90.17%\n",
      "ID: 5 | Epoch: 13/15 | Loss: 0.0025 | Attack_acc: 90.15%\n",
      "ID: 5 | Epoch: 14/15 | Loss: 0.0023 | Attack_acc: 90.32%\n",
      "ID: 5 | Epoch: 15/15 | Loss: 0.0023 | Attack_acc: 90.53%\n",
      "Test loss: 1.9199 | Test Acc: 57.40% | Attack Acc: 86.59%\n",
      "training the target model uses:  18.83664059638977\n",
      "ID: 6 | Epoch: 1/15 | Loss: 0.7684 | Attack_acc: 67.88%\n",
      "ID: 6 | Epoch: 2/15 | Loss: 0.3349 | Attack_acc: 71.99%\n",
      "ID: 6 | Epoch: 3/15 | Loss: 0.1052 | Attack_acc: 77.48%\n",
      "ID: 6 | Epoch: 4/15 | Loss: 0.0410 | Attack_acc: 83.12%\n",
      "ID: 6 | Epoch: 5/15 | Loss: 0.0202 | Attack_acc: 86.91%\n",
      "ID: 6 | Epoch: 6/15 | Loss: 0.0114 | Attack_acc: 87.42%\n",
      "ID: 6 | Epoch: 7/15 | Loss: 0.0073 | Attack_acc: 88.03%\n",
      "ID: 6 | Epoch: 8/15 | Loss: 0.0061 | Attack_acc: 88.73%\n",
      "ID: 6 | Epoch: 9/15 | Loss: 0.0048 | Attack_acc: 89.22%\n",
      "ID: 6 | Epoch: 10/15 | Loss: 0.0032 | Attack_acc: 89.64%\n",
      "ID: 6 | Epoch: 11/15 | Loss: 0.0029 | Attack_acc: 90.18%\n",
      "ID: 6 | Epoch: 12/15 | Loss: 0.0028 | Attack_acc: 90.32%\n",
      "ID: 6 | Epoch: 13/15 | Loss: 0.0026 | Attack_acc: 90.29%\n",
      "ID: 6 | Epoch: 14/15 | Loss: 0.0019 | Attack_acc: 90.12%\n",
      "ID: 6 | Epoch: 15/15 | Loss: 0.0020 | Attack_acc: 90.51%\n",
      "Test loss: 2.1609 | Test Acc: 53.53% | Attack Acc: 83.87%\n",
      "training the target model uses:  18.1199791431427\n",
      "ID: 7 | Epoch: 1/15 | Loss: 0.8234 | Attack_acc: 65.66%\n",
      "ID: 7 | Epoch: 2/15 | Loss: 0.3706 | Attack_acc: 71.39%\n",
      "ID: 7 | Epoch: 3/15 | Loss: 0.1564 | Attack_acc: 74.46%\n",
      "ID: 7 | Epoch: 4/15 | Loss: 0.0795 | Attack_acc: 79.46%\n",
      "ID: 7 | Epoch: 5/15 | Loss: 0.0300 | Attack_acc: 85.82%\n",
      "ID: 7 | Epoch: 6/15 | Loss: 0.0119 | Attack_acc: 87.73%\n",
      "ID: 7 | Epoch: 7/15 | Loss: 0.0068 | Attack_acc: 88.81%\n",
      "ID: 7 | Epoch: 8/15 | Loss: 0.0045 | Attack_acc: 89.44%\n",
      "ID: 7 | Epoch: 9/15 | Loss: 0.0045 | Attack_acc: 89.84%\n",
      "ID: 7 | Epoch: 10/15 | Loss: 0.0039 | Attack_acc: 89.45%\n",
      "ID: 7 | Epoch: 11/15 | Loss: 0.0028 | Attack_acc: 90.15%\n",
      "ID: 7 | Epoch: 12/15 | Loss: 0.0026 | Attack_acc: 90.11%\n",
      "ID: 7 | Epoch: 13/15 | Loss: 0.0024 | Attack_acc: 90.20%\n",
      "ID: 7 | Epoch: 14/15 | Loss: 0.0020 | Attack_acc: 90.60%\n",
      "ID: 7 | Epoch: 15/15 | Loss: 0.0023 | Attack_acc: 90.97%\n",
      "Test loss: 2.2286 | Test Acc: 53.27% | Attack Acc: 81.40%\n",
      "training the target model uses:  18.307103872299194\n",
      "ID: 8 | Epoch: 1/15 | Loss: 0.8419 | Attack_acc: 64.76%\n",
      "ID: 8 | Epoch: 2/15 | Loss: 0.3963 | Attack_acc: 74.65%\n",
      "ID: 8 | Epoch: 3/15 | Loss: 0.1311 | Attack_acc: 78.47%\n",
      "ID: 8 | Epoch: 4/15 | Loss: 0.0466 | Attack_acc: 84.14%\n",
      "ID: 8 | Epoch: 5/15 | Loss: 0.0159 | Attack_acc: 88.40%\n",
      "ID: 8 | Epoch: 6/15 | Loss: 0.0075 | Attack_acc: 88.89%\n",
      "ID: 8 | Epoch: 7/15 | Loss: 0.0064 | Attack_acc: 89.14%\n",
      "ID: 8 | Epoch: 8/15 | Loss: 0.0055 | Attack_acc: 89.18%\n",
      "ID: 8 | Epoch: 9/15 | Loss: 0.0038 | Attack_acc: 89.82%\n",
      "ID: 8 | Epoch: 10/15 | Loss: 0.0029 | Attack_acc: 90.15%\n",
      "ID: 8 | Epoch: 11/15 | Loss: 0.0036 | Attack_acc: 90.36%\n",
      "ID: 8 | Epoch: 12/15 | Loss: 0.0021 | Attack_acc: 90.61%\n",
      "ID: 8 | Epoch: 13/15 | Loss: 0.0025 | Attack_acc: 90.71%\n",
      "ID: 8 | Epoch: 14/15 | Loss: 0.0018 | Attack_acc: 90.93%\n",
      "ID: 8 | Epoch: 15/15 | Loss: 0.0020 | Attack_acc: 91.26%\n",
      "Test loss: 1.8479 | Test Acc: 55.47% | Attack Acc: 86.53%\n",
      "training the target model uses:  18.450568437576294\n",
      "ID: 9 | Epoch: 1/15 | Loss: 0.8791 | Attack_acc: 66.55%\n",
      "ID: 9 | Epoch: 2/15 | Loss: 0.3476 | Attack_acc: 77.38%\n",
      "ID: 9 | Epoch: 3/15 | Loss: 0.1247 | Attack_acc: 80.25%\n",
      "ID: 9 | Epoch: 4/15 | Loss: 0.0543 | Attack_acc: 82.57%\n",
      "ID: 9 | Epoch: 5/15 | Loss: 0.0290 | Attack_acc: 85.21%\n",
      "ID: 9 | Epoch: 6/15 | Loss: 0.0182 | Attack_acc: 88.71%\n",
      "ID: 9 | Epoch: 7/15 | Loss: 0.0072 | Attack_acc: 89.42%\n",
      "ID: 9 | Epoch: 8/15 | Loss: 0.0048 | Attack_acc: 89.67%\n",
      "ID: 9 | Epoch: 9/15 | Loss: 0.0064 | Attack_acc: 90.31%\n",
      "ID: 9 | Epoch: 10/15 | Loss: 0.0041 | Attack_acc: 89.55%\n",
      "ID: 9 | Epoch: 11/15 | Loss: 0.0032 | Attack_acc: 90.52%\n",
      "ID: 9 | Epoch: 12/15 | Loss: 0.0026 | Attack_acc: 90.79%\n",
      "ID: 9 | Epoch: 13/15 | Loss: 0.0028 | Attack_acc: 90.39%\n",
      "ID: 9 | Epoch: 14/15 | Loss: 0.0023 | Attack_acc: 90.83%\n",
      "ID: 9 | Epoch: 15/15 | Loss: 0.0024 | Attack_acc: 90.96%\n",
      "Test loss: 3.1348 | Test Acc: 48.20% | Attack Acc: 76.90%\n",
      "training the target model uses:  18.909919261932373\n",
      "Global epoch 8: Test loss: 1.4459 | Test Acc: 65.80%\n",
      "Global Epoch:  9\n",
      "ID: 0 | Epoch: 1/15 | Loss: 0.6724 | Attack_acc: 66.03%\n",
      "ID: 0 | Epoch: 2/15 | Loss: 0.3133 | Attack_acc: 77.22%\n",
      "ID: 0 | Epoch: 3/15 | Loss: 0.1118 | Attack_acc: 83.03%\n",
      "ID: 0 | Epoch: 4/15 | Loss: 0.0354 | Attack_acc: 83.16%\n",
      "ID: 0 | Epoch: 5/15 | Loss: 0.0162 | Attack_acc: 87.17%\n",
      "ID: 0 | Epoch: 6/15 | Loss: 0.0071 | Attack_acc: 88.15%\n",
      "ID: 0 | Epoch: 7/15 | Loss: 0.0047 | Attack_acc: 89.10%\n",
      "ID: 0 | Epoch: 8/15 | Loss: 0.0038 | Attack_acc: 89.57%\n",
      "ID: 0 | Epoch: 9/15 | Loss: 0.0031 | Attack_acc: 89.84%\n",
      "ID: 0 | Epoch: 10/15 | Loss: 0.0037 | Attack_acc: 89.97%\n",
      "ID: 0 | Epoch: 11/15 | Loss: 0.0033 | Attack_acc: 89.80%\n",
      "ID: 0 | Epoch: 12/15 | Loss: 0.0027 | Attack_acc: 90.27%\n",
      "ID: 0 | Epoch: 13/15 | Loss: 0.0026 | Attack_acc: 90.38%\n",
      "ID: 0 | Epoch: 14/15 | Loss: 0.0024 | Attack_acc: 90.69%\n",
      "ID: 0 | Epoch: 15/15 | Loss: 0.0026 | Attack_acc: 90.82%\n",
      "Test loss: 2.0636 | Test Acc: 54.93% | Attack Acc: 83.14%\n",
      "training the target model uses:  19.322711944580078\n",
      "ID: 1 | Epoch: 1/15 | Loss: 0.7393 | Attack_acc: 66.02%\n",
      "ID: 1 | Epoch: 2/15 | Loss: 0.3640 | Attack_acc: 74.67%\n",
      "ID: 1 | Epoch: 3/15 | Loss: 0.1101 | Attack_acc: 79.66%\n",
      "ID: 1 | Epoch: 4/15 | Loss: 0.0377 | Attack_acc: 86.52%\n",
      "ID: 1 | Epoch: 5/15 | Loss: 0.0137 | Attack_acc: 87.51%\n",
      "ID: 1 | Epoch: 6/15 | Loss: 0.0068 | Attack_acc: 88.44%\n",
      "ID: 1 | Epoch: 7/15 | Loss: 0.0048 | Attack_acc: 89.15%\n",
      "ID: 1 | Epoch: 8/15 | Loss: 0.0050 | Attack_acc: 89.68%\n",
      "ID: 1 | Epoch: 9/15 | Loss: 0.0032 | Attack_acc: 89.83%\n",
      "ID: 1 | Epoch: 10/15 | Loss: 0.0032 | Attack_acc: 90.26%\n",
      "ID: 1 | Epoch: 11/15 | Loss: 0.0026 | Attack_acc: 90.33%\n",
      "ID: 1 | Epoch: 12/15 | Loss: 0.0033 | Attack_acc: 90.18%\n",
      "ID: 1 | Epoch: 13/15 | Loss: 0.0023 | Attack_acc: 90.47%\n",
      "ID: 1 | Epoch: 14/15 | Loss: 0.0024 | Attack_acc: 90.72%\n",
      "ID: 1 | Epoch: 15/15 | Loss: 0.0023 | Attack_acc: 91.15%\n",
      "Test loss: 1.8531 | Test Acc: 56.33% | Attack Acc: 86.44%\n",
      "training the target model uses:  18.384166717529297\n",
      "ID: 2 | Epoch: 1/15 | Loss: 0.6758 | Attack_acc: 60.87%\n",
      "ID: 2 | Epoch: 2/15 | Loss: 0.2909 | Attack_acc: 71.57%\n",
      "ID: 2 | Epoch: 3/15 | Loss: 0.0870 | Attack_acc: 80.40%\n",
      "ID: 2 | Epoch: 4/15 | Loss: 0.0398 | Attack_acc: 83.63%\n",
      "ID: 2 | Epoch: 5/15 | Loss: 0.0238 | Attack_acc: 83.88%\n",
      "ID: 2 | Epoch: 6/15 | Loss: 0.0153 | Attack_acc: 86.07%\n",
      "ID: 2 | Epoch: 7/15 | Loss: 0.0090 | Attack_acc: 86.59%\n",
      "ID: 2 | Epoch: 8/15 | Loss: 0.0039 | Attack_acc: 87.66%\n",
      "ID: 2 | Epoch: 9/15 | Loss: 0.0042 | Attack_acc: 87.63%\n",
      "ID: 2 | Epoch: 10/15 | Loss: 0.0035 | Attack_acc: 87.97%\n",
      "ID: 2 | Epoch: 11/15 | Loss: 0.0022 | Attack_acc: 88.27%\n",
      "ID: 2 | Epoch: 12/15 | Loss: 0.0022 | Attack_acc: 88.33%\n",
      "ID: 2 | Epoch: 13/15 | Loss: 0.0020 | Attack_acc: 88.45%\n",
      "ID: 2 | Epoch: 14/15 | Loss: 0.0021 | Attack_acc: 88.80%\n",
      "ID: 2 | Epoch: 15/15 | Loss: 0.0025 | Attack_acc: 88.69%\n",
      "Test loss: 1.9322 | Test Acc: 57.53% | Attack Acc: 84.68%\n",
      "training the target model uses:  18.099817752838135\n",
      "ID: 3 | Epoch: 1/15 | Loss: 0.6687 | Attack_acc: 65.95%\n",
      "ID: 3 | Epoch: 2/15 | Loss: 0.3270 | Attack_acc: 69.59%\n",
      "ID: 3 | Epoch: 3/15 | Loss: 0.1187 | Attack_acc: 81.06%\n",
      "ID: 3 | Epoch: 4/15 | Loss: 0.0393 | Attack_acc: 83.82%\n",
      "ID: 3 | Epoch: 5/15 | Loss: 0.0173 | Attack_acc: 84.02%\n",
      "ID: 3 | Epoch: 6/15 | Loss: 0.0126 | Attack_acc: 87.05%\n",
      "ID: 3 | Epoch: 7/15 | Loss: 0.0076 | Attack_acc: 86.84%\n",
      "ID: 3 | Epoch: 8/15 | Loss: 0.0065 | Attack_acc: 87.63%\n",
      "ID: 3 | Epoch: 9/15 | Loss: 0.0052 | Attack_acc: 88.52%\n",
      "ID: 3 | Epoch: 10/15 | Loss: 0.0035 | Attack_acc: 89.16%\n",
      "ID: 3 | Epoch: 11/15 | Loss: 0.0029 | Attack_acc: 89.28%\n",
      "ID: 3 | Epoch: 12/15 | Loss: 0.0033 | Attack_acc: 89.44%\n",
      "ID: 3 | Epoch: 13/15 | Loss: 0.0028 | Attack_acc: 89.30%\n",
      "ID: 3 | Epoch: 14/15 | Loss: 0.0028 | Attack_acc: 89.36%\n",
      "ID: 3 | Epoch: 15/15 | Loss: 0.0025 | Attack_acc: 89.55%\n",
      "Test loss: 1.9792 | Test Acc: 56.27% | Attack Acc: 85.52%\n",
      "training the target model uses:  18.13389492034912\n",
      "ID: 4 | Epoch: 1/15 | Loss: 0.6456 | Attack_acc: 69.72%\n",
      "ID: 4 | Epoch: 2/15 | Loss: 0.3074 | Attack_acc: 66.68%\n",
      "ID: 4 | Epoch: 3/15 | Loss: 0.1444 | Attack_acc: 80.58%\n",
      "ID: 4 | Epoch: 4/15 | Loss: 0.0513 | Attack_acc: 81.98%\n",
      "ID: 4 | Epoch: 5/15 | Loss: 0.0204 | Attack_acc: 87.05%\n",
      "ID: 4 | Epoch: 6/15 | Loss: 0.0106 | Attack_acc: 88.53%\n",
      "ID: 4 | Epoch: 7/15 | Loss: 0.0061 | Attack_acc: 89.16%\n",
      "ID: 4 | Epoch: 8/15 | Loss: 0.0050 | Attack_acc: 89.09%\n",
      "ID: 4 | Epoch: 9/15 | Loss: 0.0047 | Attack_acc: 89.83%\n",
      "ID: 4 | Epoch: 10/15 | Loss: 0.0035 | Attack_acc: 90.15%\n",
      "ID: 4 | Epoch: 11/15 | Loss: 0.0023 | Attack_acc: 89.86%\n",
      "ID: 4 | Epoch: 12/15 | Loss: 0.0028 | Attack_acc: 90.06%\n",
      "ID: 4 | Epoch: 13/15 | Loss: 0.0024 | Attack_acc: 90.38%\n",
      "ID: 4 | Epoch: 14/15 | Loss: 0.0023 | Attack_acc: 90.70%\n",
      "ID: 4 | Epoch: 15/15 | Loss: 0.0018 | Attack_acc: 90.37%\n",
      "Test loss: 1.8236 | Test Acc: 57.00% | Attack Acc: 86.65%\n",
      "training the target model uses:  18.508568286895752\n",
      "ID: 5 | Epoch: 1/15 | Loss: 0.6294 | Attack_acc: 62.81%\n",
      "ID: 5 | Epoch: 2/15 | Loss: 0.3206 | Attack_acc: 74.70%\n",
      "ID: 5 | Epoch: 3/15 | Loss: 0.0929 | Attack_acc: 79.84%\n",
      "ID: 5 | Epoch: 4/15 | Loss: 0.0388 | Attack_acc: 84.74%\n",
      "ID: 5 | Epoch: 5/15 | Loss: 0.0148 | Attack_acc: 85.62%\n",
      "ID: 5 | Epoch: 6/15 | Loss: 0.0073 | Attack_acc: 87.42%\n",
      "ID: 5 | Epoch: 7/15 | Loss: 0.0074 | Attack_acc: 88.33%\n",
      "ID: 5 | Epoch: 8/15 | Loss: 0.0071 | Attack_acc: 88.28%\n",
      "ID: 5 | Epoch: 9/15 | Loss: 0.0037 | Attack_acc: 88.99%\n",
      "ID: 5 | Epoch: 10/15 | Loss: 0.0034 | Attack_acc: 89.08%\n",
      "ID: 5 | Epoch: 11/15 | Loss: 0.0035 | Attack_acc: 89.28%\n",
      "ID: 5 | Epoch: 12/15 | Loss: 0.0023 | Attack_acc: 89.45%\n",
      "ID: 5 | Epoch: 13/15 | Loss: 0.0024 | Attack_acc: 89.77%\n",
      "ID: 5 | Epoch: 14/15 | Loss: 0.0020 | Attack_acc: 89.66%\n",
      "ID: 5 | Epoch: 15/15 | Loss: 0.0016 | Attack_acc: 89.46%\n",
      "Test loss: 1.9063 | Test Acc: 57.07% | Attack Acc: 86.34%\n",
      "training the target model uses:  18.468255758285522\n",
      "ID: 6 | Epoch: 1/15 | Loss: 0.7657 | Attack_acc: 64.79%\n",
      "ID: 6 | Epoch: 2/15 | Loss: 0.3343 | Attack_acc: 73.74%\n",
      "ID: 6 | Epoch: 3/15 | Loss: 0.1318 | Attack_acc: 81.75%\n",
      "ID: 6 | Epoch: 4/15 | Loss: 0.0483 | Attack_acc: 81.71%\n",
      "ID: 6 | Epoch: 5/15 | Loss: 0.0143 | Attack_acc: 86.57%\n",
      "ID: 6 | Epoch: 6/15 | Loss: 0.0090 | Attack_acc: 87.19%\n",
      "ID: 6 | Epoch: 7/15 | Loss: 0.0056 | Attack_acc: 88.14%\n",
      "ID: 6 | Epoch: 8/15 | Loss: 0.0053 | Attack_acc: 87.89%\n",
      "ID: 6 | Epoch: 9/15 | Loss: 0.0047 | Attack_acc: 88.26%\n",
      "ID: 6 | Epoch: 10/15 | Loss: 0.0026 | Attack_acc: 88.78%\n",
      "ID: 6 | Epoch: 11/15 | Loss: 0.0028 | Attack_acc: 88.72%\n",
      "ID: 6 | Epoch: 12/15 | Loss: 0.0021 | Attack_acc: 89.42%\n",
      "ID: 6 | Epoch: 13/15 | Loss: 0.0028 | Attack_acc: 89.05%\n",
      "ID: 6 | Epoch: 14/15 | Loss: 0.0025 | Attack_acc: 89.81%\n",
      "ID: 6 | Epoch: 15/15 | Loss: 0.0020 | Attack_acc: 89.49%\n",
      "Test loss: 2.4534 | Test Acc: 53.07% | Attack Acc: 83.96%\n",
      "training the target model uses:  19.16194987297058\n",
      "ID: 7 | Epoch: 1/15 | Loss: 0.7527 | Attack_acc: 61.41%\n",
      "ID: 7 | Epoch: 2/15 | Loss: 0.3370 | Attack_acc: 71.31%\n",
      "ID: 7 | Epoch: 3/15 | Loss: 0.1281 | Attack_acc: 81.11%\n",
      "ID: 7 | Epoch: 4/15 | Loss: 0.0453 | Attack_acc: 83.42%\n",
      "ID: 7 | Epoch: 5/15 | Loss: 0.0256 | Attack_acc: 86.47%\n",
      "ID: 7 | Epoch: 6/15 | Loss: 0.0124 | Attack_acc: 86.93%\n",
      "ID: 7 | Epoch: 7/15 | Loss: 0.0066 | Attack_acc: 87.63%\n",
      "ID: 7 | Epoch: 8/15 | Loss: 0.0053 | Attack_acc: 88.71%\n",
      "ID: 7 | Epoch: 9/15 | Loss: 0.0036 | Attack_acc: 88.95%\n",
      "ID: 7 | Epoch: 10/15 | Loss: 0.0032 | Attack_acc: 88.94%\n",
      "ID: 7 | Epoch: 11/15 | Loss: 0.0028 | Attack_acc: 89.03%\n",
      "ID: 7 | Epoch: 12/15 | Loss: 0.0023 | Attack_acc: 89.54%\n",
      "ID: 7 | Epoch: 13/15 | Loss: 0.0026 | Attack_acc: 89.66%\n",
      "ID: 7 | Epoch: 14/15 | Loss: 0.0019 | Attack_acc: 89.80%\n",
      "ID: 7 | Epoch: 15/15 | Loss: 0.0017 | Attack_acc: 89.78%\n",
      "Test loss: 2.4876 | Test Acc: 51.20% | Attack Acc: 82.48%\n",
      "training the target model uses:  18.945029973983765\n",
      "ID: 8 | Epoch: 1/15 | Loss: 0.7168 | Attack_acc: 67.88%\n",
      "ID: 8 | Epoch: 2/15 | Loss: 0.2956 | Attack_acc: 76.01%\n",
      "ID: 8 | Epoch: 3/15 | Loss: 0.0869 | Attack_acc: 80.96%\n",
      "ID: 8 | Epoch: 4/15 | Loss: 0.0317 | Attack_acc: 84.85%\n",
      "ID: 8 | Epoch: 5/15 | Loss: 0.0166 | Attack_acc: 86.85%\n",
      "ID: 8 | Epoch: 6/15 | Loss: 0.0114 | Attack_acc: 87.31%\n",
      "ID: 8 | Epoch: 7/15 | Loss: 0.0061 | Attack_acc: 88.62%\n",
      "ID: 8 | Epoch: 8/15 | Loss: 0.0040 | Attack_acc: 89.86%\n",
      "ID: 8 | Epoch: 9/15 | Loss: 0.0041 | Attack_acc: 89.90%\n",
      "ID: 8 | Epoch: 10/15 | Loss: 0.0026 | Attack_acc: 90.30%\n",
      "ID: 8 | Epoch: 11/15 | Loss: 0.0031 | Attack_acc: 89.19%\n",
      "ID: 8 | Epoch: 12/15 | Loss: 0.0024 | Attack_acc: 90.57%\n",
      "ID: 8 | Epoch: 13/15 | Loss: 0.0020 | Attack_acc: 90.66%\n",
      "ID: 8 | Epoch: 14/15 | Loss: 0.0020 | Attack_acc: 90.93%\n",
      "ID: 8 | Epoch: 15/15 | Loss: 0.0021 | Attack_acc: 90.34%\n",
      "Test loss: 1.8486 | Test Acc: 55.73% | Attack Acc: 87.57%\n",
      "training the target model uses:  18.56642746925354\n",
      "ID: 9 | Epoch: 1/15 | Loss: 0.8146 | Attack_acc: 60.55%\n",
      "ID: 9 | Epoch: 2/15 | Loss: 0.3802 | Attack_acc: 72.97%\n",
      "ID: 9 | Epoch: 3/15 | Loss: 0.1276 | Attack_acc: 80.43%\n",
      "ID: 9 | Epoch: 4/15 | Loss: 0.0529 | Attack_acc: 83.49%\n",
      "ID: 9 | Epoch: 5/15 | Loss: 0.0294 | Attack_acc: 83.43%\n",
      "ID: 9 | Epoch: 6/15 | Loss: 0.0122 | Attack_acc: 88.43%\n",
      "ID: 9 | Epoch: 7/15 | Loss: 0.0055 | Attack_acc: 88.38%\n",
      "ID: 9 | Epoch: 8/15 | Loss: 0.0042 | Attack_acc: 89.05%\n",
      "ID: 9 | Epoch: 9/15 | Loss: 0.0037 | Attack_acc: 89.05%\n",
      "ID: 9 | Epoch: 10/15 | Loss: 0.0037 | Attack_acc: 89.55%\n",
      "ID: 9 | Epoch: 11/15 | Loss: 0.0043 | Attack_acc: 89.16%\n",
      "ID: 9 | Epoch: 12/15 | Loss: 0.0032 | Attack_acc: 89.95%\n",
      "ID: 9 | Epoch: 13/15 | Loss: 0.0024 | Attack_acc: 90.22%\n",
      "ID: 9 | Epoch: 14/15 | Loss: 0.0025 | Attack_acc: 90.13%\n",
      "ID: 9 | Epoch: 15/15 | Loss: 0.0024 | Attack_acc: 90.66%\n",
      "Test loss: 2.5120 | Test Acc: 50.27% | Attack Acc: 82.83%\n",
      "training the target model uses:  18.24434995651245\n",
      "Global epoch 9: Test loss: 1.5403 | Test Acc: 64.33%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_clients = range(clients)\n",
    "split_index, flat_indice = FlatSplitParams(copy.deepcopy(glob_model), args.num_users)\n",
    "sec_record = []\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for j in range(glob_epochs):\n",
    "   print(\"Global Epoch: \", j)\n",
    "   drop_users = random.sample(all_clients, int(clients * drop_frac))\n",
    "   nondrop_users = [x for x in range(args.num_users) if x not in drop_users]\n",
    "   w_locals, weight_slices, noise_slices = [], [], []\n",
    "   for i in range(clients):\n",
    "      if i in drop_users:\n",
    "         weight_slices.insert(i, \"D\")\n",
    "         noise_slices.insert(i, \"D\")\n",
    "         continue\n",
    "      \n",
    "      if mechanism == 'None':\n",
    "        w = nor_train(copy.deepcopy(glob_model), device, i, learning_rate, local_epochs, train_loader[i], test_loader[i], train_data[i], train_targets[i], test_data[i],\n",
    "                      test_targets[i], audit_data[i], audit_targets[i], sec_record)\n",
    "      elif mechanism == 'DP':\n",
    "         w = dp_train(copy.deepcopy(glob_model), device, i, learning_rate, local_epochs, train_loader[i], test_loader[i], train_data[i], train_targets[i], test_data[i],\n",
    "                      test_targets[i], audit_data[i], audit_targets[i], sec_record, q, batch_size, clip, sigma, len(train_loader[i]))\n",
    "      elif mechanism == 'DP2':\n",
    "         w = dp_trainv2(copy.deepcopy(glob_model), device, i, learning_rate, local_epochs, train_loader[i], test_loader[i], train_data[i], train_targets[i], test_data[i],\n",
    "                        test_targets[i], audit_data[i], audit_targets[i], sec_record, eps, delta, glob_epochs, clip)\n",
    "      elif mechanism == 'Proposed':\n",
    "         w, weight_slice, noise_slice = proposed_train(copy.deepcopy(glob_model), device, i, learning_rate, local_epochs, train_loader[i], test_loader[i], train_data[i], train_targets[i], test_data[i],\n",
    "                                                       test_targets[i], audit_data[i], audit_targets[i], sec_record, eps, delta, split_index, flat_indice, clients)\n",
    "         weight_slices.insert(i, weight_slice)\n",
    "         noise_slices.insert(i, noise_slice)\n",
    "      w_locals.insert(i, copy.deepcopy(w))\n",
    "\n",
    "   if mechanism == 'Proposed':\n",
    "      for i, id in enumerate(nondrop_users):\n",
    "         ProtectWeight(w_locals[i], noise_slices, weight_slices, split_index, id, flat_indice, device)\n",
    "      loss_audit_results = sec_func(model, criterion, device, train_data[0], train_targets[0], test_data[0], test_targets[0], audit_data[0], audit_targets[0])\n",
    "      sec_record.append(loss_audit_results[0].roc_auc)\n",
    "    \n",
    "   new_glob_w = aggregate(w_locals, clients, device)\n",
    "   glob_model.load_state_dict(copy.deepcopy(new_glob_w))\n",
    "   randon_id = np.random.choice(range(clients), 1, replace=False)[0]\n",
    "   glob_loss, glob_acc = test(copy.deepcopy(glob_model), device, test_loader[randon_id])\n",
    "   print(f\"Global epoch {j}: Test loss: {glob_loss:.4f} | Test Acc: {glob_acc:.2f}%\")\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel('Attack Accuracy')\n",
    "plt.xlabel('Global Epoch')\n",
    "plt.plot(range(len(sec_record)), sec_record, label='{}'.format(\"No-DP\"))\n",
    "plt.title('{} Attack Accuracy'.format('Cifar'))\n",
    "plt.legend()\n",
    "plt.savefig('test.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrap the target model and datasets\n",
    "The `batch_size` parameter determines the number of samples used in each iteration when computing the signals. Larger batch sizes can increase computation speed, but they also consume more memory. If you're computing the loss, you can use a larger batch size, but if you're using the GPU to compute gradient information such as gradient norm, using a batch size that is too large may result in an Out Of Memory (OOM) error. This is largely dependent on the size of your model and the memory capacity of your GPU. As a general guideline, we recommend using a batch size of 10 when computing gradient information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m target_model \u001b[39m=\u001b[39m PytorchModelTensor(model_obj\u001b[39m=\u001b[39mmodel, loss_fn\u001b[39m=\u001b[39mcriterion, device\u001b[39m=\u001b[39mdevice,batch_size\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "target_model = PytorchModelTensor(model_obj=model, loss_fn=criterion, device=device,batch_size=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the dataset in the tensor formate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_dataset_subset(dataset: torchvision.datasets, index: List(int)):\n",
    "    \"\"\"Get a subset of the dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset (torchvision.datasets): Whole dataset.\n",
    "        index (list): List of index.\n",
    "    \"\"\"\n",
    "    assert max(index) < len(dataset) and min(index) >= 0, \"Index out of range\"\n",
    "    print(torch.from_numpy(dataset.data[index]).shape)\n",
    "    print(torch.from_numpy(dataset.data[index]).float().permute(0, 3, 1, 2).shape)\n",
    "    data = (\n",
    "        torch.from_numpy(dataset.data[index]).float().permute(0, 3, 1, 2) / 255\n",
    "    )  # channel first\n",
    "    targets = list(np.array(dataset.targets)[index])\n",
    "    targets = torch.tensor(targets, dtype=torch.long)\n",
    "    return data, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([600, 32, 32, 3])\n",
      "torch.Size([600, 3, 32, 32])\n",
      "torch.Size([600, 32, 32, 3])\n",
      "torch.Size([600, 3, 32, 32])\n",
      "torch.Size([1200, 32, 32, 3])\n",
      "torch.Size([1200, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "train_data, train_targets = get_dataset_subset(all_data, train_index)\n",
    "test_data, test_targets = get_dataset_subset(all_data, test_index)\n",
    "audit_data, audit_targets = get_dataset_subset(all_data, population_index)\n",
    "target_dataset = Dataset(\n",
    "    data_dict={\n",
    "        \"train\": {\"x\": train_data, \"y\": train_targets},\n",
    "        \"test\": {\"x\": test_data, \"y\": test_targets},\n",
    "    },\n",
    "    default_input=\"x\",\n",
    "    default_output=\"y\",\n",
    ")\n",
    "\n",
    "audit_dataset = Dataset(\n",
    "        data_dict={\"train\": {\"x\": audit_data, \"y\": audit_targets}},\n",
    "        default_input=\"x\",\n",
    "        default_output=\"y\",\n",
    ")\n",
    " \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Information Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_info_source = InformationSource(\n",
    "    models=[target_model], \n",
    "    datasets=[target_dataset]\n",
    ")\n",
    "\n",
    "reference_info_source = InformationSource(\n",
    "    models=[target_model],\n",
    "    datasets=[audit_dataset]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric and Audit \n",
    "We assess the privacy risk of our trained model using a population attack that is based on both the loss of the target model and the gradient norm of the target model. The results based on the loss indicate the privacy risk of the model in a black-box setting, where the adversary does not have access to the entire model. Conversely, computing the gradient norm per sample requires the adversary to have access to the entire model parameters, which corresponds to a white-box setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = PopulationMetric(\n",
    "            target_info_source=target_info_source,\n",
    "            reference_info_source=reference_info_source,\n",
    "            signals=[ModelLoss()],\n",
    "            hypothesis_test_func=linear_itp_threshold_func,\n",
    "        )\n",
    "audit_obj = Audit(\n",
    "    metrics=metric,\n",
    "    inference_game_type=InferenceGame.PRIVACY_LOSS_MODEL,\n",
    "    target_info_sources=target_info_source,\n",
    "    reference_info_sources=reference_info_source,\n",
    ")\n",
    "audit_obj.prepare()\n",
    "loss_audit_results = audit_obj.run()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py:1053: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    }
   ],
   "source": [
    "metric = PopulationMetric(\n",
    "            target_info_source=target_info_source,\n",
    "            reference_info_source=reference_info_source,\n",
    "            signals=[ModelGradientNorm()],\n",
    "            hypothesis_test_func=linear_itp_threshold_func,\n",
    "        )\n",
    "audit_obj = Audit(\n",
    "    metrics=metric,\n",
    "    inference_game_type=InferenceGame.PRIVACY_LOSS_MODEL,\n",
    "    target_info_sources=target_info_source,\n",
    "    reference_info_sources=reference_info_source,\n",
    ")\n",
    "audit_obj.prepare()\n",
    "gradient_norm_audit_results = audit_obj.run()[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This instruction won't be needed once the tool is on pip\n",
    "from privacy_meter import audit_report\n",
    "audit_report.REPORT_FILES_DIR = '../privacy_meter/report_files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAAsTAAALEwEAmpwYAABLbUlEQVR4nO3dd3gU5fbA8e9Jr6QDofdA6B1EaWJBEZRqwa54vTasP7127HrtHctFURARC4id3nvvoUMo6b1u3t8fu0CAlA1ks5vs+TxPHrKz78ycvAlzduadOa8YY1BKKaVK4+HsAJRSSrk2TRRKKaXKpIlCKaVUmTRRKKWUKpMmCqWUUmXSRKGUUqpMmiiUUkqVSROFqnFEZJ+I5IhIpogcFZFJIhJ0RpsLRGSuiGSISJqIzBKR2DPa1BKRd0TkgG1bu22vI6v2J1LKuTRRqJrqKmNMENAJ6Aw8ceINEekN/AX8AtQDmgIbgCUi0szWxgeYA7QFLgdqAb2BJKCHo4IWES9HbVupc6WJQtVoxpijwJ9YE8YJrwNfG2PeNcZkGGOSjTFPAcuB52xtbgIaAdcYY7YaY4qMMceNMS8YY34raV8i0lZE/haRZBE5JiL/sS2fJCIvFmvXX0QOFXu9T0T+T0Q2Alm27384Y9vvish7tu9DROQLETkiIodF5EUR8Ty/nlKqdJooVI0mIg2AwUCc7XUAcAEwvYTm3wOX2L4fBPxhjMm0cz/BwD/AH1jPUlpgPSOx13XAlUAo8B1whW2b2JLAaGCKre0koNC2j87ApcAdFdiXUhWiiULVVD+LSAZwEDgOPGtbHo717/5ICescAU6MP0SU0qY0Q4Cjxpg3jTG5tjOVFRVY/z1jzEFjTI4xZj+wFrjG9t5AINsYs1xE6gBXAOONMVnGmOPA28C1FdiXUhWiiULVVFcbY4KB/kBrTiWAFKAIiC5hnWgg0fZ9UiltStMQ2H1OkVodPOP1FKxnGQDXc+psojHgDRwRkVQRSQU+BWqfx76VKpMmClWjGWMWYL1U81/b6yxgGTCqhOajOXW56B/gMhEJtHNXB4FmpbyXBQQUe123pFDPeD0d6G+7dHYNpxLFQSAPiDTGhNq+ahlj2toZp1IVpolCuYN3gEtEpKPt9ePAzSJyv4gEi0iYbbC5N/C8rc1krAflGSLSWkQ8RCRCRP4jIleUsI9fgWgRGS8ivrbt9rS9tx7rmEO4iNQFxpcXsDEmAZgP/A/Ya4zZZlt+BOsdW2/abt/1EJHmItKvop2ilL00Uagaz3bQ/Rp4xvZ6MXAZMBzrOMR+rIPCFxpjdtna5GEd0N4O/A2kAyuxXsI6a+zBGJOBdSD8KuAosAsYYHt7Mtbbb/dhPchPszP0KbYYppyx/CbAB9iK9VLaD1TsMplSFSI6cZFSSqmy6BmFUkqpMjksUYjIlyJyXEQ2l/K+iMh7IhInIhtFpIujYlFKKXXuHHlGMQlr6YPSDAZa2r7GAR87MBallFLnyGGJwhizEEguo8kwrGUUjDFmORAqIjogp5RSLsaZBcjqc/pDRodsy856GlZExmE968DPz69ro0aNqiRAV1dUVISHhw4zQcl9UWSsXxYDFmMwxvqwQpHh5PfF/y067bUpZfnZDzwo5crqk0gtyWbDkfxEY0zUuWyjWlSqNMZMBCYCxMTEmB07djg5Itcwf/58+vfv7+wwqowxhrScAhIz80nMzLN+ZeSRmJnPxl378AkOJ8H2Oikrj4KCopPrllYxz8tD8PXywNfbEx8vD+v3J7888fXysC33xNf7jPdsr31s7c5cz9fbA29PDzxEqqaDbPZtXU+T2E5Vuk9X5bZ9ceJuVhFq7/gG37xk6l8zYf+5bs6ZieIw1rIHJzSwLVMKsCaGtQdS+Gb5AZbtSSIpM48Cy9mf5z1FCPI2ROZlERbgQ5voYMICIggL9CE8wJuwQB9C/L3x8/LEx3Zw9/OyJgZPj6o9iFeFND8hKtjX2WG4BHfsC8/MeCIX/oesFkPJjBmO6XY7Fk8PYMI5b9OZiWImcK+IfAf0BNJsT50qN5eVV8jP6w/zzfL9bDuSQYCPJ72bRRAV7Hvq4B/gQ1igD2EB3tTy92bPxlW06NjN2aEr5TymiOCtU4hY+iIUFZDd+OJK27TDEoWITMVakC3SVnv/WazFzDDGfAL8hrUKZhyQDdzqqFhU9bDjaAbfLN/Pj+sOkZVnoUXtIB66pCUXt66Dv49Ot6BUabzS9hE17xH8Dy8jp34fEga8TmFIk8rbfqVt6QzGmOvKed8A9zhq/6p6yCu08Mfmo3yzfD+r9qXg4+lBv5gohnaMJja6FlLF1/eVqo58krbjm7CZhP6vkxF7PVTy/5tqMZitap6DydlMXXmA71YdJDkrn3ohftzVtxmXt61LSIC3s8NTyuV5J23HN2ETma1Hkd3scg7UW0qRX7hD9qWJQlUZS5Fh4c4Evlm+n7k7jiNA72YRDO1Uj66Nw6r87iClqiVLPmFr3id0zftYAiLJanEVxsvPYUkCNFGoKpCYmcf3qw8yZcUBDqXkEB7gww09G3Fl+2jq1PJzdnhKVRu+R9cSNe8RfJJ3kNFqOEkXPo/xcvz/IU0UymFy8i18MG8XExfuocBi6NQwlNv6NKFPi0i8PfVBQaUqwjPzCPV+Go4lIJIjV35FTpNBVbZvTRTKIebvOM7TP2/mYEoOg9rU5vqejWgSYe9kcUqpE7xTd1MQ2hxLUDTHLvuYnAYXYnyCqzQGTRSqUh1Lz2XCr1uZvfEIDcP9eXNUBzo3CnN2WEpVOx55aYQvfYngrVM4cs0P5NbrRXazwU6JRROFqhSWIsM3y/fzxp87yC8s4tYLmjCme0N8vPQSk1IVFbD3LyIXPIFn9nHSOt9NXu2O5a/kQJoo1HnbfDiN//y0iY2H0ujaKJQHBrWkQViAs8NSqlqKnPsItbZNJS+iDUev+JJ8JycJ0EShzkNmXiFv/bWTSUv3Ehrgw5NXtGFg6yh9SE6piipWxC+vdgeSazUgtfM94OkazxRpolAVZozhzy1HeXbmFo6n53FVx3rccWFTgvz0z0mpivLMOEzUgsfJbDmMzJiRZLS7ydkhnUX/Z6sKOZqWy39+2sTc7cdpHhXI09fFEluvlrPDUqr6MUUEb5lMxNKXwVjIctJAtT00USi7ZeUVcuMXKziYks2/+jVjRJcGNbJMt1KO5pW6h6h5j+Ifv5zsBheROOB1Cmu57oRsmiiUXYwxPDZjI7sTMnltRAe6NtZbXpU6Vz7Ju/BJ3ErCgDfJaDOm0ov4VTZNFMouny/ay+yNR7jzoqaaJJQ6Bz6JW/BJ3EJm69FkN7uMg/WWUeQX6uyw7KKJQpVr6e5EXv1jO31bRnJt94blr6CUOsWSR9jqdwld+yGWgNpktRhqK+IX6uzI7KaJQpUpPjWHe6eso36oP49dHqO3vipVAb5HVxM19xF8UnaRETOSpAufrZIifpVNE4UqVV6hhbu/WUNugYW3RnUkwEf/XJSyl7WI30gKA2pzZMg35DQe4OyQzpn+z1elem7mVjYcSuO5obE0itAnrZWyh3fyLgrCW9qK+H1iK+IX5OywzosW4lElmrbqAFNXHuC6Hg3p2zLK2eEo5fI8clOJmvMQDaf2xy9+BQDZzS6v9kkC9IxClWDjoVSe/mULXRuHcVufps4ORymXF7DndyIX/AfPnCRSutzr9CJ+lU0ThTpNUmYed01eQ1iAN09d0UYfqFOqHFFzHiJ4+zTyIttydMjX5Ee1d3ZIlU4ThTqp0FLE/VPXkZSZz7vXdiIkwDUKkinlcooV8cut24WCkCakdr7bZYr4VTZNFOqk//61kyW7k3j00lbE1K3aGbSUqi680g8RueD/yGx5NZmtR5HRdqyzQ3I4HcxWAPy+6QifLNjNVR2iGdw+2tnhKOV6TBG1Nk2iwXcD8YtfiRQVOjuiKqNnFIq44xk8PH0DbaKDuWdAC2eHo5TL8U6JI2reI/gdWUV2w34k9n+NwlruU6VAE4Wby8gtYNzXa/Dx8uC5q9rq1KVKlcA7dQ/eybs4PvAtMluPdvkifpVNE4UbM8bw6PSN7E/K5o1RHYgK9nV2SEq5DJ+EzdYifm3GkN30Ug7euJQi3xBnh+UUmijc2PerD/LHlqPc3a8ZnRqGOjscpVyCFOYSuuptQtd9TGFgXbJaDrMW8XPTJAGaKNxWUZHh4/m7aVUniJFdGzg7HKVcgu+RVUTNfRif1N1ktB5DUp9nqmURv8qmicJN/bPtGPuSsnn6yjZaEVYpbEX8fh5FYWAdjlw1hZxG/ZwdksvQROGmJi7aQ91avvRtpXWclHvzTt5JQXgraxG/yyeSU78PxifQ2WG5FL3FxQ2tPZDC6n0pjOiqc14r9+WRm0LUnPE0nDoAv/jlAGQ3vVSTRAn0jMINfb5oD0G+XgxuV9fZoSjlFIG7ZxOx4Ek881JI6Xo/ebU7OTskl6aJws0cSMrmj81HGdO9oU5EpNxS1JzxBG+fTl5Ue45e9Q35Ue2cHZLL0yOFm/lyyV48RLimc31nh6JU1TmtiF838sNaktbpLvDQQ6A9HDpGISKXi8gOEYkTkcdLeL+RiMwTkXUislFErnBkPO4uNTufaasOcnGb2kQG6cN1yj14pR+g7szrCNoxHYCMtmNJ63KPJokKcFiiEBFP4ENgMBALXCcisWc0ewr43hjTGbgW+MhR8Sj4dsUBcgosjO7mPjVqlBsrstAo/lcaTB2I37G1p84qVIU5MqX2AOKMMXsAROQ7YBiwtVgbA9SyfR8CxDswHreWV2jhf0v20qNJGE0j9a4OVbN5J+8iat7D+B1dQ3ajgST0fxVLsF5uPVeOTBT1gYPFXh8Cep7R5jngLxG5DwgEBpW0IREZB4wDiIqKYv78+ZUda7WUmZlpd18sPFRAYmY+N7aCuA0rHRuYE+TmZNXIn+tcaF9AVNIq6iTuYG2Tf5FY/1LYcxg47OywnOZ8n6l19kW664BJxpg3RaQ3MFlE2hljioo3MsZMBCYCxMTEmP79+1d9pC5o/vz52NMXxhheenshLWr7MKR/lxr5JHbchpW06NjD2WG4BHftC5/jG/FN3EpG7LVADw5feBOJ27a5ZV+cydvz/EYZHDmYfRgofjG8AWen9NuB7wGMMcsAPyDSgTG5pcOpOew6nsnlbevWyCSh3JsU5hC+7GXq/zCE0NXvIIW5ABgfnaWxsjgyUawCWopIUxHxwTpYPfOMNgeAiwFEpA3WRJHgwJjc0vqDqQC0q1+r7IZKVTN+8cup/90lhK79kIzWozk85k8t4ucADrv0ZIwpFJF7gT8BT+BLY8wWEZkArDbGzAQeBj4TkQexDmzfYozemlDZ1h1IxcfLg2Y6iK1qEM/MI0T/MobCoHrED/2O3IYXOTukGsuhYxTGmN+A385Y9kyx77cCfRwZg7KeUbSsHYTXeV6nVMoVeCdtoyCijbWI3+DPrUX8vAOcHVaNpkeOGi6/sIjNh9OIjdbLTqp688hJJurv+2j43aBTRfyaXKJJogo4+64n5WDbj6aTV1hEm2gd2FPVlDEExs0ictFTeOSlkdL9IXLrdHZ2VG5FE0UNd2Igu7WeUahqKmrOAwTvmEFu7Y4kDJtGQUQbZ4fkdspMFCLiBwwBLgLqATnAZmC2MWaL48NT52v9gVTCA32oE6y1nVQ1UryIX73e5EfEktbxDq3P5CSl9rqIPI81ScwHVgDHsd6+2gp41ZZEHjbGbKyCONU5WnsghTZ1g/X5CVVteKXtJ2reo2TEjCCzzRgyYq9zdkhur6z0vNIY82wp770lIrWBRg6ISVWS1Ox89iVlM6hNHWeHolT5iizU2vQl4ctfA/Eko/VIZ0ekbEpNFMaY2aW9JyKNjDEHsJ5lKBd1YnxCB7KVq/NO3knU3IfwO7aOrMYXk9j/VSxB9ZwdlrIpb4yiN9bifguNMcdFpAPwONYxC61V7eLWH0xFgJi6miiUa/NKP4B32n6OXfIhWS2HnX8VO1WpSn2OQkTeAL4ERgCzReRF4C+s4xUtqyY8dT7WHUilSWSgTnmqXJLvsfUEb/kWgJwmgzhw4zKyWl2tScIFlXUEuRLobIzJFZEwrCXD2xlj9lVJZOq8GGPYcDCVC5pHODsUpU4jBTmErXyDkA2fURjcgMyYERgvP4xPkLNDU6UoK1HkGmNyAYwxKSKyS5NE9bEvKZvUnALa6PMTyoX4HV5K1NxH8U7fR3rbsST1flKL+FUDZSWKZiJyotqrAE2LvcYYM9Shkanzsu5ACqAD2cp1eGbGEz3zOgqDGhA/7HtyG2iZt+qirEQx7IzX/3VkIKpyrT+Yir+PJ40jtGKsci6fxC3kR7bFElSPo4O/JLf+BRhvf2eHpSqgrNtjF4hIJ6AFsMUYs63KolLnbd2BVGLqBOPpoQODyjk8cpKIXPQMQbt+Jv7qH8it35ucJhc7Oyx1Dsq66+kZrLPPnbjr6c4qi0qdl9wCC9uOpOtlJ+UcxhC482caTulP4O7ZJPd4hNy6XZ0dlToPZV16GgN0MsZki0gE8AfwWdWEpc7Hlvg0CosMberqQLaqelH/3E/wzh/JrdOZhAFvUhAR4+yQ1HkqK1HkGWOyAYwxSSKic1dUE39uOQboQLaqQqYIEGsRv/oXkB/VnrQOt4OHp7MjU5WgInc9Nde7nlzfij1JfL5oD5e1rUNEkFaMVY7nlbqXqPmPktlqJBmx12oRvxpI73qqQdKyCxg/bT3RIf7cN7CFs8NRNV1RISEbPidsxRsYTx9MG00QNVVZieJWY8wtVRWIOj/GGJ74aSPHM/J4/7pOWrZDOZR30nZrEb/jG8hqehmJ/V7GEljX2WEpBynraNKhyqJQ52366kP8tukod17UlNY6iK0czCvjMN4Zhzh26UdktRiq9ZlquLISRYCIdMY6PnEWY8xax4SkKmp3QibPztxC50ahjOmuRX2VY/geXYtP0lYy2o4lp8nFHBi7DOOjD3S6g7ISRX3gTUpOFAYY6JCIVIXkFxbxwNR1eHsKj1/eGg/9ZKcqmRRkE7bidUI2fE5hrcZktB4Fnr6aJNxIWYkizhijycDFvfnXDjbHpzNhaFuidF5sVcn8Di0mat5jeKfvJ63dTST3/g946t+Zu9ERz2psS6KFT1fv4aoO0VzYMtLZ4agaxjMznuhZN1AQ3JD4a2aQW6+Xs0NSTlJWovi/KotCVVhyVj6fbcqjUXgAd/dv7uxwVA3ik7CZ/Kh21iJ+V0wit34vjJcW8XNnZT1tfZ+IXCUi3me+ISLNRGSCiNzmwNhUKYwxPPbDRjLzDU9d2QY/b336VZ0/z+wEav/5Lxp8fxl+h5cBkNN4gCYJVeYZxZ3AQ8A7IpIMJAB+QBNgN/CBMeYXh0eozvLNigP8s+0Yo1t506K2zgqmzpMxBO38kYhFz+BRkE1yz8fIrdvN2VEpF1JWmfGjwGPAYyLSBIgGcoCdJ2pAqaq381gGL/66lR5NwhjYMMfZ4agaoPbf9xC06xdy63a1FvELb+nskJSLsWsw2zYF6j6HRqLKlVtg4b6p6wjw8eSxy1uTHLfe2SGp6qpYEb/shv3IrdOV9Pa3aBE/VSKtCFuNvPr7dnYczeDRy2IID/RxdjiqmvJO3U30z6MI3vYdAJltxpDeUSu9qtLp7bHVxNztx5i0dB/Du9SnV7MIZ4ejqqOiQkLWTyRs5ZsYL1+KvPycHZGqJuxKFCLiDzQyxuxwcDyqBGk5BTwyfSPNowIZd1EzZ4ejqiGfxK1EzX0Y34SNZDUbTGLfl7AE1nF2WKqaKPfSk4hcBazHOsMdItKp+LwUyvEW7EwgOSuf+we2xMdLrxaqivPMPIJnZjzHLvuUY5d/pklCVYg9R53ngB5AKoAxZj3Q1J6Ni8jlIrJDROJE5PFS2owWka0iskVEptgVtZtZvCuBIF8vYutpVVhlP98jqwje/DUAOU0u5uCNy8hqMUQrvaoKs+fSU4ExJk1O/+My5a0kIp7Ah8AlwCFglYjMNMZsLdamJfAE0McYkyIitSsUvRswxrBoVyKdG4Xi6aH/wVX5PC05RCx6hlobv6QwpDEZbcZYi/h5Bzg7NFVN2ZMotojI9YCn7cB+P7DUjvV6YC0suAdARL7DOmve1mJt7gQ+NMakABhjjlckeHewNzGLI2m5Wj5c2cX/wAIuWPsAfnmJpLe/heRej2sRP3Xe7EkU9wFPAnnAFOBP4AU71qsPHCz2+hDQ84w2rQBEZAngCTxnjPnjzA2JyDhgHEBUVBTz58+3Y/c1w5wDBQBEZh8gbsOh097LzckibsNKZ4TlcrQvwDcvkYtW/4ssn9qsav8iqSGxsG1r+SvWYPp3YXW+VxvtSRRXGmOexJosbDuVUcD089v1yf23BPoDDYCFItLeGJNavJExZiIwESAmJsb079+/EnZdPUz5ejV1Q9Lo3asHZ1z+I27DSlp07OGkyFyLO/eFz/GN5Ne2Tkh5LPobtiR60KzzhWg9Yff+uyjO2/P8boKxZ+0n7Fx2psNA8eslDWzLijsEzDTGFBhj9gI7sSYOBRRaili6O4mujcLOShJKeWYdp/Yf42gwffCpIn4N+1LkoQ9jqspV6hmFiAwGrgDqi8h7xd6qBRTase1VQEsRaYo1QVwLXH9Gm5+B64D/iUgk1ktRe+yOvobbeDiNzLxCujYOdXYoypUYQ9CO6UQsfh4pzCG51+NaxE85VFmXnuKB1cBQYE2x5RnAg+Vt2BhTKCL3Yh3T8AS+NMZsEZEJwGpjzEzbe5eKyFbAAjxqjEk6tx+l5lm8KxEBOjcMc3YoyoXU/utuguJmkRvdnYQB/6UgrIWzQ1I1XFnVYzcAG0RkijGm4Fw2boz5DfjtjGXPFPveYC1l/tC5bL+mWxyXSIs6QYQEnDUliHI3xYv4NR5IbnRP0tvfDKIPYCrHs+evrImI/GB7KG7PiS+HR+bmsvIKWXcgha6N9GzC3XmnxFHvp+EEb5sKQGbr0aR3uFWThKoy9tz19D/gWeBtYABwK1p11uFW7k2mwGLo1lgThduyFBC6/hNCV72N8fKnyDvQ2REpN2VPovA3xswRETHG7AeeE5E1wDPlrajO3aJdifh4edCufoizQ1FO4JOwmai5D+GbuIXM5leSdNGLWAK1cIFyDnsSRZ6IeAC7bIPThwGdf9PBFscl0L5+iBYBdFOe2Ql4Zidw9PLPyG5+hbPDUW7OnqPQA0AA1tIdXYGxwM2ODMrdHU/PZeexTLo2CnV2KKoK+cavpNamSQDkNB7AwbFLNUkol1DmGYWtsN8YY8wjQCbW8QnlYIvjEgHoquMTbkHyMwlf/gohmyaRH9KU9NjrbEX8/J0dmlJAOYnCGGMRkQurKhhltXBnAiH+3jSvrVf4ajr/A/OJnPcYXpnxpHW4neSe/6dF/JTLsWeMYp1toqLpQNaJhcaYHx0WlRvLLbDw97Zj9GsZhYeW7ajRPDMOU3f2zRSENCF++E/kRXd3dkhKlcieROEHJAEDiy0zgCYKB5i/I4GsPAsDWusdLjWSMfge30BenU5YgutzdMhkcqN7YHT+auXCyk0Uxhgdl6hCszbGExrgTaeGoc4ORVUyz6xjRC58ksA9vxN/9Q/k1u9NTsO+zg5LqXLZc0ahqkhWXiFzth3jsti6OptdTWIMwdumEb50AlKYR1LvJ8nVy0yqGtFE4ULmbD9ObkER/VtHOTsUVYlq/3kXQbtnk1OvF4kDXqcgtLmzQ1KqQjRRuJBZG+KJDPKhvT6NXf0VWazTiokH2U0uIadBHzLa3qj1mVS1VO5frYjUEZEvROR32+tYEbnd8aG5l/TcAubvOE6/Vnq3U3XnnbyTej9dQ/DWE0X8RpHRTiu9qurLnr/cSVjnjahne70TGO+geNzWX1uOUWAxDNS7naovSwGhq9+hwbTL8E7dQ5FPsLMjUqpS2HPpKdIY872IPAEnJySyODgutzNrQzx1Q/xoXVcPLtWRT8JmouaMxzdpG5kthpJ40QsUBeis1apmsCdRZIlIBNZnJxCRXkCaQ6NyM8lZ+SyJS2Rk1wY6N3Y15ZmdgGduCkcHf0l2s8ucHY5SlcqeRPEwMBNoLiJLgChgpEOjcjN/bD5KYZFedqpu/OKX45O0nfT2t9iK+C3GeGl9JlXz2PPA3RoR6QfEAALsONepUVXJZm2Ip2GYP82jdGKa6kDyM4hY+hK1tkwmP7TZqSJ+miRUDWXPXU8bgceAXGPMZk0Slet4ei7L9yYxIKa2XnaqBvz3/UPDqQMI3vINqR3v5PDoP7WIn6rx7Lnr6SqgEPheRFaJyCMi0sjBcbmN3zYdwRj0IbtqwDPjMHV/v50i72DiR/xC8oXPYbwDnB2WUg5XbqIwxuw3xrxujOkKXA90APY6PDI38evGIzSLDKRJhF52cknG4Ht0NQCW4PocuepbDo35g7y6XZ0cmFJVx64ngESksYg8BnwHtMZ6KUqdp0Mp2azen0L/GD2bcEWeWUep89tt1J8xDL/DywDIbXChXmpSbqfcwWwRWQF4Y52PYpQxZo/Do3ITXyzei6eHMCi2jrNDUcUZQ/C2qYQveQGx5JN0wdNaxE+5NXtuj73JGLPD4ZG4maTMPKauPMCgNrWpW0vnInAldf4YR+Ce38ip15uEAW9QGNrU2SEp5VSlJgoRGWuM+Qa4UkSuPPN9Y8xbDo2shvtyyV7yCoq4rrveF+ASihXxy2p2GdkN+5LR9gatz6QUZZ9RnBhdLammhHFALG4jPbeAr5bu56JWkTSK0LtmnM07aTtR8x4ho811ZLS9gcwYfZ5UqeJKTRTGmE9t3/5jjFlS/D0R6ePQqGq4ycv2k5lXyPU99GzCqSz5hK75gLA171HkE0SRr5Z3V6ok9oxRvA90sWOZskNOvoUvFu+lR5MwWtXRAoDO4nN8I7XnPIhP8nYyWl5D0kXPU+Qf4eywlHJJZY1R9AYuAKJE5KFib9UCPB0dWE313aoDJGflc8OQWGeH4tY8c1PwyE/j6JWTyG5yibPDUcqllXVG4QME2doU/+ibjhYFPCf5hUV8unAPHRqE0L6BXuaoan6Hl+KTuI30jreT06gfB29YjPHSO86UKk9ZYxQLgAUiMskYs78KY6qxflp3iKNpuYy/uKWzQ3ErkpdOxNIXqbX1W/LDWpDebqytiJ8mCaXsUdalp3eMMeOBD0TkrLucjDFDHRlYTWMpMnw0fzct6wTRvUmYs8NxGwF7/yJywRN4Zh8ntdNdpPR4VJ+sVqqCyrr0NNn273+rIpCabuGuBPYnZfPMkFitEltFPDMOU+ePceSHteDY4C/Iq9PJ2SEpVS2Vdelpje3fBSeWiUgY0NAYs7EKYqtR/tpyDH8fTy5ornfWOJStiF9edHdrEb+hU8it2w08fZwdmVLVlj3zUcwXkVoiEg6sBT4TEbueyhaRy0Vkh4jEicjjZbQbISJGRLrZH3r1UVRk+GfrMbo3CcPHS5/0dRTPzHjq/HYL9X+8+lQRv/oXaJJQ6jzZc9QKMcakA8OBr40xPYFB5a0kIp7Ah8BgIBa4TkTOuidURIKBB4AVFQm8OtlwKJWEzDz6NI90dig1kymiwZE/aThlAP6HFpPU51lyo3s4Oyqlagx7EoWXiEQDo4FfK7DtHkCcMWaPMSYfa4nyYSW0ewF4DcitwLarlb+3HsNThJ5Nw50dSo1U5/c7id39CXm1O3Lo2rmkdRoHHvqoj1KVxZ4nsycAfwJLjDGrRKQZsMuO9eoDB4u9PgT0LN5ARLpgHfOYLSKPlrYhERkHjAOIiopi/vz5duzedfy8OpsWocLxnes4Xonbzc3JIm7DykrcYvUhxoLBVsTPOwZL4/ocb3Al7DsGHHN2eE7lzn8XZ9K+sDrf+2fKTRTGmOlY56I48XoPMOL8dgsi4gG8BdxiRwwTgYkAMTExpn///ue7+yqzLzGL+D/mc8+AZrTo2KBStx23YSUtOrrfJRafxK1Eniji1+5GoIfb9kVJtC9O0b6w8vY8v7FRewazG4jITyJy3PY1Q0TsOeIdBhoWe93AtuyEYKAdMF9E9gG9gJk1bUD7n23WT7c6PlEJLHmErfgv9acPxjvjEBatzaRUlbDn0tP/gCnAKNvrsbZl5RXIWQW0FJGmWBPEtVjn3AbAGJMGnDx6ish84BFjzGp7g68O/tp6jOZRgdQN0aeAz4fvsfVEzXkQn5SdZLQaTtKFz1Pkr2M+SlUFe85Hoowx/zPGFNq+JgHlTvJsjCkE7sU6vrEN+N4Ys0VEJoiIWzzVnZyVz+p9yfTWZyfOm0deGh4FmRy58msSLnlfk4RSVcieM4okERkLTLW9vg5IsmfjxpjfgN/OWPZMKW3727PN6mTu9uMUGb3sdK78Di3GJ2k76R3vIKdRPw6MXazlN5RyAnvOKG7DemvsUdvXSOBWRwZVU/y+6QhRwb60qhPk7FCqFY+8NCLnPUq9X8ZQa8s3YMmzvqFJQimnsOeup/2AW1wqqkyJmXnM35nAqK4NtLZTBQTs+dNaxC8ngdTOd5PS42FNEEo5mT13PTUTkVkikmC76+kX27MUqgwz18djKTJcElvH2aFUG54Zh6nz511Y/MM5PPJXki94CuPl7+ywlHJ79lx6mgJ8D0QD9bA+UzG1zDUUP649RKs6QTSNDHR2KK7NGPzirdVbLMH1OTLsOw6P+o382h2dHJhS6gR7EkWAMWZysbuevgH0Xs8y7DyWweb4dC7Vs4kyeWYcpu6vN1Hvp+GnivjV66VF/JRyMfbc9fS7rfLrd4ABxgC/2arJYoxJdmB81dKPaw/jKcKA1rWdHYprMkUEb5lMxNKXwBSReOEELeKnlAuzJ1GMtv171xnLr8WaOHS8ohhLkeGndYfo3jSMsAD9ZFySOr/fQeDeP8lu2JfE/q9TWKth+SsppZzGnruemlZFIDXF0t2JHEvP466+zZ0dimspKgTxAPEgs8VQsppeRmbr0edfrUwB8NXEj8jMSAMgPTmRWv/McXJEruFEXwQFh3DzuH87O5xqy54zClUBk5bsIzTAW2eyK8YncQtRcx8mPfZ6MtrdRFarq50dUo2TmZHGU08/C0DyscOE16nv5Ihcw4m+ePGF550dSrWmiaIS7U7IZM7249zUu7HOZAfWIn6r3yV07YdYfEOxBOiYjVLVkSaKSvTl4r34eHowrFM9Z4fidL7H1hE1Zzw+KXFkxIwk6cLnKPILc3ZYSqlzYM8DdyIiY0XkGdvrRiKit6icITkrnxlrDzEotrYOYgMe+RlIYS5HrvqWhEHvapJwktmzfiE8yJedO7afXLZ44QKuHXn1ae3uuesOfvnpRwAKCgp4/pkn6dYxlv59enLpwL78/dcf5x3L2/99na4d2tCjczvm/PNXiW0WzJtL/z496du7O4MvGcCe3XEA/O/zifTp0eXk8u3btp1cZ8vmTVw6sC+9u3WiT48u5ObW2Mkyncae6yMfAb2xFgMEyMA6F7YqZsqK/eQWFDGiS+VOTlSd+B9YQMj6iQDkNOzLwRsWktOov3ODcnMzpn9Pr959mDH9e7vXefmF5zh29ChLVq5j/pIVfDN1OpkZmecVx/Zt2/jxh+9Zumo903+axaMP3o/FYjmr3SMP3senX0xi4bJVjBw1hjdffxWAEaOvZcnKtSxctor7xz/EU09YJ8QsLCzkrttv4a13P2DZ6vXM+v1vvL29zytWdTZ7EkVPY8w92Oa0NsakAPqRuZi8QgtfLd1PjyZhbvkktkduKlFzHiJ61vUEb/tOi/i5iMzMTFYsW8p7H33CTzPsSxTZ2dl8PelLXv3v2/j6Wn9/tevU4ZoRI88rlt9nz2L4yNH4+vrSuElTmjZrzprVq85qJyJkZGQAkJ6eTt3oaABq1ap1Ksas7JP10+bN+Zu27drTrn0HAMIjIvD01PnSK5s9YxQFIuKJ9ZkJRCQKKHJoVNXMrA1HSMjM49HLWjk7lCoXsPs3Ihc+iWdOEild7iW1+4OaIFzE77NnMfCSS2nRshVh4RGsX7eWTp27lLnO3j27adCg4WkH5tL85/8eYfHCBWctHz5yNOMffvS0ZUfiD9OtR8+Tr+vVb8CR+Piz1n33g08YM2IYfn7+BAcH89e8RSff+/zTj/nog3fJzy/gl9nWS2FxcbsQEUYMu5KkxESGjxzF/Q8+Um7sqmLsSRTvAT8BtUXkJaxlxp9yaFTViDGGzxftoWlkIF0bu9d1eM+Mw9T569/kh7fi6JDJ5Ee1c3ZIqpgZ06dx17/vBWD4iFHMmD6NTp27lFrNuKJVjl9+7b/nHeOZPv7gPabN+IVu3Xvw3jtv8tQTj/Heh58AcMddd3PHXXfzw/ff8ebrr/LRxC8oLCxk+bIlzFmwFP+AAK4ecjkdO3Wh34CBlR6bO7PngbtvRWQNcDEgwNXGmG3lrOY2lu5OYvvRDB69LMY9yokbg1/8cnLr98YSXJ/4Yd+TV6czeOp1YVeSkpzMogXz2bplCyKCxWJBRJjw0quEhUeQmpp6evuUZCIiImjarDmHDh0kPT293LOKipxRRNerz+FDh06+jj98iOh6p98dmJiQwObNG+nW3XqvzPARoxh59VUlbv/h8fcBUK9eAy7ocxERkdbJwS659HI2bFiniaKS2XPXUyMgG5gFzASybMsU8PmiPYQH+nCxG9R18ko/RN1fx1Lv55Eni/jl1euhScIF/fLzj4y+9no2btvFhq072bxjN40bN2HZksU0b9GCo0fi2bHd+nnv4IH9bN60ifYdOhIQEMDYm27hicceJj8/H7AewH/+ccZZ+3j5tf+ycNmqs77OTBIAl18xhB9/+J68vDz279vLnt1xdO3W/bQ2oWFhpKelE7drJwDz5s6hVUxrAHbH7TrZ7q8/fqN58xYAXDzoErZu2Ux2djaFhYUsXbyQ1q3bVEIPquLsufQ0G+v4hGCtGtsU2AG0dWBc1ULc8Qzm7Ujg1gua1OwH7EwRtTZ9RfiylwFIvOhFcuv1LGcl5Uw/Tv+e+x96+LRlVw27mhnTp3HBhRfxyeeTuPfuceTl5uLt7c27H35MrZAQAJ585nlemvAsvbt1xNfXj4DAQJ54qsQZjO3WJjaWq4ePpHe3jnh5efH6W++eHHQePXwo7374CdHR9Xjng4+5+YZr8fDwIDQ0jPc//hSAzz79mAXz5uLt7U1oaBgffvoFYE0u/77vAS7uewEiwiWXXc6ll19xXrGqs4kxpmIriHQB/m2MucMxIZUtJibG7Nixwxm7PssTP25kxtrDfHdnT0Kd8OxE3IaVtOjo+Eda6sy+hcB9f5PdqD+J/V6jsJbr3QJcVX3hqj588xUt4VGC4iU87nn4CWeH4zTenh40ighcY4zpdi7rV/jJbGPMWhFx+4+TSZl5zFh7mEtj6zglSTicpQA8PK1F/FpeTVbzK8mMGalF/JRyQ+UmChF5qNhLD6ALcPZ9bW5m6soD5BcWMaJLzfvk5pOwmai5D5ERez3p7W/RIn5KuTl7ziiCi31fiHXM4uyRLTdijGH6mkN0ahhK44ia84CdFOYSuuptQtd9jMU/gsIgrVmllConUdgetAs2xugTLMWsPZDC/qRsxnSrORPu+B5dYy3il7qHjNZjSOrzDEV+oc4OSynlAkpNFCLiZYwpFJE+VRlQdfDDmsP4eXvQt1Wks0OpNFKQjRQVcmToVHIa9nV2OEopF1LWGcVKrOMR60VkJjAdyDrxpjHmRwfH5pJyCyz8ujGeC1tEEuBTvau0+x+Yj0/SdtI6/4vchhdx8PoF4FkDB+bdQFBwyMnJedKTE6kVXnM+xJyPE30RFBzi7FCqNXuOdH5AEjCQU89TGMAtE8U/246RkVvIZW3rOjuUc+aRm0LEkucJ3j6dvIg2pHW4zZogNElUW8Wn+XT3W4WL076oHGUlitq2O542cypBnFCxhy9qkBlrDhEV7EunhqHODqXijCFw92wiFj6JZ14qKd0eIKXbA5oglFJlKitReAJBnJ4gTnDLRHE8I5eFuxIZ3a0Bnh7V73kCr4zD1P77XvIjWnP0qm+1iJ9Syi5lJYojxpgJVRZJNTBzfTyWIsOlsXWcHYr9jMHv8BJyG1xIYa0GxF893VrEz6N6j68opapOWQWKqt9HZgc6npHL18v207pucLV5dsIr/QB1Z15HvV/GnCriF91dk4RSqkLKOmJcXGVRuLjDqTnc8Nlyjmfk8srw9s4Op3xFFmpt+h/hy18F8SSh3ytaxE8pdc5KTRTGmOSqDMRV7UnI5IbPV5CRW8jrIzrQrr7r32ZX57dbCdw/h+zGA0no9yqW4JpXZkQpVXX0GkQZth1JZ+znK7AYw1ujO9KidpCzQypd8SJ+MSPIank1ma2u0SJ+Sqnz5tBJFETkchHZISJxIvJ4Ce8/JCJbRWSjiMwRkcaOjKci1h1IYcyny/DwEN4Z3cmlk4TP8Q3Unz6YWpu/BiCr5TAyY4ZrklBKVQqHJQpbnagPgcFALHCdiMSe0Wwd0M0Y0wH4AXjdUfFUxNLdidzw+QqC/bx4d0wnGkUEODukEnlY8ghf+iL1fxiCZ04yhXqJSSnlAI689NQDiDPG7AEQke+AYcDWEw2MMfOKtV8OjHVgPHbZdiSd2yatom4tP94Y2YGIIF9nh1Qi36Or6b3uQQJzj5AeewPJFzxJka/rj58opaofRyaK+sDBYq8PAWXdenM78HtJb4jIOGAcQFRUFPPnz6+kEE+XXWB4flkOvmK4N7aIlN0bSHHIns5feOpGQo2F1e2eJzm0A2x3jVn/nCU3J4u4DSudHYZL0L44RfvC6nyvQrvEYLaIjAW6Af1Ket8YMxGYCNapUPv371/pMRhjuPubtSTm5PDW6E60b+B6n879983BJ3knaV3uBnqwtFYszTtfQLizA3MBWtPnFO2LU7QvrLw9z2+UwZGD2YeB4hM2NLAtO42IDAKeBIYaY/IcGE+ZPl+0lz+2HGVc36YulyQ8cpKJ+vs+omffRNDOH8GSD4DRB+eUUlXAkUeaVUBLEWmKNUFcC1xfvIGIdAY+BS43xhx3YCxlWrk3mVf/2M5FLSMZ2bWBs8I4mzEExs0kctHTeOSlk9L9IVK63qdF/JRSVcphicI26dG9wJ9YCwx+aYzZIiITgNXGmJnAG1gLD04X60W0A8aYoY6KqSQJGXncO2UtdWv58ehlMYgL3VLqlXGY2v+MJy8yloRh/6Ugoo2zQ1JKuSGHXrswxvwG/HbGsmeKfT/Ikfu3x5dL9pKUlc8nY7sQ5OsCl3KMwe/QYnIbXmQt4nfND+TV7mR9mE4ppZzABY6MzrVwZwJt69WieZTzH6jzSttH1LzH8D+8hPirfyC3fm/y6nZ1dliqBimyFJKXlkhRQT7uMFtAZEQYWcf2OzuMKiR4ePvgGxKJh2flHd7dOlEkZuaxJT6d2/o0cW4gRRZCNn5O2IrXwcObhP6vaRE/5RB5aYmEh9YiLCzcpS6zOkpuThZ+/tWj2nNlMMaQkpJMcmoi/uGVNwunWyeKJXGJAHRrEubUOOrOvoWAA3PJajKIxH6vYAmq59R4VM1VVJDvNknCHYkIYWHhJCYkVup23TpRLNqVSLCfFy1rB1f9zi351nkhxIOM1qPIiBlBVsthWp9JOZjRJFHDWX+/lXtZ0aFFAV2ZMYZFuxLo0iisyqc19T22jgbfD6bWpq8AyGo5lKxWV2uSUEq5JLdNFN+uOMCx9Dy6V+FlJynIIXzJBOrNGIpHXioFIS5TLFepKhPg50OPbl3p0qkjw68eRmpqapntExISuKhPb3p278bixYuqJsgq9tqrr5T5/rChQ8rtJ0dyy0QxY80hnv5lMz2bhnNJFc1/7XtkFQ2+G0To+k/JiL2Bg9fPJ6fxwCrZt1KuxN/fn5Wr17B2/QbCwsP55OOPymw/b+5c2rZrz4pVq7nwwovs2ofFYqmMUKvM66+9WuJyYwxFRUX8MvNXQkNDqzaoYtxujOLXjfE8+sMGOjcM5fmhbc+7Boq9xJKPETl526tSzvbSb9vYfiS9UrfZOroWT15h/4OhvXr1YtOmTQDs3r2b8Q/cR2JCIv4B/nz88afk5ubyn/88Tm5ODj3WrGHBosUsXryIFyc8T15ePs2aNWPi518QFBREq5bNGTVyFHPmzOGhhx8hLDyMCc89S0FB4Vntxo69kd9mz6agoIApU78jpnVrMjMzeXD8A6xdswYR4cmnnuaa4cP5+++/StxfcZcMGkinTp1YsngJWVlZfPG///HGa6+xectmRo4cxfMTXgBgyrff8tGH75OfX0D3Hj147/0PePbpp8jJyaFHt660iY3l+QkvcNWVV9C9Rw/WrV3LzzNnccmggSxdtoLIyEi+mTyZd95+CxGhXfv2/G/SV5X3CyyFW51R7DqWwUPfb6BtvRBeuLodPl6O/fED9v5FyFrrp6XcBn04dP18TRJK2VgsFubNncuQIUMAuOff/+Ltt99l2YqVvPra69x//7107NSJZ559jpGjRrNy9RqysrJ49ZWX+e2Pv1i+chVdunbl3XfePrnN8IgIlq9cxcCLL+bVV17m519+KbFdZGQky1euYtxdd/H2228B8MpLLxISEsKadetZvXYd/QcMIDExscz9Fefj7cPS5Su4c9w4Ro0Yzjvvvc/adRv4ZvLXJCUlsX3bNn6Y/j3zFixi5eo1eHp6MnXKFF58+ZWTZ1lffT0ZgLi4Xdz1r3+xbsNGGjc+dYl665YtvPrKy/zx19+sWrOWN98qOZbK5jZnFAWWIh6cth5/b0+eGxqLv7fjnnT2yEkictEzBO36mbzItqR1vMNan0mL+CkXUpFP/pXpxKfn+PjDxLRuzcWDLiEzM5Ply5Zx/XXXnmyXl3d2jdCVK5azfds2BvTrC0B+fj49e/U6+f7IUaNPa3fZZZfhIR5ntRt29TUAdO7ShZ9//gmAuXPnMvmbb0+2CQsL47fZv5a5v+KuvOoqANq2a0eb2Fiio6MBaNK0KYcOHmTp0iWsW7eWPr17neyHqKioErfVqHFjevY8ez/z589j+IgRREZGAhAeXjW1o93myPX+3Dg2x6fz/NC2hAU4qKieMQTu+sVaxC8/g+Qej5Da5R4t4qdUMSc+PWdnZzPkysF88vFH3HjTzYSGhrJy9Zoy1zXGMPDiQacd0IsLDAw8rd1nn00s8YE7X1/rhGSenp4UFhae8/5K2qaHh8fJ70+8LrQUYozhhrE38uJLL5e7rcAA13pI0C0uPe06lsGH8+K4JLYOF7WMdNh+vDIOU3vOgxSENObQ6D9J7f6gJgmlShEQEMBbb73DO++8TUBAAE2aNGHGDz8A1gP0xg0bzlqnR89eLFu2lN1xcQBkZWWxa+fOUtvt2b27zHbFXXzxxXzyyccnX6ekpNi9P3sMGDCQn376kePHrYWyk5OT2b/fWl7E29ubgoKCcrfRv/8Afpwxg6SkpJPbqApukSjemxuHr5cH/+7XvPI3borwPzAfwFrEb/iPxA//hYKImMrfl1I1TKfOnWnfrj3TvvuO/301mUmTvqR71y507tiBWbNmntU+KiqKzz7/gptuHEu3Lp3pd9GF7Nhx9uyOJ9rdfvvtZbYr7vH/PElKSgpdOnWke9cuLJg/3+792aNNbCzPPTeBIVcMpluXzlw5+HKOHj0CwO2330G3Lp25+aYby9xGbNu2/N/jT3DJxQPp3rULjz36yDnFUlFiTPUqDBYTE2Mq8otKysyj1ytzGNqxHvcMaFGpsXil7rEW8YtfRvw1M8itV/K1S0fR2btO0b44pay+yDq2n1Yxras4Iudxt1pPJ+zcsZ3AOqcGwb09PWgUEbjGGNPtXLZX48cofl4fT4HFcEX76MrbaFEhIes/I2zlfzGePiQMeJPcaC3ip5SqmWp0ojDGMG3VAVrXDaZpZOV9qqg7+2YCDswnq+llJPZ7GUtg5VVpVEopV1OjE8W6g6nsPJbJg4Nanv/GLHng4W0t4tfmOjJajyarxVCtz6SUqvFq7GB2Vl4hj/+wkdAAbwa0rn1e2/I9upoG0y6j1qZJ1m23GKKVXpVSbqNGnlEYY/jPT5uIS8jktREdznmKUynIJnzFa9Ta8AWWoGgKQppWcqRKKeX6amSi+Gb5fn5ZH89tfZrQtfG5VYf1i19B1JzxeKcfIK3dzST3fgLj44R5K5RSyslq3KWnuOOZTPh1K72ahXN9z0bnvqGiQoyHF/HXzCCp38uaJJSqJBUtM26vr7/+ivEP3F8p21Knq3GJ4u1/duLl6cFjl8XgUcExhIA9fxC65n3AVsTvunlV/myEUjVdRcuMK+erUZeetsanM3vjEW7o2YjQCtRz8sxOIGLhUwTt/pW8qPakdrpLi/gpt+A9+aqzllnaXE1Rt9uhIBvv78ac/X6H6yjqeD1kJ+E945bT3iu4cVaF9l+8zPiqVSt55KEHyc3Nw9/fj4mffUGrmBi+/vorZs+aRXZONnv27GHY0GG8/OprAHz11STeeO01QkNDaN+h48kaS/v27eOucXeQkJBA7dq1mfjZFzRq1Ig7br8Nf39/Nqxfx/GEBD6d+BnffvMNK5Yvp3uPHnz+xZdnxfjH77/x2KOPEhgYSO8LLmDv3j389PNMXpjwPEFBQTz40MMAdOnUkR9//oUmTZqUWE4c4K5xd54sY37zLbdw/wPj+fCD9/ls4kS8vLxo06YNk7+dUqE+rAo16kj43pxdBPl6MbpbA/tWMIagnTOIWPQsHgXZJPf8P1I73w2e3o4NVCl1ssz4LbfeCkBMTGvmzFuAl5cXc+b8wzNPP8V3308HYMPGDaxYuRpfX1/at4vl7nvuxcvLixcmPM+y5SsJCQnh0ksuplOnzgA8NP4Bxo69iVGjRvDdtO95+MHxTJ/xIwCpKSksWLSEX2fNYuTwa5g3fyGxn06kT+9ebFi/no6dOp2MMTc3l3vu+Tf/zJlH06ZNuXHsDeX+XMXLiXt7e3P/ffcydcoUYtvGEh9/mLXrrTWsTlxy++8br7N9Zxy+vr5OncWuLDUqUWw5kkaPpuEE+9l3oPfKOEzU3EfJq92ehAFvUhBeCc9bKFWNlHkG4B1Q9vsBERU+g4CSy4wDpKWlccdttxIXF4eInFYkb8CAgYSEhADQpk0bDhzYT1JiEn379jtZqnvUqNHs2rULgBUrljNt+g9YCvO54YaxPPnE4ye3dcWVQxAR2rZrR+06dWjXvr11u7Gx7N+//7REsWP7dpo2bUrTptY7HseMuZYvvviszJ9v3ry5JZYTv3LIEPbu3cuD4x9g8ODBDLrkUgDatW/PLTfdyFVDhzF02LAK92dVqHFjFB7lDUuYIvz3zwWsRfwOj/iZ+Gt+0iShVBU5MUaxM24PxpiTYxTPP/cs/fr3Z+36Dcz46Wdy83JPrlO8bHd5pcHLc1o5cJ8zyoFXYLteXl4UFRWdfH0i3hPlxFeuXsPK1WvYtGUrTz/zLGFhYaxavZa+ffvx2cSJ/OuucQD8/Mss7rr7btavtyaX8/nZHKXGJYqyeKfuJvqnkUT/eiN+h5cBkF+7I3g4bhIjpVTJipcZLywsJD0tjXr16gMw+evyp/fs3qMHixYtJCkpiYKCAmbM+OHke7169eb7adMAmDp1Cn36XHhOMbaKiWHv3r3s27cPgOnTvz/5XuPGTVi/bh0A69atZd/evUDp5cQTExMpKirimuHDee75Caxft46ioiIOHjxI//4DeOnlV0lPTyMzM/OcYnWkGnHp6UhaDrM2xJOclV9yg6JCQtZ/StjKNzFefhwf+JbezaSUCyheZvyhRx7hjttu49VXXubywYPLXTc6Opqnnn6GfhddSGhoCB06djr53lvvvMu4O2/nzTffODmYfS78/f157733GTrkSgIDA+na7VTx1WuGD+fbbyfTuWMHuvfoQcuWrYDTy4kXFRXh7e3NO++9h7+fP+PuvOPkWcgLL76IxWLh1ltuIj0tHWMM/77nXkJDQ88pVkeq9mXGkzLzGPTWAlKyC4gO8eOOC5ueVbKj7szrCTi4gKxmV5DY9yUsgedX0sNVaGntU7QvTtEy46dURpnxzMxMgoKCMMbwwP330aJFC+5/YHzlBOggWma8mAU7E3jh162k5xTy0tXt6N084uR7UpiL8fAGD08y2t5ARuz1ZLUY4sRolVLV0ZdffM43kyeTn59Px06duOPOcc4OqcpV60Tx/pxdxB3P5LmhsaclCd8jq4ia+zDp7W4mvePtZDW/0olRKqWqs/sfGO/yZxCOVq0TxfGMPC5sEUnfltbb4yQ/i/Dlr1Jr0/8oDK6vdzIpdRbBGINo5eMayzqcULm/32qbKOJTcziQnM2QDtaZ6/wOLyNqzni8Mg6T3v5Wkns9jvFxvykQlSqLh7cPKSnJhIWFa7KogYwxpKQk4+Ftf2UKe1TLRDH8oyWsPZAKQPv6ISeXGy8/4of/RF50dydFppRr8w2JJDk1kcSERKB63chyLgoK8vGu5IOmaxM8vH3wDYms1K1Wy0RxIkm81mYv3Q9uIL3u/eTW782ha+fqMxFKlcHD0wv/cPeZulfvhqscDn3gTkQuF5EdIhInIo+X8L6viEyzvb9CRJrYs90oUplddyJj9j5J0L4/wGJ7fkKThFJKVTqHnVGIiCfwIXAJcAhYJSIzjTFbizW7HUgxxrQQkWuB14Czy1UWY8lN5x/fRwhMKySp1xOkdbpLi/gppZQDOfLSUw8gzhizB0BEvgOGAcUTxTDgOdv3PwAfiIiYMp4CDClI4JB3DzyHvUdQg1jc6erjmUTAx8utqrCUSvviFO2LU7QvrLw8zq8PHJko6gMHi70+BPQsrY0xplBE0oAIILF4IxEZB5x4yiWv3dPLNvO0DlgDkZzRV25M++IU7YtTtC9OiTnXFavFYLYxZiIwEUBEVp/rY+g1jfbFKdoXp2hfnKJ9cYqIrD7XdR15TnYYaFjsdQPbshLbiIgXEAIkOTAmpZRSFeTIRLEKaCkiTUXEB7gWmHlGm5nAzbbvRwJzyxqfUEopVfUcdunJNuZwL/An4Al8aYzZIiITgNXGmJnAF8BkEYkDkrEmk/JMdFTM1ZD2xSnaF6doX5yifXHKOfdFtSszrpRSqmrpfWNKKaXKpIlCKaVUmVw2UTiq/Ed1ZEdfPCQiW0Vko4jMEZHGJW2nJiivL4q1GyEiRkRq7K2R9vSFiIy2/W1sEZEpVR1jVbHj/0gjEZknIuts/0+ucEacjiYiX4rIcRHZXMr7IiLv2fppo4h0sWvDxhiX+8I6+L0baAb4ABuA2DPa/Bv4xPb9tcA0Z8ftxL4YAATYvr/bnfvC1i4YWAgsB7o5O24n/l20BNYBYbbXtZ0dtxP7YiJwt+37WGCfs+N2UF/0BboAm0t5/wrgd6wTVvQCVtizXVc9ozhZ/sMYkw+cKP9R3DDgK9v3PwAXS80ssF9uXxhj5hljsm0vl2N9ZqUmsufvAuAFrHXDcqsyuCpmT1/cCXxojEkBMMYcr+IYq4o9fWGAWrbvQ4D4KoyvyhhjFmK9g7Q0w4CvjdVyIFREosvbrqsmipLKf9QvrY0xphA4Uf6jprGnL4q7Hesnhpqo3L6wnUo3NMbMrsrAnMCev4tWQCsRWSIiy0Xk8iqLrmrZ0xfPAWNF5BDwG3Bf1YTmcip6PAGqSQkPZR8RGQt0A/o5OxZnEBEP4C3gFieH4iq8sF5+6o/1LHOhiLQ3xqQ6MygnuQ6YZIx5U0R6Y31+q50xpsjZgVUHrnpGoeU/TrGnLxCRQcCTwFBjTF4VxVbVyuuLYKAdMF9E9mG9Bjuzhg5o2/N3cQiYaYwpMMbsBXZiTRw1jT19cTvwPYAxZhngh7VgoLux63hyJldNFFr+45Ry+0JEOgOfYk0SNfU6NJTTF8aYNGNMpDGmiTGmCdbxmqHGmHMuhubC7Pk/8jPWswlEJBLrpag9VRhjVbGnLw4AFwOISBusiSKhSqN0DTOBm2x3P/UC0owxR8pbySUvPRnHlf+oduzsizeAIGC6bTz/gDFmqNOCdhA7+8It2NkXfwKXishWwAI8aoypcWfddvbFw8BnIvIg1oHtW2riB0sRmYr1w0GkbTzmWcAbwBjzCdbxmSuAOCAbuNWu7dbAvlJKKVWJXPXSk1JKKRehiUIppVSZNFEopZQqkyYKpZRSZdJEoZRSqkyaKJRDiYhFRNYX+2pSRtvMKgytVCJST0R+sH3fqXilUREZWlbVWgfE0kRErj+H9fxFZIGIeNq2kXPG78FHRG4RkQTb660icqdt3eLLt9tuKT2x3XtF5LbK/BmV69PbY5VDiUimMSaosttWFRG5BWsF2nsduA8vW72ykt7rDzxijBlSwW3eA3gZY961JedfjTHtzmhzC7afTURqA1uwPtk+uNjyCGAH0NkYc1BEAoAlxpjOFfohVbWmZxSqSolIkFjnzFgrIptE5KzqryISLSILbZ9oN4vIRbbll4rIMtu600XkrKQiIvNF5N1i6/awLQ8XkZ/FWoN/uYh0sC3vV+xT9joRCbZ9At9se8p3AjDG9v4Y26ftD0QkRET2i7W+FCISKCIHRcRbRJqLyB8iskZEFolI6xLifE5EJovIEqwPjjaxtV1r+7rA1vRV4CLb/h+0nSG8ISKrbD/LXaV09Q3AL/b+XmxP9O8GGp+xPAnrw1nRttfZwL4T/arcgyYK5Wj+xQ7EP2Et/X2NMaYL1nk03hQ5qzz89cCfxphOQEdgvVhLUDwFDLKtuxp4qJR9BtjW/TfwpW3Z88A6Y0wH4D/A17bljwD32NpfBOSc2IitZPUzWOf36GSMmVbsvTRgPacKMA6xxVyAde6D+4wxXW3b/6iUOGNtP891wHHgEtvPNgZ4z9bmcWCRbf9vY61ZlGaM6Q50B+4UkabFN2pLcM2MMfuKLW5e7Pfw4ZmBiEgzrPM5xJ2xvBHWchcbiy1ebesr5SZcsoSHqlFybAdhAETEG3hZRPoCRVhLHNcBjhZbZxXwpa3tz8aY9SLSD+uBdYktr/gAy0rZ51Sw1uYXkVoiEgpcCIywLZ8rIhEiUgtYArwlIt8CPxpjDp2dt0o1DetBfR7WEjIf2c5yLuBUORUA31LWn2mMOZGYvIEPRKQT1nIbrUpZ51Kgg4iMtL0OwVrob2+xNpFA6hnr7S7+eyhmjIhcCOQBdxljkm1xj7H9jloD9xpjis/tcdy2XLkJTRSqqt0ARAFdjTEFYq3y6le8ge0A3xe4EpgkIm8BKcDftk/f5Tlz4K3UgThjzKsiMhtr/ZslInIZ9k94NBNr0gsHugJzgUAgtZSD8pmyin3/IHAM6xmURxkxCNazlT/L2G4OZ/RpGaaVMv4yzTZG0Q34S0RmGmNOJHM/ip15qZpPLz2pqhYCHLcliQGccU0cQKxzfh8zxnwGfI51asflQB8RaWFrEygipX3qHmNrcyHWyzRpwCKsSerEAHGiMSZdRJobYzYZY17DeiZz5iflDKzly89ijMm0rfMu1sFiizEmHdgrIqNs+xIR6WhnvxyxzY9wI9bidiXt/0/gbtvZFiLSSkQCz4grBfAUEXuTRalslXcnAw8UW9wKKHFOZlUzaaJQVe1boJuIbAJuAraX0KY/sEFE1mE96L9rjEnAOiHRVBHZiPWyU2mXP3Jt636C9Zo+WGc462pb91VOlagfbxu43ggUcPbsgPOA2BOD2SXsaxow1vbvCTcAt4vIBqx3EpU0XeuZPgJutq3TmlNnGxsBi4hsEOttqp8DW4G1IrIZa3n5kq4M/IX1cltleA24VUROJKw+wN+VtG1VDejtsapGEZH5WG8nrYlzUNhNrFPCPmiMubGSt9sZeKiyt6tcm55RKFUDGWPWAvNExLPcxhUTCTxdydtULk7PKJRSSpVJzyiUUkqVSROFUkqpMmmiUEopVSZNFEoppcqkiUIppVSZ/h9dMvKeL3LIUgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8357833333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ROCCurveReport.generate_report(\n",
    "    metric_result=loss_audit_results[0],\n",
    "    inference_game_type=InferenceGame.PRIVACY_LOSS_MODEL,\n",
    "    show=True\n",
    ")\n",
    "print(loss_audit_results[0].roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ROCCurveReport.generate_report(\n",
    "    metric_result=gradient_norm_audit_results[0],\n",
    "    inference_game_type=InferenceGame.PRIVACY_LOSS_MODEL,\n",
    "    show=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "privacy_meter_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af48e0a30d2a0b619bf296aea7d7271ba14c9beb98b0928b3e23c82f12ae949a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
